<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  
  <title>自编码器AutoEncoder | 姬小野的部落</title>
  
  <meta name="keywords" content="湖南大学">
  
  
  <meta name="description" content="湖南大学 | 计算机科学与技术">
  

  
  <link rel="alternate" href="/atom.xml" title="姬小野的部落">
  

  <meta name="HandheldFriendly" content="True">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <!-- meta -->
  

  <!-- link -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css">
  
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-waves@0.7.6/dist/waves.min.css">
  
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.10.1/css/all.min.css">
  

  

  
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-material-x@19.10.22/css/style.css">
  

  <script>
    function setLoadingBarProgress(num) {
      document.getElementById('loading-bar').style.width=num+"%";
    }
  </script>

  
  
<link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"></head>

<body>
  
  
  <div class="cover-wrapper">
    <cover class='cover post half'>
      
        
  <h1 class='title'>Demo</h1>


  <div class="m_search">
    <form name="searchform" class="form u-search-form">
      <input type="text" class="input u-search-input" placeholder="" />
      <i class="icon fas fa-search fa-fw"></i>
    </form>
  </div>

<div class='menu navgation'>
  <ul class='h-list'>
    
      
        <li>
          <a class="nav home" href="/"
            
            
            id="home">
            <i class='fas fa-rss fa-fw'></i>&nbsp;博文
          </a>
        </li>
      
        <li>
          <a class="nav home" href="/projects/"
            
            
            id="projects">
            <i class='fas fa-code-branch fa-fw'></i>&nbsp;项目
          </a>
        </li>
      
        <li>
          <a class="nav home" href="/friends/"
            
              rel="nofollow"
            
            
            id="friends">
            <i class='fas fa-link fa-fw'></i>&nbsp;友链
          </a>
        </li>
      
        <li>
          <a class="nav home" href="/about/"
            
              rel="nofollow"
            
            
            id="about">
            <i class='fas fa-info-circle fa-fw'></i>&nbsp;关于
          </a>
        </li>
      
    
  </ul>
</div>

      
    </cover>
    <header class="l_header pure">
  <div id="loading-bar-wrapper">
    <div id="loading-bar" class="pure"></div>
  </div>

	<div class='wrapper'>
		<div class="nav-main container container--flex">
      <a class="logo flat-box" href='/' >
        
          姬小野的部落
        
      </a>
			<div class='menu navgation'>
				<ul class='h-list'>
          
  					
  						<li>
								<a class="nav flat-box" href="/"
                  
                  
                  id="home">
									<i class='fas fa-grin fa-fw'></i>&nbsp;示例
								</a>
							</li>
      			
  						<li>
								<a class="nav flat-box" href="/blog/categories/"
                  
                    rel="nofollow"
                  
                  
                  id="blogcategories">
									<i class='fas fa-folder-open fa-fw'></i>&nbsp;分类
								</a>
							</li>
      			
  						<li>
								<a class="nav flat-box" href="/blog/tags/"
                  
                    rel="nofollow"
                  
                  
                  id="blogtags">
									<i class='fas fa-hashtag fa-fw'></i>&nbsp;标签
								</a>
							</li>
      			
  						<li>
								<a class="nav flat-box" href="/blog/archives/"
                  
                    rel="nofollow"
                  
                  
                  id="blogarchives">
									<i class='fas fa-archive fa-fw'></i>&nbsp;归档
								</a>
							</li>
      			
      		
				</ul>
			</div>

			
				<div class="m_search">
					<form name="searchform" class="form u-search-form">
						<input type="text" class="input u-search-input" placeholder="搜索" />
						<i class="icon fas fa-search fa-fw"></i>
					</form>
				</div>
			
			<ul class='switcher h-list'>
				
					<li class='s-search'><a class="fas fa-search fa-fw" href='javascript:void(0)'></a></li>
				
				<li class='s-menu'><a class="fas fa-bars fa-fw" href='javascript:void(0)'></a></li>
			</ul>
		</div>

		<div class='nav-sub container container--flex'>
			<a class="logo flat-box"></a>
			<ul class='switcher h-list'>
				<li class='s-comment'><a class="flat-btn fas fa-comments fa-fw" href='javascript:void(0)'></a></li>
        
          <li class='s-toc'><a class="flat-btn fas fa-list fa-fw" href='javascript:void(0)'></a></li>
        
			</ul>
		</div>
	</div>
</header>
	<aside class="menu-phone">
    <header>
		<nav class="menu navgation">
      <ul>
        
          
            <li>
							<a class="nav flat-box" href="/"
                
                
                id="home">
								<i class='fas fa-clock fa-fw'></i>&nbsp;近期文章
							</a>
            </li>
          
            <li>
							<a class="nav flat-box" href="/blog/archives/"
                
                  rel="nofollow"
                
                
                id="blogarchives">
								<i class='fas fa-archive fa-fw'></i>&nbsp;文章归档
							</a>
            </li>
          
            <li>
							<a class="nav flat-box" href="/projects/"
                
                
                id="projects">
								<i class='fas fa-code-branch fa-fw'></i>&nbsp;开源项目
							</a>
            </li>
          
            <li>
							<a class="nav flat-box" href="/friends/"
                
                  rel="nofollow"
                
                
                id="friends">
								<i class='fas fa-link fa-fw'></i>&nbsp;我的友链
							</a>
            </li>
          
            <li>
							<a class="nav flat-box" href="https://xaoxuu.com/wiki/material-x/"
                
                  rel="nofollow"
                
                
                id="https:xaoxuu.comwikimaterial-x">
								<i class='fas fa-book fa-fw'></i>&nbsp;主题文档
							</a>
            </li>
          
            <li>
							<a class="nav flat-box" href="/about/"
                
                  rel="nofollow"
                
                
                id="about">
								<i class='fas fa-info-circle fa-fw'></i>&nbsp;关于小站
							</a>
            </li>
          
       
      </ul>
		</nav>
    </header>
	</aside>
<script>setLoadingBarProgress(40);</script>

  </div>


  <div class="l_body">
    <div class='body-wrapper'>
      <div class='l_main'>
  

  <article id="post" class="post white-box article-type-post" itemscope itemprop="blogPost">
    


  <section class='meta'>
    
    
    <div class="meta" id="header-meta">
      
        
  
    <h1 class="title">
      <a href="/2019/08/14/zi-bian-ma-qi-autoencoder/">
        自编码器AutoEncoder
      </a>
    </h1>
  


      
      <div class='new-meta-box'>
        
          
        
          
            
  <div class='new-meta-item author'>
    
      <a href="/" rel="nofollow">
        
          <i class="fas fa-user" aria-hidden="true"></i>
        
        <p></p>
      </a>
    
  </div>


          
        
          
            <div class="new-meta-item date">
  <a class='notlink'>
    <i class="fas fa-calendar-alt" aria-hidden="true"></i>
    <p>2019-08-14</p>
  </a>
</div>

          
        
          
            
  
  <div class='new-meta-item category'>
    <a href='/categories/深度学习/' rel="nofollow">
      <i class="fas fa-folder-open" aria-hidden="true"></i>
      <p>深度学习</p>
    </a>
  </div>


          
        
          
            
  
    <div class="new-meta-item browse busuanzi">
      <a class='notlink'>
        <i class="fas fa-eye" aria-hidden="true"></i>
        <p>
          <span id="busuanzi_value_page_pv">
            <i class="fas fa-spinner fa-spin fa-fw" aria-hidden="true"></i>
          </span>
        </p>
      </a>
    </div>
  


          
        
          
            

          
        
      </div>
      
        <hr>
      
    </div>
  </section>


    <section class="article typo">
      <div class="article-entry" itemprop="articleBody">
        <h2 id="一-什么是自编码器"><a href="#一-什么是自编码器" class="headerlink" title="一. 什么是自编码器"></a>一. 什么是自编码器</h2><p>自动编码器 autoencoder, 简单表现编码器为将一组数据进行压缩编码(降维), 解码器将这组数据恢复成高维的数据. 这种编码和解码的过程不是无损的, 因此最终的输出和输入是有一些差异的, 且非常依赖于训练的数据集.</p>
<p>如图所示<br><img src="/images/20190814_1.png" alt></p>
<p>如上面这张图所示, 对于一个简单的三层线性神经网络组成的自编码器, 我们在进行神经网络的搭建过程中, 将(input, hidden) 这个过程叫做编码器, 将(hidden, output) 这个过程叫做解码器. 对于mnist数据集而言, 它的维度变化是 784 -&gt; x -&gt; 784, 其中, x &lt; 784, 是编码的维度.</p>
<hr>
<h2 id="二-有什么作用"><a href="#二-有什么作用" class="headerlink" title="二. 有什么作用"></a>二. 有什么作用</h2><h3 id="1-图像去噪"><a href="#1-图像去噪" class="headerlink" title="1) 图像去噪"></a>1) 图像去噪</h3><p>看上去很强啊<br><img src="/images/20190814_2.png" alt></p>
<h3 id="2-可视化降维"><a href="#2-可视化降维" class="headerlink" title="2) 可视化降维"></a>2) 可视化降维</h3><hr>
<h2 id="三-如何实现"><a href="#三-如何实现" class="headerlink" title="三. 如何实现"></a>三. 如何实现</h2><p>训练神经网络需要定义损失函数, 那么这个自编码器的损失衡量值是什么? </p>
<p>衡量损失的值是由网络的输出结果和输入决定的. 也就是说, 是由这两个784维数据的差别决定的.</p>
<h3 id="1-全连接层实现"><a href="#1-全连接层实现" class="headerlink" title="1) 全连接层实现"></a>1) 全连接层实现</h3><p>首先定义一个神经网络</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Autoencoder</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, encoding_dim)</span>:</span></span><br><span class="line">        super(Autoencoder, self).__init__()</span><br><span class="line">        <span class="comment">## encoder ##</span></span><br><span class="line">        self.encoder = nn.Linear(<span class="number">784</span>, encoding_dim)</span><br><span class="line">        </span><br><span class="line">        <span class="comment">## decoder ##</span></span><br><span class="line">        self.decoder = nn.Linear(encoding_dim, <span class="number">784</span>)</span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="comment"># define feedforward behavior </span></span><br><span class="line">        <span class="comment"># and scale the *output* layer with a sigmoid activation function</span></span><br><span class="line"><span class="comment">#         print(x.shape)</span></span><br><span class="line">        x = x.view(<span class="number">-1</span>, <span class="number">784</span>)</span><br><span class="line">        x = F.relu(self.encoder(x))</span><br><span class="line">        x = torch.sigmoid(self.decoder(x))</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="comment"># initialize the NN</span></span><br><span class="line">encoding_dim = <span class="number">128</span></span><br><span class="line">model = Autoencoder(encoding_dim)</span><br></pre></td></tr></table></figure>

<p>定义损失函数和优化器</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># specify loss function</span></span><br><span class="line">criterion = nn.MSELoss()</span><br><span class="line"></span><br><span class="line"># specify loss function</span><br><span class="line">optimizer = torch.optim.Adam(model.parameters(), lr=<span class="number">0.001</span>)</span><br></pre></td></tr></table></figure>

<p>训练过程, 一共20个epochs, 话说pytorch还真慢, 这么简单的网络都要训练好一会</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># number of epochs to train the model</span></span><br><span class="line">n_epochs = <span class="number">20</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">1</span>, n_epochs+<span class="number">1</span>):</span><br><span class="line">    <span class="comment"># monitor training loss</span></span><br><span class="line">    train_loss = <span class="number">0.0</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">###################</span></span><br><span class="line">    <span class="comment"># train the model #</span></span><br><span class="line">    <span class="comment">###################</span></span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> train_loader:</span><br><span class="line">        <span class="comment"># _ stands in for labels, here</span></span><br><span class="line">        images, _ = data</span><br><span class="line">        <span class="comment"># flatten images</span></span><br><span class="line">        images = images.view(images.size(<span class="number">0</span>), <span class="number">-1</span>)</span><br><span class="line">        <span class="comment"># clear the gradients of all optimized variables</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        <span class="comment"># forward pass: compute predicted outputs by passing inputs to the model</span></span><br><span class="line"><span class="comment">#         print(images.shape)</span></span><br><span class="line">        outputs = model(images)</span><br><span class="line">        <span class="comment"># calculate the loss</span></span><br><span class="line">        loss = criterion(outputs, images)</span><br><span class="line">        <span class="comment"># backward pass: compute gradient of the loss with respect to model parameters</span></span><br><span class="line">        loss.backward()</span><br><span class="line">        <span class="comment"># perform a single optimization step (parameter update)</span></span><br><span class="line">        optimizer.step()</span><br><span class="line">        <span class="comment"># update running training loss</span></span><br><span class="line">        train_loss += loss.item()*images.size(<span class="number">0</span>)</span><br><span class="line">            </span><br><span class="line">    <span class="comment"># print avg training statistics </span></span><br><span class="line">    train_loss = train_loss/len(train_loader)</span><br><span class="line">    print(<span class="string">'Epoch: &#123;&#125; \tTraining Loss: &#123;:.6f&#125;'</span>.format(</span><br><span class="line">        epoch, </span><br><span class="line">        train_loss</span><br><span class="line">        ))</span><br></pre></td></tr></table></figure>

<p>训练过程的损失变化</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">Epoch: <span class="number">1</span> 	Training Loss: <span class="number">0.342308</span></span><br><span class="line">Epoch: <span class="number">2</span> 	Training Loss: <span class="number">0.081272</span></span><br><span class="line">Epoch: <span class="number">3</span> 	Training Loss: <span class="number">0.058724</span></span><br><span class="line">Epoch: <span class="number">4</span> 	Training Loss: <span class="number">0.051274</span></span><br><span class="line">Epoch: <span class="number">5</span> 	Training Loss: <span class="number">0.047382</span></span><br><span class="line">Epoch: <span class="number">6</span> 	Training Loss: <span class="number">0.044760</span></span><br><span class="line">Epoch: <span class="number">7</span> 	Training Loss: <span class="number">0.043184</span></span><br><span class="line">Epoch: <span class="number">8</span> 	Training Loss: <span class="number">0.042066</span></span><br><span class="line">Epoch: <span class="number">9</span> 	Training Loss: <span class="number">0.041246</span></span><br><span class="line">Epoch: <span class="number">10</span> 	Training Loss: <span class="number">0.040589</span></span><br><span class="line">Epoch: <span class="number">11</span> 	Training Loss: <span class="number">0.040059</span></span><br><span class="line">Epoch: <span class="number">12</span> 	Training Loss: <span class="number">0.039646</span></span><br><span class="line">Epoch: <span class="number">13</span> 	Training Loss: <span class="number">0.039272</span></span><br><span class="line">Epoch: <span class="number">14</span> 	Training Loss: <span class="number">0.038980</span></span><br><span class="line">Epoch: <span class="number">15</span> 	Training Loss: <span class="number">0.038733</span></span><br><span class="line">Epoch: <span class="number">16</span> 	Training Loss: <span class="number">0.038524</span></span><br><span class="line">Epoch: <span class="number">17</span> 	Training Loss: <span class="number">0.038328</span></span><br><span class="line">Epoch: <span class="number">18</span> 	Training Loss: <span class="number">0.038162</span></span><br><span class="line">Epoch: <span class="number">19</span> 	Training Loss: <span class="number">0.038012</span></span><br><span class="line">Epoch: <span class="number">20</span> 	Training Loss: <span class="number">0.037874</span></span><br></pre></td></tr></table></figure>

<p>那么效果如何呢? 上面一排是输入图像, 下面一排是输出图像. 经过自编码器之后, 还原度还是很高的.</p>
<p><img src="/images/20190814_3.png" alt></p>
<h3 id="2-测试-对有噪声图像的自编码"><a href="#2-测试-对有噪声图像的自编码" class="headerlink" title="2) 测试: 对有噪声图像的自编码"></a>2) 测试: 对有噪声图像的自编码</h3><p>首先查看一张图片</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">a_img = np.squeeze(images[<span class="number">0</span>])</span><br><span class="line">print(a_img.shape)</span><br><span class="line">print(np.max(a_img))</span><br><span class="line">print(np.min(a_img))</span><br><span class="line"></span><br><span class="line">plt.imshow(a_img, cmap=<span class="string">'gray'</span>)</span><br></pre></td></tr></table></figure>

<p><img src="/images/20190814_4.png" alt><br>然后向其中加入噪声</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a_img_x = a_img + <span class="number">0.08</span> * np.random.normal(loc=<span class="number">0.0</span>, scale=<span class="number">1.0</span>, size=a_img.shape)</span><br><span class="line"></span><br><span class="line">plt.imshow(a_img_x, cmap=<span class="string">'gray'</span>)</span><br></pre></td></tr></table></figure>

<p>这是加入噪声之后的图片, 可以看出差别还是很大的. 那么我们的编码器能还原出如何的效果呢?<br><img src="/images/20190814_5.png" alt></p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">a_img_output = model(torch.Tensor(a_img_x).view(<span class="number">1</span>, <span class="number">-1</span>))</span><br><span class="line">print(a_img_output.shape)</span><br><span class="line"></span><br><span class="line">output_img = a_img_output.view(<span class="number">28</span>, <span class="number">28</span>)</span><br><span class="line">output_img = output_img.detach().numpy()</span><br><span class="line"></span><br><span class="line">plt.imshow(output_img, cmap=<span class="string">'gray'</span>)</span><br></pre></td></tr></table></figure>

<p>这是还原后的, 说实话看到这个图片我心里也是很惊讶的. 就在于加入那么多噪声之后, 居然还可以还原的如此清晰. 当然这是对于MNIST数据集而言, 这个数据集比较简单.<br><img src="/images/20190814_6.png" alt></p>
<h3 id="3-卷积层实现"><a href="#3-卷积层实现" class="headerlink" title="3) 卷积层实现"></a>3) 卷积层实现</h3><p>不同之处在于定义自编码器的神经网络结构<br>如图所示<br><img src="/images/20190814_7.png" alt><br>可以看到在decoder中经过了两个反卷积层, <del>但是由于水平有限, 这个反卷积层看着好奇怪, 不知道是怎么反卷积的. </del></p>
<p>pytorch实现</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="comment"># define the NN architecture</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ConvAutoencoder</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(ConvAutoencoder, self).__init__()</span><br><span class="line">        <span class="comment">## encoder layers ##</span></span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">1</span>, <span class="number">16</span>, <span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.conv2 = nn.Conv2d(<span class="number">16</span>, <span class="number">4</span>, <span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        self.pool = nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>)        </span><br><span class="line">        </span><br><span class="line">        <span class="comment">## decoder layers ##</span></span><br><span class="line">        <span class="comment">## a kernel of 2 and a stride of 2 will increase the spatial dims by 2</span></span><br><span class="line">        self.t_conv1 = nn.ConvTranspose2d(<span class="number">4</span>, <span class="number">16</span>, <span class="number">2</span>, stride=<span class="number">2</span>)</span><br><span class="line">        self.t_conv2 = nn.ConvTranspose2d(<span class="number">16</span>, <span class="number">1</span>, <span class="number">2</span>, stride=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="comment">## encode ##</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">## decode ##</span></span><br><span class="line">        <span class="comment">## apply ReLu to all hidden layers *except for the output layer</span></span><br><span class="line">        <span class="comment">## apply a sigmoid to the output layer</span></span><br><span class="line">        x = F.relu(self.conv1(x))</span><br><span class="line">        x = self.pool(x)</span><br><span class="line">        x = F.relu(self.conv2(x))</span><br><span class="line">        x = self.pool(x)</span><br><span class="line">        </span><br><span class="line">        x = F.relu(self.t_conv1(x))</span><br><span class="line">        x = torch.sigmoid(self.t_conv2(x))</span><br><span class="line">                </span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="comment"># initialize the NN</span></span><br><span class="line">model = ConvAutoencoder()</span><br><span class="line">print(model)</span><br></pre></td></tr></table></figure>

<p>训练起来比全连接层的网络还要慢很多, 而损失值的降低也慢很多, 不像之前从epoch 1 到 epoch 2 直接就断崖式下跌了. 下面是损失值的变化过程, 只训练了 15个epoch. 从损失之上看这个效果好像差很多?</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">Epoch: <span class="number">1</span> 	Training Loss: <span class="number">0.448799</span></span><br><span class="line">Epoch: <span class="number">2</span> 	Training Loss: <span class="number">0.266815</span></span><br><span class="line">Epoch: <span class="number">3</span> 	Training Loss: <span class="number">0.251290</span></span><br><span class="line">Epoch: <span class="number">4</span> 	Training Loss: <span class="number">0.240823</span></span><br><span class="line">Epoch: <span class="number">5</span> 	Training Loss: <span class="number">0.231836</span></span><br><span class="line">Epoch: <span class="number">6</span> 	Training Loss: <span class="number">0.220550</span></span><br><span class="line">Epoch: <span class="number">7</span> 	Training Loss: <span class="number">0.210341</span></span><br><span class="line">Epoch: <span class="number">8</span> 	Training Loss: <span class="number">0.202768</span></span><br><span class="line">Epoch: <span class="number">9</span> 	Training Loss: <span class="number">0.197010</span></span><br><span class="line">Epoch: <span class="number">10</span> 	Training Loss: <span class="number">0.193259</span></span><br><span class="line">Epoch: <span class="number">11</span> 	Training Loss: <span class="number">0.190589</span></span><br><span class="line">Epoch: <span class="number">12</span> 	Training Loss: <span class="number">0.188406</span></span><br><span class="line">Epoch: <span class="number">13</span> 	Training Loss: <span class="number">0.186529</span></span><br><span class="line">Epoch: <span class="number">14</span> 	Training Loss: <span class="number">0.184983</span></span><br><span class="line">Epoch: <span class="number">15</span> 	Training Loss: <span class="number">0.183579</span></span><br></pre></td></tr></table></figure>

<p>观察下图的数字9的话, 可以看到损失了不少.<br><img src="/images/20190814_8.png" alt></p>
<p><strong>再看看噪声图片的处理能力如何</strong></p>
<p>原图:<br><img src="/images/20190814_9.png" alt><br>加入噪声:<br><img src="/images/20190814_10.png" alt><br>经过自编码器<br><img src="/images/20190814_11.png" alt><br>呃, 效果似乎有点不是很对, 可能是训练的epoch太少了, 毕竟我们可以前面看到训练15个epoch的损失值还是达到了0.18, 而在全连接层的简单自编码器上第二个epoch的损失值就达到了0.08</p>
<hr>
<h2 id="四-一些小细节"><a href="#四-一些小细节" class="headerlink" title="四. 一些小细节"></a>四. 一些小细节</h2><ol>
<li><p>numpy 的 squeeze 函数<br><a href="https://blog.csdn.net/zenghaitao0128/article/details/78512715" target="_blank" rel="noopener">参考博客</a><br>作用：<strong>从数组的形状中删除单维度条目，即把shape中为1的维度去掉</strong></p>
</li>
<li><p>给MNIST图片加入噪声的方法</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">test_img_x = test_img + <span class="number">0.08</span> * np.random.normal(loc=<span class="number">0.0</span>, scale=<span class="number">1.0</span>, size=test_img.shape)</span><br></pre></td></tr></table></figure>

</li>
</ol>
<p>就是加入一些随机值, 在原图的基础上进行小幅度修改.</p>

      </div>
      
        <br>
        


  <section class='meta' id="footer-meta">
    <div class='new-meta-box'>
      
        
          <div class="new-meta-item date" itemprop="dateUpdated" datetime="2019-11-23T00:31:59+08:00">
  <a class='notlink'>
    <i class="fas fa-clock" aria-hidden="true"></i>
    <p>更新于 2019年11月23日</p>
  </a>
</div>

        
      
        
          
  
  <div class="new-meta-item meta-tags"><a class="tag" href="/tags/深度学习/" rel="nofollow"><i class="fas fa-tag" aria-hidden="true"></i><p>深度学习</p></a></div>


        
      
        
          
  <div class="new-meta-item share -mob-share-list">
  <div class="-mob-share-list share-body">
    
      
        <a class="-mob-share-qq" title="QQ好友" rel="external nofollow noopener noreferrer"
          
          href="http://connect.qq.com/widget/shareqq/index.html?url=https://fiveplus.top/2019/08/14/zi-bian-ma-qi-autoencoder/&title=自编码器AutoEncoder | 姬小野的部落&summary="
          
          >
          
            <img src="https://cdn.jsdelivr.net/gh/xaoxuu/assets@19.1.9/logo/128/qq.png">
          
        </a>
      
    
      
        <a class="-mob-share-qzone" title="QQ空间" rel="external nofollow noopener noreferrer"
          
          href="https://sns.qzone.qq.com/cgi-bin/qzshare/cgi_qzshare_onekey?url=https://fiveplus.top/2019/08/14/zi-bian-ma-qi-autoencoder/&title=自编码器AutoEncoder | 姬小野的部落&summary="
          
          >
          
            <img src="https://cdn.jsdelivr.net/gh/xaoxuu/assets@19.1.9/logo/128/qzone.png">
          
        </a>
      
    
      
        <a class="-mob-share-weibo" title="微博" rel="external nofollow noopener noreferrer"
          
          href="http://service.weibo.com/share/share.php?url=https://fiveplus.top/2019/08/14/zi-bian-ma-qi-autoencoder/&title=自编码器AutoEncoder | 姬小野的部落&summary="
          
          >
          
            <img src="https://cdn.jsdelivr.net/gh/xaoxuu/assets@19.1.9/logo/128/weibo.png">
          
        </a>
      
    
  </div>
</div>



        
      
    </div>
  </section>


      
      
          <div class="prev-next">
              
                  <section class="prev">
                      <span class="art-item-left">
                          <h6><i class="fas fa-chevron-left" aria-hidden="true"></i>&nbsp;上一页</h6>
                          <h4>
                              <a href="/2019/11/02/zheng-ze-biao-da-shi-zhuan-hua-wei-dfa-zhuang-tai-tu/" rel="prev" title="正则表达式转化为DFA状态图">
                                
                                    正则表达式转化为DFA状态图
                                
                              </a>
                          </h4>
                          
                              
                              <h6 class="tags">
                                  <a class="tag" href="/tags/编译原理/"><i class="fas fa-tag fa-fw" aria-hidden="true"></i> 编译原理</a>
                              </h6>
                          
                      </span>
                  </section>
              
              
                  <section class="next">
                      <span class="art-item-right" aria-hidden="true">
                          <h6>下一页&nbsp;<i class="fas fa-chevron-right" aria-hidden="true"></i></h6>
                          <h4>
                              <a href="/2019/08/05/introduction-to-pytorch-bi-ji/" rel="prev" title="Introduction to PyTorch 笔记">
                                  
                                      Introduction to PyTorch 笔记
                                  
                              </a>
                          </h4>
                          
                              
                              <h6 class="tags">
                                  <a class="tag" href="/tags/深度学习/"><i class="fas fa-tag fa-fw" aria-hidden="true"></i> 深度学习</a> <a class="tag" href="/tags/pytorch/"><i class="fas fa-tag fa-fw" aria-hidden="true"></i> pytorch</a>
                              </h6>
                          
                      </span>
                  </section>
              
          </div>
      
    </section>
  </article>



  <!-- 显示推荐文章和评论 -->



  






<!-- 根据页面mathjax变量决定是否加载MathJax数学公式js -->



  <script>
    window.subData = {
      title: '自编码器AutoEncoder',
      tools: true
    }
  </script>


</div>
<aside class='l_side'>
  
    
    
      
      
        
          
          
            
              <section class='widget author'>
  <div class='content pure'>
    
      <div class='avatar'>
        <img class='avatar' src='https://cdn.jsdelivr.net/gh/xaoxuu/assets@master/avatar/avatar.png'/>
      </div>
    
    
    
      <div class="social-wrapper">
        
          
            <a href="/atom.xml"
              class="social fas fa-rss flat-btn"
              target="_blank"
              rel="external nofollow noopener noreferrer">
            </a>
          
        
          
            <a href="mailto:me@xaoxuu.com"
              class="social fas fa-envelope flat-btn"
              target="_blank"
              rel="external nofollow noopener noreferrer">
            </a>
          
        
          
            <a href="https://github.com/xaoxuu"
              class="social fab fa-github flat-btn"
              target="_blank"
              rel="external nofollow noopener noreferrer">
            </a>
          
        
          
            <a href="https://music.163.com/#/user/home?id=63035382"
              class="social fas fa-headphones-alt flat-btn"
              target="_blank"
              rel="external nofollow noopener noreferrer">
            </a>
          
        
      </div>
    
  </div>
</section>

            
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
      
        
          
          
        
          
          
            
              
  <section class='widget toc-wrapper'>
    
<header class='pure'>
  <div><i class="fas fa-list fa-fw" aria-hidden="true"></i>&nbsp;&nbsp;本文目录</div>
  
    <!-- <div class='wrapper'><a class="s-toc rightBtn" rel="external nofollow noopener noreferrer" href="javascript:void(0)"><i class="fas fa-thumbtack fa-fw"></i></a></div> -->
  
</header>

    <div class='content pure'>
      <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#一-什么是自编码器"><span class="toc-text">一. 什么是自编码器</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#二-有什么作用"><span class="toc-text">二. 有什么作用</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-图像去噪"><span class="toc-text">1) 图像去噪</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-可视化降维"><span class="toc-text">2) 可视化降维</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#三-如何实现"><span class="toc-text">三. 如何实现</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-全连接层实现"><span class="toc-text">1) 全连接层实现</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-测试-对有噪声图像的自编码"><span class="toc-text">2) 测试: 对有噪声图像的自编码</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-卷积层实现"><span class="toc-text">3) 卷积层实现</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#四-一些小细节"><span class="toc-text">四. 一些小细节</span></a></li></ol>
    </div>
  </section>


            
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
      
        
          
          
        
          
          
        
          
          
            
              <section class='widget grid'>
  
<header class='pure'>
  <div><i class="fas fa-map-signs fa-fw" aria-hidden="true"></i>&nbsp;&nbsp;站内导航</div>
  
</header>

  <div class='content pure'>
    <ul class="grid navgation">
      
        <li><a class="flat-box" title="/" href="/"
          
          
          id="home">
          
            <i class="fas fa-clock fa-fw" aria-hidden="true"></i>
          
          近期文章
        </a></li>
      
        <li><a class="flat-box" title="/blog/archives/" href="/blog/archives/"
          
            rel="nofollow"
          
          
          id="blogarchives">
          
            <i class="fas fa-archive fa-fw" aria-hidden="true"></i>
          
          文章归档
        </a></li>
      
        <li><a class="flat-box" title="/projects/" href="/projects/"
          
          
          id="projects">
          
            <i class="fas fa-code-branch fa-fw" aria-hidden="true"></i>
          
          开源项目
        </a></li>
      
        <li><a class="flat-box" title="/friends/" href="/friends/"
          
            rel="nofollow"
          
          
          id="friends">
          
            <i class="fas fa-link fa-fw" aria-hidden="true"></i>
          
          我的友链
        </a></li>
      
        <li><a class="flat-box" title="https://xaoxuu.com/wiki/material-x/" href="https://xaoxuu.com/wiki/material-x/"
          
            rel="nofollow"
          
          
          id="https:xaoxuu.comwikimaterial-x">
          
            <i class="fas fa-book fa-fw" aria-hidden="true"></i>
          
          主题文档
        </a></li>
      
        <li><a class="flat-box" title="/about/" href="/about/"
          
            rel="nofollow"
          
          
          id="about">
          
            <i class="fas fa-info-circle fa-fw" aria-hidden="true"></i>
          
          关于小站
        </a></li>
      
    </ul>
  </div>
</section>

            
          
        
          
          
        
          
          
        
          
          
        
          
          
        
      
        
          
          
        
          
          
        
          
          
        
          
          
            
              
  <section class='widget category'>
    
<header class='pure'>
  <div><i class="fas fa-folder-open fa-fw" aria-hidden="true"></i>&nbsp;&nbsp;文章分类</div>
  
    <a class="rightBtn"
    
      rel="nofollow"
    
    
    href="/blog/categories/"
    title="blog/categories/">
    <i class="fas fa-expand-arrows-alt fa-fw"></i></a>
  
</header>

    <div class='content pure'>
      <ul class="entry">
        
          <li><a class="flat-box" title="/categories/blog/" href="/categories/blog/"><div class='name'>blog</div><div class='badge'>(1)</div></a></li>
        
          <li><a class="flat-box" title="/categories/java/" href="/categories/java/"><div class='name'>java</div><div class='badge'>(1)</div></a></li>
        
          <li><a class="flat-box" title="/categories/开发工具/" href="/categories/开发工具/"><div class='name'>开发工具</div><div class='badge'>(4)</div></a></li>
        
          <li><a class="flat-box" title="/categories/操作系统/" href="/categories/操作系统/"><div class='name'>操作系统</div><div class='badge'>(3)</div></a></li>
        
          <li><a class="flat-box" title="/categories/机器学习/" href="/categories/机器学习/"><div class='name'>机器学习</div><div class='badge'>(3)</div></a></li>
        
          <li><a class="flat-box" title="/categories/深度学习/" href="/categories/深度学习/"><div class='name'>深度学习</div><div class='badge'>(5)</div></a></li>
        
          <li><a class="flat-box" title="/categories/算法/" href="/categories/算法/"><div class='name'>算法</div><div class='badge'>(12)</div></a></li>
        
          <li><a class="flat-box" title="/categories/编译原理/" href="/categories/编译原理/"><div class='name'>编译原理</div><div class='badge'>(1)</div></a></li>
        
          <li><a class="flat-box" title="/categories/网络/" href="/categories/网络/"><div class='name'>网络</div><div class='badge'>(1)</div></a></li>
        
          <li><a class="flat-box" title="/categories/计算机系统/" href="/categories/计算机系统/"><div class='name'>计算机系统</div><div class='badge'>(2)</div></a></li>
        
          <li><a class="flat-box" title="/categories/计算机视觉/" href="/categories/计算机视觉/"><div class='name'>计算机视觉</div><div class='badge'>(1)</div></a></li>
        
      </ul>
    </div>
  </section>


            
          
        
          
          
        
          
          
        
          
          
        
      
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
            
              
  <section class='widget tagcloud'>
    
<header class='pure'>
  <div><i class="fas fa-tags fa-fw" aria-hidden="true"></i>&nbsp;&nbsp;热门标签</div>
  
    <a class="rightBtn"
    
      rel="nofollow"
    
    
    href="/blog/tags/"
    title="blog/tags/">
    <i class="fas fa-expand-arrows-alt fa-fw"></i></a>
  
</header>

    <div class='content pure'>
      <a href="/tags/Anaconda/" style="font-size: 16.5px; color: #888">Anaconda</a> <a href="/tags/Chrome/" style="font-size: 14px; color: #999">Chrome</a> <a href="/tags/blog/" style="font-size: 14px; color: #999">blog</a> <a href="/tags/csapp/" style="font-size: 14px; color: #999">csapp</a> <a href="/tags/gdb/" style="font-size: 14px; color: #999">gdb</a> <a href="/tags/idea/" style="font-size: 14px; color: #999">idea</a> <a href="/tags/java/" style="font-size: 14px; color: #999">java</a> <a href="/tags/opencv/" style="font-size: 14px; color: #999">opencv</a> <a href="/tags/pytorch/" style="font-size: 14px; color: #999">pytorch</a> <a href="/tags/ubuntu/" style="font-size: 19px; color: #777">ubuntu</a> <a href="/tags/v2ray/" style="font-size: 14px; color: #999">v2ray</a> <a href="/tags/人脸识别/" style="font-size: 16.5px; color: #888">人脸识别</a> <a href="/tags/开发工具/" style="font-size: 16.5px; color: #888">开发工具</a> <a href="/tags/开源库/" style="font-size: 21.5px; color: #666">开源库</a> <a href="/tags/操作系统/" style="font-size: 14px; color: #999">操作系统</a> <a href="/tags/数学/" style="font-size: 14px; color: #999">数学</a> <a href="/tags/数据库/" style="font-size: 14px; color: #999">数据库</a> <a href="/tags/机器学习/" style="font-size: 19px; color: #777">机器学习</a> <a href="/tags/汇编/" style="font-size: 14px; color: #999">汇编</a> <a href="/tags/深度学习/" style="font-size: 21.5px; color: #666">深度学习</a> <a href="/tags/目标检测/" style="font-size: 14px; color: #999">目标检测</a> <a href="/tags/科学上网/" style="font-size: 14px; color: #999">科学上网</a> <a href="/tags/算法/" style="font-size: 24px; color: #555">算法</a> <a href="/tags/编译原理/" style="font-size: 14px; color: #999">编译原理</a> <a href="/tags/随机树/" style="font-size: 14px; color: #999">随机树</a>
    </div>
  </section>


            
          
        
          
          
        
          
          
        
      
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
            
              <section class='widget list'>
  
<header class='pure'>
  <div><i class="fas fa-thumbs-up fa-fw" aria-hidden="true"></i>&nbsp;&nbsp;强烈推荐</div>
  
</header>

  <div class='content pure'>
    <ul class="entry">
      
        <li><a class="flat-box" title="https://xaoxuu.com/wiki/hexo.sh/" href="https://xaoxuu.com/wiki/hexo.sh/"
          
          
          >
          <div class='name'>
            
              <i class=" fa-fw" aria-hidden="true"></i>
            
            &nbsp;&nbsp;Hexo脚本（Mac）
          </div>
          
        </a></li>
      
        <li><a class="flat-box" title="https://xaoxuu.com/wiki/vim-cn.sh/" href="https://xaoxuu.com/wiki/vim-cn.sh/"
          
          
          >
          <div class='name'>
            
              <i class=" fa-fw" aria-hidden="true"></i>
            
            &nbsp;&nbsp;图床脚本（Mac）
          </div>
          
        </a></li>
      
        <li><a class="flat-box" title="https://yasuotu.com" href="https://yasuotu.com"
          
          
          >
          <div class='name'>
            
              <i class=" fa-fw" aria-hidden="true"></i>
            
            &nbsp;&nbsp;图片在线压缩
          </div>
          
        </a></li>
      
        <li><a class="flat-box" title="https://realfavicongenerator.net" href="https://realfavicongenerator.net"
          
          
          >
          <div class='name'>
            
              <i class=" fa-fw" aria-hidden="true"></i>
            
            &nbsp;&nbsp;生成Favicon
          </div>
          
        </a></li>
      
        <li><a class="flat-box" title="https://mxclub.github.io/resume/" href="https://mxclub.github.io/resume/"
          
          
          >
          <div class='name'>
            
              <i class=" fa-fw" aria-hidden="true"></i>
            
            &nbsp;&nbsp;简历主题
          </div>
          
        </a></li>
      
    </ul>
  </div>
</section>

            
          
        
      
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
      
    

  
</aside>

<footer id="footer" class="clearfix">
  
  
    <div class="social-wrapper">
      
        
          <a href="/atom.xml"
            class="social fas fa-rss flat-btn"
            target="_blank"
            rel="external nofollow noopener noreferrer">
          </a>
        
      
        
          <a href="mailto:me@xaoxuu.com"
            class="social fas fa-envelope flat-btn"
            target="_blank"
            rel="external nofollow noopener noreferrer">
          </a>
        
      
        
          <a href="https://github.com/xaoxuu"
            class="social fab fa-github flat-btn"
            target="_blank"
            rel="external nofollow noopener noreferrer">
          </a>
        
      
        
          <a href="https://music.163.com/#/user/home?id=63035382"
            class="social fas fa-headphones-alt flat-btn"
            target="_blank"
            rel="external nofollow noopener noreferrer">
          </a>
        
      
    </div>
  
  <br>
  <div><p>博客内容遵循 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh">署名-非商业性使用-相同方式共享 4.0 国际 (CC BY-NC-SA 4.0) 协议</a></p>
</div>
  <div>
    本站使用
    <a href="https://xaoxuu.com/wiki/material-x/" target="_blank" class="codename">Material X</a>
    作为主题
    
      ，
      总访问量为
      <span id="busuanzi_value_site_pv"><i class="fas fa-spinner fa-spin fa-fw" aria-hidden="true"></i></span>
      次
    
    。
  </div>
</footer>
<script>setLoadingBarProgress(80);</script>


      <script>setLoadingBarProgress(60);</script>
    </div>
    <a class="s-top fas fa-arrow-up fa-fw" href='javascript:void(0)'></a>
  </div>
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script>

  <script>
    var GOOGLE_CUSTOM_SEARCH_API_KEY = "";
    var GOOGLE_CUSTOM_SEARCH_ENGINE_ID = "";
    var ALGOLIA_API_KEY = "";
    var ALGOLIA_APP_ID = "";
    var ALGOLIA_INDEX_NAME = "";
    var AZURE_SERVICE_NAME = "";
    var AZURE_INDEX_NAME = "";
    var AZURE_QUERY_KEY = "";
    var BAIDU_API_ID = "";
    var SEARCH_SERVICE = "hexo" || "hexo";
    var ROOT = "/"||"/";
    if(!ROOT.endsWith('/'))ROOT += '/';
  </script>

<script src="//instant.page/1.2.2" type="module" integrity="sha384-2xV8M5griQmzyiY3CDqh1dn4z3llDVqZDqzjzcY+jCBCk/a5fXJmuZ/40JJAPeoU"></script>


  <script async src="https://cdn.jsdelivr.net/npm/scrollreveal@4.0.5/dist/scrollreveal.min.js"></script>
  <script type="text/javascript">
    $(function() {
      const $reveal = $('.reveal');
      if ($reveal.length === 0) return;
      const sr = ScrollReveal({ distance: 0 });
      sr.reveal('.reveal');
    });
  </script>


  <script src="https://cdn.jsdelivr.net/npm/node-waves@0.7.6/dist/waves.min.js"></script>
  <script type="text/javascript">
    $(function() {
      Waves.attach('.flat-btn', ['waves-button']);
      Waves.attach('.float-btn', ['waves-button', 'waves-float']);
      Waves.attach('.float-btn-light', ['waves-button', 'waves-float', 'waves-light']);
      Waves.attach('.flat-box', ['waves-block']);
      Waves.attach('.float-box', ['waves-block', 'waves-float']);
      Waves.attach('.waves-image');
      Waves.init();
    });
  </script>


  <script async src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-busuanzi@2.3/js/busuanzi.pure.mini.js"></script>




  
  
  
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-backstretch/2.0.4/jquery.backstretch.min.js"></script>
    <script type="text/javascript">
      $(function(){
        if ('.cover') {
          $('.cover').backstretch(
          ["https://img.vim-cn.com/29/91197b04c13f512f734a76d4ac422d89dbe229.jpg"],
          {
            duration: "6000",
            fade: "2500"
          });
        } else {
          $.backstretch(
          ["https://img.vim-cn.com/29/91197b04c13f512f734a76d4ac422d89dbe229.jpg"],
          {
            duration: "6000",
            fade: "2500"
          });
        }
      });
    </script>
  











  <script src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-material-x@19.9/js/app.js"></script>


  <script src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-material-x@19.9/js/search.js"></script>




<!-- 复制 -->
<script src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js"></script>
<script>
  let COPY_SUCCESS = "复制成功";
  let COPY_FAILURE = "复制失败";
  /*页面载入完成后，创建复制按钮*/
  !function (e, t, a) {
    /* code */
    var initCopyCode = function(){
      var copyHtml = '';
      copyHtml += '<button class="btn-copy" data-clipboard-snippet="">';
      copyHtml += '  <i class="fa fa-copy"></i><span>复制</span>';
      copyHtml += '</button>';
      $(".highlight .code pre").before(copyHtml);
      var clipboard = new ClipboardJS('.btn-copy', {
        target: function(trigger) {
          return trigger.nextElementSibling;
        }
      });

      clipboard.on('success', function(e) {
        //您可以加入成功提示
        console.info('Action:', e.action);
        console.info('Text:', e.text);
        console.info('Trigger:', e.trigger);
        success_prompt(COPY_SUCCESS);
        e.clearSelection();
      });
      clipboard.on('error', function(e) {
        //您可以加入失败提示
        console.error('Action:', e.action);
        console.error('Trigger:', e.trigger);
        fail_prompt(COPY_FAILURE);
      });
    }
    initCopyCode();

  }(window, document);

  /**
   * 弹出式提示框，默认1.5秒自动消失
   * @param message 提示信息
   * @param style 提示样式，有alert-success、alert-danger、alert-warning、alert-info
   * @param time 消失时间
   */
  var prompt = function (message, style, time)
  {
      style = (style === undefined) ? 'alert-success' : style;
      time = (time === undefined) ? 1500 : time*1000;
      $('<div>')
          .appendTo('body')
          .addClass('alert ' + style)
          .html(message)
          .show()
          .delay(time)
          .fadeOut();
  };

  // 成功提示
  var success_prompt = function(message, time)
  {
      prompt(message, 'alert-success', time);
  };

  // 失败提示
  var fail_prompt = function(message, time)
  {
      prompt(message, 'alert-danger', time);
  };

  // 提醒
  var warning_prompt = function(message, time)
  {
      prompt(message, 'alert-warning', time);
  };

  // 信息提示
  var info_prompt = function(message, time)
  {
      prompt(message, 'alert-info', time);
  };

</script>


<!-- fancybox -->
<script src="https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js"></script>
<script>
  let LAZY_LOAD_IMAGE = "";
  $(".article-entry").find("fancybox").find("img").each(function () {
      var element = document.createElement("a");
      $(element).attr("data-fancybox", "gallery");
      $(element).attr("href", $(this).attr("src"));
      /* 图片采用懒加载处理时,
       * 一般图片标签内会有个属性名来存放图片的真实地址，比如 data-original,
       * 那么此处将原本的属性名src替换为对应属性名data-original,
       * 修改如下
       */
       if (LAZY_LOAD_IMAGE) {
         $(element).attr("href", $(this).attr("data-original"));
       }
      $(this).wrap(element);
  });
</script>





  <script>setLoadingBarProgress(100);</script>
</body>
</html>
