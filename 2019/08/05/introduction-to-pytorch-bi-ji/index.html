<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  
  <title>Introduction to PyTorch 笔记 | 姬小野的部落</title>
  
  <meta name="keywords" content="湖南大学">
  
  
  <meta name="description" content="湖南大学 | 计算机科学与技术">
  

  
  <link rel="alternate" href="/atom.xml" title="姬小野的部落">
  

  <meta name="HandheldFriendly" content="True">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <!-- meta -->
  

  <!-- link -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css">
  
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-waves@0.7.6/dist/waves.min.css">
  
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.10.1/css/all.min.css">
  

  

  
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-material-x@19.10.22/css/style.css">
  

  <script>
    function setLoadingBarProgress(num) {
      document.getElementById('loading-bar').style.width=num+"%";
    }
  </script>

  
  
<link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"></head>

<body>
  
  
  <header class="l_header pure">
  <div id="loading-bar-wrapper">
    <div id="loading-bar" class="pure"></div>
  </div>

	<div class='wrapper'>
		<div class="nav-main container container--flex">
      <a class="logo flat-box" href='/' >
        
          姬小野的部落
        
      </a>
			<div class='menu navgation'>
				<ul class='h-list'>
          
  					
  						<li>
								<a class="nav flat-box" href="/"
                  
                  
                  id="home">
									<i class='fas fa-grin fa-fw'></i>&nbsp;示例
								</a>
							</li>
      			
  						<li>
								<a class="nav flat-box" href="/blog/categories/"
                  
                    rel="nofollow"
                  
                  
                  id="blogcategories">
									<i class='fas fa-folder-open fa-fw'></i>&nbsp;分类
								</a>
							</li>
      			
  						<li>
								<a class="nav flat-box" href="/blog/tags/"
                  
                    rel="nofollow"
                  
                  
                  id="blogtags">
									<i class='fas fa-hashtag fa-fw'></i>&nbsp;标签
								</a>
							</li>
      			
  						<li>
								<a class="nav flat-box" href="/blog/archives/"
                  
                    rel="nofollow"
                  
                  
                  id="blogarchives">
									<i class='fas fa-archive fa-fw'></i>&nbsp;归档
								</a>
							</li>
      			
      		
				</ul>
			</div>

			
				<div class="m_search">
					<form name="searchform" class="form u-search-form">
						<input type="text" class="input u-search-input" placeholder="搜索" />
						<i class="icon fas fa-search fa-fw"></i>
					</form>
				</div>
			
			<ul class='switcher h-list'>
				
					<li class='s-search'><a class="fas fa-search fa-fw" href='javascript:void(0)'></a></li>
				
				<li class='s-menu'><a class="fas fa-bars fa-fw" href='javascript:void(0)'></a></li>
			</ul>
		</div>

		<div class='nav-sub container container--flex'>
			<a class="logo flat-box"></a>
			<ul class='switcher h-list'>
				<li class='s-comment'><a class="flat-btn fas fa-comments fa-fw" href='javascript:void(0)'></a></li>
        
          <li class='s-toc'><a class="flat-btn fas fa-list fa-fw" href='javascript:void(0)'></a></li>
        
			</ul>
		</div>
	</div>
</header>
	<aside class="menu-phone">
    <header>
		<nav class="menu navgation">
      <ul>
        
          
            <li>
							<a class="nav flat-box" href="/"
                
                
                id="home">
								<i class='fas fa-clock fa-fw'></i>&nbsp;近期文章
							</a>
            </li>
          
            <li>
							<a class="nav flat-box" href="/blog/archives/"
                
                  rel="nofollow"
                
                
                id="blogarchives">
								<i class='fas fa-archive fa-fw'></i>&nbsp;文章归档
							</a>
            </li>
          
            <li>
							<a class="nav flat-box" href="/projects/"
                
                
                id="projects">
								<i class='fas fa-code-branch fa-fw'></i>&nbsp;开源项目
							</a>
            </li>
          
            <li>
							<a class="nav flat-box" href="/friends/"
                
                  rel="nofollow"
                
                
                id="friends">
								<i class='fas fa-link fa-fw'></i>&nbsp;我的友链
							</a>
            </li>
          
            <li>
							<a class="nav flat-box" href="https://xaoxuu.com/wiki/material-x/"
                
                  rel="nofollow"
                
                
                id="https:xaoxuu.comwikimaterial-x">
								<i class='fas fa-book fa-fw'></i>&nbsp;主题文档
							</a>
            </li>
          
            <li>
							<a class="nav flat-box" href="/about/"
                
                  rel="nofollow"
                
                
                id="about">
								<i class='fas fa-info-circle fa-fw'></i>&nbsp;关于小站
							</a>
            </li>
          
       
      </ul>
		</nav>
    </header>
	</aside>
<script>setLoadingBarProgress(40);</script>



  <div class="l_body nocover">
    <div class='body-wrapper'>
      <div class='l_main'>
  

  <article id="post" class="post white-box article-type-post" itemscope itemprop="blogPost">
    


  <section class='meta'>
    
    
    <div class="meta" id="header-meta">
      
        
  
    <h1 class="title">
      <a href="/2019/08/05/introduction-to-pytorch-bi-ji/">
        Introduction to PyTorch 笔记
      </a>
    </h1>
  


      
      <div class='new-meta-box'>
        
          
        
          
            
  <div class='new-meta-item author'>
    
      <a href="/" rel="nofollow">
        
          <i class="fas fa-user" aria-hidden="true"></i>
        
        <p></p>
      </a>
    
  </div>


          
        
          
            <div class="new-meta-item date">
  <a class='notlink'>
    <i class="fas fa-calendar-alt" aria-hidden="true"></i>
    <p>2019-08-05</p>
  </a>
</div>

          
        
          
            
  
  <div class='new-meta-item category'>
    <a href='/categories/深度学习/' rel="nofollow">
      <i class="fas fa-folder-open" aria-hidden="true"></i>
      <p>深度学习</p>
    </a>
  </div>


          
        
          
            
  
    <div class="new-meta-item browse busuanzi">
      <a class='notlink'>
        <i class="fas fa-eye" aria-hidden="true"></i>
        <p>
          <span id="busuanzi_value_page_pv">
            <i class="fas fa-spinner fa-spin fa-fw" aria-hidden="true"></i>
          </span>
        </p>
      </a>
    </div>
  


          
        
          
            

          
        
      </div>
      
        <hr>
      
    </div>
  </section>


    <section class="article typo">
      <div class="article-entry" itemprop="articleBody">
        <h1 id="Introduction-to-PyTorch-笔记"><a href="#Introduction-to-PyTorch-笔记" class="headerlink" title="Introduction to PyTorch 笔记"></a>Introduction to PyTorch 笔记</h1><h2 id="Part-1-Tensors-in-PyTorch-Solution-ipynb"><a href="#Part-1-Tensors-in-PyTorch-Solution-ipynb" class="headerlink" title="Part 1 - Tensors in PyTorch (Solution).ipynb"></a>Part 1 - Tensors in PyTorch (Solution).ipynb</h2><ol>
<li><p>最基本的神经网络, 使用矩阵计算. </p>
</li>
<li><p>激活函数, sigmoid, softmax, relu等</p>
</li>
<li><p>使用pytorch生成随机数(用来初始化weights). 似乎用不同的norm函数影响较大</p>
</li>
<li><p>介绍了前向传播的实现方式, 矩阵相乘 + 偏置</p>
</li>
<li><p>矩阵改变形状, 从numpy转化来/去</p>
</li>
</ol>
<h2 id="Part-2-Neural-Networks-in-PyTorch-Exercises-ipynb"><a href="#Part-2-Neural-Networks-in-PyTorch-Exercises-ipynb" class="headerlink" title="Part 2 - Neural Networks in PyTorch (Exercises).ipynb"></a>Part 2 - Neural Networks in PyTorch (Exercises).ipynb</h2><ol>
<li><p>加载MNIST数据集, 设置是训练或者测试, 用DataLoader进行分批加载, 可设置随机化</p>
</li>
<li><p>使用了transforms转换器转换数据, 比如归一化, 转化为tensor, 改变图片大小等</p>
 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">train_transforms = transforms.Compose([transforms.RandomRotation(<span class="number">30</span>),</span><br><span class="line">                                       transforms.RandomResizedCrop(<span class="number">224</span>),</span><br><span class="line">                                       transforms.RandomHorizontalFlip(),</span><br><span class="line">                                       transforms.ToTensor(),</span><br><span class="line">                                       transforms.Normalize([<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>], </span><br><span class="line">                                                            [<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>])])</span><br></pre></td></tr></table></figure>
</li>
<li><p>练习自定义网络权重, 并实现网络的前向传播</p>
</li>
<li><p>自己用pytorch实现了softmax. 使用sum, argmax等函数需要注意设置dim</p>
 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">softmax</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> torch.exp(out) / torch.exp(out).sum(dim=<span class="number">1</span>).view(<span class="number">64</span>, <span class="number">1</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>自定义网络结构(class方式), 继承自nn.Module. 自定义层次, 激活函数等, 实现init, forward函数</p>
 <figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Network</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Inputs to hidden layer linear transformation</span></span><br><span class="line">        self.hidden = nn.Linear(<span class="number">784</span>, <span class="number">256</span>)</span><br><span class="line">        <span class="comment"># Output layer, 10 units - one for each digit</span></span><br><span class="line">        self.output = nn.Linear(<span class="number">256</span>, <span class="number">10</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Define sigmoid activation and softmax output </span></span><br><span class="line">        self.sigmoid = nn.Sigmoid()</span><br><span class="line">        self.softmax = nn.Softmax(dim=<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="comment"># Pass the input tensor through each of our operations</span></span><br><span class="line">        x = self.hidden(x)</span><br><span class="line">        x = self.sigmoid(x)</span><br><span class="line">        x = self.output(x)</span><br><span class="line">        x = self.softmax(x)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
</li>
<li><p>有model对象, 可方便地查看模型的权重, 偏置值, 还可以进行更改, 如使用随机值</p>
</li>
<li><p>使用nn.Sequential()搭建网络, 和之前其实类似</p>
 <figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">model = nn.Sequential(nn.Linear(input_size, hidden_sizes[<span class="number">0</span>]),</span><br><span class="line">                      nn.ReLU(),</span><br><span class="line">                      nn.Linear(hidden_sizes[<span class="number">0</span>], hidden_sizes[<span class="number">1</span>]),</span><br><span class="line">                      nn.ReLU(),</span><br><span class="line">                      nn.Linear(hidden_sizes[<span class="number">1</span>], output_size),</span><br><span class="line">                      nn.Softmax(dim=<span class="number">1</span>))</span><br></pre></td></tr></table></figure>



</li>
</ol>
<ol start="8">
<li>多次出现helper辅助代码, 实现一些功能, 如下所示</li>
</ol>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn, optim</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test_network</span><span class="params">(net, trainloader)</span>:</span></span><br><span class="line"></span><br><span class="line">    criterion = nn.MSELoss()</span><br><span class="line">    optimizer = optim.Adam(net.parameters(), lr=<span class="number">0.001</span>)</span><br><span class="line"></span><br><span class="line">    dataiter = iter(trainloader)</span><br><span class="line">    images, labels = dataiter.next()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Create Variables for the inputs and targets</span></span><br><span class="line">    inputs = Variable(images)</span><br><span class="line">    targets = Variable(images)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Clear the gradients from all Variables</span></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Forward pass, then backward pass, then update weights</span></span><br><span class="line">    output = net.forward(inputs)</span><br><span class="line">    loss = criterion(output, targets)</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">imshow</span><span class="params">(image, ax=None, title=None, normalize=True)</span>:</span></span><br><span class="line">    <span class="string">"""Imshow for Tensor."""</span></span><br><span class="line">    <span class="keyword">if</span> ax <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        fig, ax = plt.subplots()</span><br><span class="line">    image = image.numpy().transpose((<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> normalize:</span><br><span class="line">        mean = np.array([<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>])</span><br><span class="line">        std = np.array([<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])</span><br><span class="line">        image = std * image + mean</span><br><span class="line">        image = np.clip(image, <span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    ax.imshow(image)</span><br><span class="line">    ax.spines[<span class="string">'top'</span>].set_visible(<span class="literal">False</span>)</span><br><span class="line">    ax.spines[<span class="string">'right'</span>].set_visible(<span class="literal">False</span>)</span><br><span class="line">    ax.spines[<span class="string">'left'</span>].set_visible(<span class="literal">False</span>)</span><br><span class="line">    ax.spines[<span class="string">'bottom'</span>].set_visible(<span class="literal">False</span>)</span><br><span class="line">    ax.tick_params(axis=<span class="string">'both'</span>, length=<span class="number">0</span>)</span><br><span class="line">    ax.set_xticklabels(<span class="string">''</span>)</span><br><span class="line">    ax.set_yticklabels(<span class="string">''</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> ax</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">view_recon</span><span class="params">(img, recon)</span>:</span></span><br><span class="line">    <span class="string">''' Function for displaying an image (as a PyTorch Tensor) and its</span></span><br><span class="line"><span class="string">        reconstruction also a PyTorch Tensor</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line"></span><br><span class="line">    fig, axes = plt.subplots(ncols=<span class="number">2</span>, sharex=<span class="literal">True</span>, sharey=<span class="literal">True</span>)</span><br><span class="line">    axes[<span class="number">0</span>].imshow(img.numpy().squeeze())</span><br><span class="line">    axes[<span class="number">1</span>].imshow(recon.data.numpy().squeeze())</span><br><span class="line">    <span class="keyword">for</span> ax <span class="keyword">in</span> axes:</span><br><span class="line">        ax.axis(<span class="string">'off'</span>)</span><br><span class="line">        ax.set_adjustable(<span class="string">'box-forced'</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">view_classify</span><span class="params">(img, ps, version=<span class="string">"MNIST"</span>)</span>:</span></span><br><span class="line">    <span class="string">''' Function for viewing an image and it's predicted classes.</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    ps = ps.data.numpy().squeeze()</span><br><span class="line"></span><br><span class="line">    fig, (ax1, ax2) = plt.subplots(figsize=(<span class="number">6</span>,<span class="number">9</span>), ncols=<span class="number">2</span>)</span><br><span class="line">    ax1.imshow(img.resize_(<span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>).numpy().squeeze())</span><br><span class="line">    ax1.axis(<span class="string">'off'</span>)</span><br><span class="line">    ax2.barh(np.arange(<span class="number">10</span>), ps)</span><br><span class="line">    ax2.set_aspect(<span class="number">0.1</span>)</span><br><span class="line">    ax2.set_yticks(np.arange(<span class="number">10</span>))</span><br><span class="line">    <span class="keyword">if</span> version == <span class="string">"MNIST"</span>:</span><br><span class="line">        ax2.set_yticklabels(np.arange(<span class="number">10</span>))</span><br><span class="line">    <span class="keyword">elif</span> version == <span class="string">"Fashion"</span>:</span><br><span class="line">        ax2.set_yticklabels([<span class="string">'T-shirt/top'</span>,</span><br><span class="line">                            <span class="string">'Trouser'</span>,</span><br><span class="line">                            <span class="string">'Pullover'</span>,</span><br><span class="line">                            <span class="string">'Dress'</span>,</span><br><span class="line">                            <span class="string">'Coat'</span>,</span><br><span class="line">                            <span class="string">'Sandal'</span>,</span><br><span class="line">                            <span class="string">'Shirt'</span>,</span><br><span class="line">                            <span class="string">'Sneaker'</span>,</span><br><span class="line">                            <span class="string">'Bag'</span>,</span><br><span class="line">                            <span class="string">'Ankle Boot'</span>], size=<span class="string">'small'</span>);</span><br><span class="line">    ax2.set_title(<span class="string">'Class Probability'</span>)</span><br><span class="line">    ax2.set_xlim(<span class="number">0</span>, <span class="number">1.1</span>)</span><br><span class="line"></span><br><span class="line">    plt.tight_layout()</span><br></pre></td></tr></table></figure>

<h2 id="Part-3-Training-Neural-Networks-Exercises-ipynb"><a href="#Part-3-Training-Neural-Networks-Exercises-ipynb" class="headerlink" title="Part 3 - Training Neural Networks (Exercises).ipynb"></a>Part 3 - Training Neural Networks (Exercises).ipynb</h2><ol>
<li>梯度下降与反向传播. 反向传播算法是求导过程中链式法则的应用<br> $$<br> \large \frac{\partial \ell}{\partial W_1} = \frac{\partial L_1}{\partial W_1} \frac{\partial S}{\partial L_1} \frac{\partial L_2}{\partial S} \frac{\partial \ell}{\partial L_2}<br> $$</li>
</ol>
<p>$$<br>\large W^\prime_1 = W_1 - \alpha \frac{\partial \ell}{\partial W_1}<br>$$</p>
<ol start="2">
<li><p>通常会导入的包</p>
 <figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets, transforms</span><br></pre></td></tr></table></figure>



</li>
</ol>
<ol start="3">
<li><p>介绍了损失函数. </p>
<p> 比如交叉熵nn.CrossEntropyLoss(), 一般赋值给criterion</p>
<p> 还有比如nn.NLLLoss()</p>
</li>
</ol>
<ol start="4">
<li><p>介绍了自动求导autograd, 调用.backward()可查看导数</p>
</li>
<li><p>介绍了optimizer, 在torch.optim中. 有SGD(随机梯度下降等). Adam更好. </p>
 <figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> optim</span><br><span class="line"></span><br><span class="line"><span class="comment"># Optimizers require the parameters to optimize and a learning rate</span></span><br><span class="line">optimizer = optim.SGD(model.parameters(), lr=<span class="number">0.01</span>)</span><br></pre></td></tr></table></figure>



</li>
</ol>
<ol start="6">
<li><p>训练中记得清零梯度<code>optimizer.zero_grad()</code></p>
</li>
<li><p>optimizer调用step()方法更新模型的权重</p>
</li>
<li><p>一个较完整的训练过程</p>
 <figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## Your solution here</span></span><br><span class="line"></span><br><span class="line">model = nn.Sequential(nn.Linear(<span class="number">784</span>, <span class="number">128</span>),</span><br><span class="line">                      nn.ReLU(),</span><br><span class="line">                      nn.Linear(<span class="number">128</span>, <span class="number">64</span>),</span><br><span class="line">                      nn.ReLU(),</span><br><span class="line">                      nn.Linear(<span class="number">64</span>, <span class="number">10</span>),</span><br><span class="line">                      nn.LogSoftmax(dim=<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">criterion = nn.NLLLoss()</span><br><span class="line">optimizer = optim.SGD(model.parameters(), lr=<span class="number">0.003</span>)</span><br><span class="line"></span><br><span class="line">epochs = <span class="number">5</span></span><br><span class="line"><span class="keyword">for</span> e <span class="keyword">in</span> range(epochs):</span><br><span class="line">    running_loss = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> images, labels <span class="keyword">in</span> trainloader:</span><br><span class="line">        <span class="comment"># Flatten MNIST images into a 784 long vector</span></span><br><span class="line">        images = images.view(images.shape[<span class="number">0</span>], <span class="number">-1</span>)</span><br><span class="line">    </span><br><span class="line">        <span class="comment"># <span class="doctag">TODO:</span> Training pass</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        output = model.forward(images)</span><br><span class="line"><span class="comment">#         print(output.shape)</span></span><br><span class="line"><span class="comment">#         print(labels.shape)</span></span><br><span class="line">        </span><br><span class="line">        loss = criterion(output, labels)</span><br><span class="line">        </span><br><span class="line">        running_loss += loss.item()</span><br><span class="line">        </span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        print(<span class="string">f"Training loss: <span class="subst">&#123;running_loss/len(trainloader)&#125;</span>"</span>)</span><br></pre></td></tr></table></figure>



</li>
</ol>
<h2 id="Part-4-Fashion-MNIST-Exercises-ipynb"><a href="#Part-4-Fashion-MNIST-Exercises-ipynb" class="headerlink" title="Part 4 - Fashion-MNIST (Exercises).ipynb"></a>Part 4 - Fashion-MNIST (Exercises).ipynb</h2><p>使用pytorch对数据集Fashion-MNIST进行分类的练习, 有如下过程</p>
<ol>
<li>导入必要的库</li>
<li>导入数据集并格式化</li>
<li>定义网络结构</li>
<li>定义optimizer, loss函数等</li>
<li>开始训练, 分epoch和batch</li>
<li>前向传播后计算损失函数, 求梯度, 反向传播更新权重</li>
<li>训练结束, 输出正确率, 损失值等等</li>
</ol>
<p>完整代码如下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn, optim</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets, transforms</span><br><span class="line"></span><br><span class="line"><span class="comment"># Define a transform to normalize the data</span></span><br><span class="line">transform = transforms.Compose([transforms.ToTensor(),</span><br><span class="line">                                transforms.Normalize((<span class="number">0.5</span>,), (<span class="number">0.5</span>,))])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Download and load the training data</span></span><br><span class="line">trainset = datasets.FashionMNIST(<span class="string">'~/.pytorch/F_MNIST_data/'</span>, download=<span class="literal">True</span>, train=<span class="literal">True</span>, transform=transform)</span><br><span class="line">trainloader = torch.utils.data.DataLoader(trainset, batch_size=<span class="number">64</span>, shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Download and load the test data</span></span><br><span class="line">testset = datasets.FashionMNIST(<span class="string">'~/.pytorch/F_MNIST_data/'</span>, download=<span class="literal">True</span>, train=<span class="literal">False</span>, transform=transform)</span><br><span class="line">testloader = torch.utils.data.DataLoader(testset, batch_size=<span class="number">64</span>, shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义网络结构</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyFashionMnist</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">    super().__init__()</span><br><span class="line">    self.fc1 = nn.Linear(<span class="number">784</span>, <span class="number">256</span>)</span><br><span class="line">    self.fc2 = nn.Linear(<span class="number">256</span>, <span class="number">64</span>)</span><br><span class="line">    self.fc3 = nn.Linear(<span class="number">64</span>, <span class="number">10</span>)</span><br><span class="line">    </span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">    x = x.view(<span class="number">-1</span>, <span class="number">784</span>)</span><br><span class="line">    x = F.relu(self.fc1(x))</span><br><span class="line">    x = F.relu(self.fc2(x))</span><br><span class="line">    x = F.log_softmax(self.fc3(x))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> x</span><br><span class="line">  </span><br><span class="line">model = MyFashionMnist()</span><br><span class="line"></span><br><span class="line">optimizer = optim.Adam(model.parameters(), lr=<span class="number">0.003</span>)</span><br><span class="line"></span><br><span class="line">criterion = nn.NLLLoss()</span><br><span class="line"></span><br><span class="line">epochs = <span class="number">20</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> e <span class="keyword">in</span> range(epochs):</span><br><span class="line">  running_loss = <span class="number">0</span> <span class="comment"># 损失</span></span><br><span class="line">  <span class="keyword">for</span> images, labels <span class="keyword">in</span> trainloader:</span><br><span class="line">    output = model(images)</span><br><span class="line">    loss = criterion(output, labels)</span><br><span class="line">    </span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br><span class="line">    </span><br><span class="line">    running_loss += loss.item()</span><br><span class="line">   </span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">    print(<span class="string">"loss: "</span>, running_loss / len(trainloader))</span><br><span class="line">    </span><br><span class="line">sum = correct = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 用测试集测试正确率</span></span><br><span class="line"><span class="keyword">for</span> images, labels <span class="keyword">in</span> testloader:</span><br><span class="line">  output = torch.exp(model(images))</span><br><span class="line">  result = torch.argmax(output, dim=<span class="number">1</span>)</span><br><span class="line">  correct += (result == labels).sum()</span><br><span class="line">  sum += len(images)</span><br><span class="line">  </span><br><span class="line">print(<span class="string">"correct = "</span>, correct.item())</span><br><span class="line">print(<span class="string">"sum = "</span>, sum)</span><br><span class="line">print(<span class="string">"rate = &#123;&#125;"</span>.format(correct.item() / sum))</span><br></pre></td></tr></table></figure>

<p>写了一份基于keras的代码做对比, 过程是类似的. 相对而言keras更黑箱所以代码短一些</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> datasets, models, layers</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">os.environ[<span class="string">'TF_CPP_MIN_LOG_LEVEL'</span>] = <span class="string">'2'</span></span><br><span class="line"></span><br><span class="line">(train_images, train_labels), (test_images, test_labels) = datasets.fashion_mnist.load_data()</span><br><span class="line">train_images = tf.reshape(train_images, [<span class="number">-1</span>, <span class="number">784</span>])</span><br><span class="line">test_images = tf.reshape(test_images, [<span class="number">-1</span>, <span class="number">784</span>])</span><br><span class="line"></span><br><span class="line">print(train_images.shape, train_labels.shape, test_images.shape, test_labels.shape)</span><br><span class="line"></span><br><span class="line">model = models.Sequential()</span><br><span class="line">model.add(layers.Dense(<span class="number">256</span>, activation=<span class="string">'relu'</span>, input_shape=(<span class="number">784</span>, )))</span><br><span class="line">model.add(layers.Dense(<span class="number">64</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">10</span>, activation=<span class="string">'softmax'</span>))</span><br><span class="line">print(<span class="string">"model build!"</span>)</span><br><span class="line"></span><br><span class="line">model.compile(optimizer=<span class="string">'rmsprop'</span>,</span><br><span class="line">              loss=<span class="string">'categorical_crossentropy'</span>,</span><br><span class="line">              metrics=[<span class="string">'accuracy'</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将训练集随机化</span></span><br><span class="line">idx = tf.range(len(train_images))</span><br><span class="line">idx = tf.random.shuffle(idx)</span><br><span class="line">print(idx)</span><br><span class="line">train_images = tf.gather(train_images, indices=idx)</span><br><span class="line"><span class="comment"># train_images = train_images[idx]</span></span><br><span class="line">train_labels = tf.gather(train_labels, indices=idx)</span><br><span class="line"><span class="comment"># train_labels = train_labels[idx]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 将label转化成one hot</span></span><br><span class="line">train_labels = tf.one_hot(train_labels, depth=<span class="number">10</span>)</span><br><span class="line">test_labels = tf.one_hot(test_labels, depth=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 划分出训练集和验证集</span></span><br><span class="line">partial_x_train = train_images[<span class="number">3000</span>:]</span><br><span class="line">x_val = train_images[:<span class="number">3000</span>]</span><br><span class="line">partial_y_train = train_labels[<span class="number">3000</span>:]</span><br><span class="line">y_val = train_labels[:<span class="number">3000</span>]</span><br><span class="line"></span><br><span class="line">print(partial_x_train.shape, partial_y_train.shape, x_val.shape, y_val.shape)</span><br><span class="line"></span><br><span class="line">history = model.fit(partial_x_train,</span><br><span class="line">                    partial_y_train,</span><br><span class="line">                    epochs=<span class="number">20</span>,</span><br><span class="line">                    batch_size=<span class="number">64</span>,</span><br><span class="line">                    validation_data=(x_val, y_val))</span><br><span class="line"></span><br><span class="line">result = model.evaluate(test_images, test_labels)</span><br></pre></td></tr></table></figure>

<p>差别是:</p>
<ol>
<li>keras的训练起来要比pytorch快得多. 不知道是不是因为keras在gpu条件满足情况下自动调用了gpu, 而pytorch用的是cpu</li>
<li>准确率用pytorch写的反而要高, 这么一个简单的网络正确率达到了86%-87%, 而反观keras的, 在和pytorch的超参数差不多的情况下, 正确率只有70%左右. 设置其他的超参数才能稍高一些</li>
</ol>
<h2 id="Part-5-Inference-and-Validation-Exercises-ipynb"><a href="#Part-5-Inference-and-Validation-Exercises-ipynb" class="headerlink" title="Part 5 - Inference and Validation (Exercises).ipynb"></a>Part 5 - Inference and Validation (Exercises).ipynb</h2><ol>
<li><p>这部分主要讲验证, 比如用topk()来衡量正确</p>
<p> 但用topk()时总是出错, 所以后面改用argmax()了</p>
</li>
<li><p>介绍了dropout的使用, 可以明显地减少过拟合. 也就是训练时的损失和验证损失差不多, 但同时训练时正确率更低一些</p>
<p> dropout也真是玄学</p>
</li>
<li><p>定义了自己的带dropout层的网络</p>
 <figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## <span class="doctag">TODO:</span> Define your model with dropout added</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn, optim</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Classifier</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">784</span>, <span class="number">256</span>)</span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">256</span>, <span class="number">128</span>)</span><br><span class="line">        self.fc3 = nn.Linear(<span class="number">128</span>, <span class="number">64</span>)</span><br><span class="line">        self.fc4 = nn.Linear(<span class="number">64</span>, <span class="number">10</span>)</span><br><span class="line">        </span><br><span class="line">        self.dropout = nn.Dropout(p=<span class="number">0.2</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="comment"># make sure input tensor is flattened</span></span><br><span class="line">        x = x.view(x.shape[<span class="number">0</span>], <span class="number">-1</span>)</span><br><span class="line">        </span><br><span class="line">        x = self.dropout(F.relu(self.fc1(x)))</span><br><span class="line">        x = self.dropout(F.relu(self.fc2(x)))</span><br><span class="line">        x = self.dropout(F.relu(self.fc3(x)))</span><br><span class="line">        x = F.log_softmax(self.fc4(x), dim=<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
</li>
<li><p>在训练时记录了各个时间点的损失, 所以用下面的代码可以轻松画出损失的变化值, 来判断是否发生过拟合</p>
 <figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">train_losses = torch.Tensor(train_losses) / len(trainloader)</span><br><span class="line">test_losses = torch.Tensor(test_losses) / len(testloader)</span><br><span class="line"></span><br><span class="line">plt.plot(train_losses.numpy(), label=<span class="string">'train_losses'</span>)</span><br><span class="line">plt.plot(test_losses.numpy(), label=<span class="string">'test_losses'</span>)</span><br><span class="line">plt.legend()</span><br></pre></td></tr></table></figure>



</li>
</ol>
<ol start="5">
<li>在验证时需要调用model.eval(), 避免验证进入dropout. 训练时要验证, 验证之后要用model.train()进入训练模式</li>
</ol>
<h2 id="Part-6-Saving-and-Loading-Models-ipynb"><a href="#Part-6-Saving-and-Loading-Models-ipynb" class="headerlink" title="Part 6 - Saving and Loading Models.ipynb"></a>Part 6 - Saving and Loading Models.ipynb</h2><p>这部分将如何保存和恢复模型, 因为这一节notebook运行较麻烦原因没有很认真去看…</p>
<h2 id="Part-7-Loading-Image-Data-Exercises-ipynb"><a href="#Part-7-Loading-Image-Data-Exercises-ipynb" class="headerlink" title="Part 7 - Loading Image Data (Exercises).ipynb"></a>Part 7 - Loading Image Data (Exercises).ipynb</h2><p>这部分讲如何从文件夹中加载数据集</p>
<ol>
<li><p>文件夹格式, 主文件夹下有多个子文件夹, 分别代表图片的类别. 可以在这两层文件夹之间加一层来区分训练集和测试集.</p>
</li>
<li><p>常规步骤:</p>
<ol>
<li><p>定义转化器transform(改变图片大小, 中心裁剪部分图片, 转化成tensor, 翻转图片等)</p>
</li>
<li><p>使用datasets.ImageFolder()方法加载数据集</p>
</li>
<li><p>使用torch.utils.data.DataLoader()方法得到生成器dataloader</p>
<p>代码实现:</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">data_dir = <span class="string">'Cat_Dog_data/train'</span></span><br><span class="line"></span><br><span class="line">transform = transforms.Compose([transforms.Resize(<span class="number">255</span>),</span><br><span class="line">                               transforms.CenterCrop(<span class="number">224</span>),</span><br><span class="line">                               transforms.ToTensor()])</span><br><span class="line"><span class="comment"># <span class="doctag">TODO:</span> compose transforms here</span></span><br><span class="line">dataset = datasets.ImageFolder(data_dir, transform=transform)</span><br><span class="line"><span class="comment"># <span class="doctag">TODO:</span> create the ImageFolder</span></span><br><span class="line">dataloader = torch.utils.data.DataLoader(dataset, batch_size=<span class="number">32</span>, shuffle=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># <span class="doctag">TODO:</span> use the ImageFolder dataset to create the DataLoader</span></span><br></pre></td></tr></table></figure>



</li>
</ol>
</li>
</ol>
<ol start="3">
<li>最后一部分是用之前所学网络结构实现猫狗分类(老师说很可能不成功, 因为之前只学了full connection net, 且只训练过MNIST这种简单的数据集, 像这种彩色的, 大图片的分类, 那些简单的网络可能效果非常不好, 所以我没尝试)</li>
</ol>
<h2 id="Part-8-Transfer-Learning-Exercises-ipynb"><a href="#Part-8-Transfer-Learning-Exercises-ipynb" class="headerlink" title="Part 8 - Transfer Learning (Exercises).ipynb"></a>Part 8 - Transfer Learning (Exercises).ipynb</h2><ol>
<li><p>这部分讲的是迁移学习, 用别人预训练好的模型就可以做好多很厉害的东西啦. 样例使用的是densenet121, 分为feature和classifier部分, 我们需要改动的是classifier部分, 从开始的ImageNet输出1000类改成2类的分类器(猫狗分类). 直观上, 感觉像是那很复杂很复杂的feature部分是将图片的特征提取出来了, 作为一个1024长度的向量是输入, 然后我们再用之前学过的知识对这个输入进行分类???</p>
</li>
<li><p>自定义classifier, 看着有点怪, 不像之前自己定义的网络</p>
 <figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Freeze parameters so we don't backprop through them</span></span><br><span class="line"><span class="keyword">for</span> param <span class="keyword">in</span> model.parameters():</span><br><span class="line">    param.requires_grad = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> OrderedDict</span><br><span class="line">classifier = nn.Sequential(OrderedDict([</span><br><span class="line">                          (<span class="string">'fc1'</span>, nn.Linear(<span class="number">1024</span>, <span class="number">500</span>)),</span><br><span class="line">                          (<span class="string">'relu'</span>, nn.ReLU()),</span><br><span class="line">                          (<span class="string">'fc2'</span>, nn.Linear(<span class="number">500</span>, <span class="number">2</span>)),</span><br><span class="line">                          (<span class="string">'output'</span>, nn.LogSoftmax(dim=<span class="number">1</span>))</span><br><span class="line">                          ]))</span><br><span class="line">    </span><br><span class="line">model.classifier = classifier</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>最后有一个自己使用预训练模型进行猫狗分类的练习, 我自己做出来正确率居然是51%(嗯, 不错, 对了一半…). 视频里讲的跟我差不多的方法是95+%的正确率. 我果然太天真. </li>
<li>不过过程就是这样了, 从torchvision.models加载某一预训练模型, 然后查看他的网络结构, 修改最后一部分(分类器), 注意freeze网络参数. 然后开始使用gpu训练(据比较gpu和cpu的训练速度是几百倍的差别, 然而在colab上进行训练即使是一个epoch也要训练几分钟的…), 这部分和普通的网络训练一样, 最后是测试(或者将验证部分嵌入到训练部分, 在训练过程中不断获悉正确率)</li>
</ol>
</li>
</ol>

      </div>
      
        <br>
        


  <section class='meta' id="footer-meta">
    <div class='new-meta-box'>
      
        
          <div class="new-meta-item date" itemprop="dateUpdated" datetime="2019-09-15T09:20:28+08:00">
  <a class='notlink'>
    <i class="fas fa-clock" aria-hidden="true"></i>
    <p>更新于 2019年9月15日</p>
  </a>
</div>

        
      
        
          
  
  <div class="new-meta-item meta-tags"><a class="tag" href="/tags/深度学习/" rel="nofollow"><i class="fas fa-tag" aria-hidden="true"></i><p>深度学习</p></a></div> <div class="new-meta-item meta-tags"><a class="tag" href="/tags/pytorch/" rel="nofollow"><i class="fas fa-tag" aria-hidden="true"></i><p>pytorch</p></a></div>


        
      
        
          
  <div class="new-meta-item share -mob-share-list">
  <div class="-mob-share-list share-body">
    
      
        <a class="-mob-share-qq" title="QQ好友" rel="external nofollow noopener noreferrer"
          
          href="http://connect.qq.com/widget/shareqq/index.html?url=https://fiveplus.top/2019/08/05/introduction-to-pytorch-bi-ji/&title=Introduction to PyTorch 笔记 | 姬小野的部落&summary="
          
          >
          
            <img src="https://cdn.jsdelivr.net/gh/xaoxuu/assets@19.1.9/logo/128/qq.png">
          
        </a>
      
    
      
        <a class="-mob-share-qzone" title="QQ空间" rel="external nofollow noopener noreferrer"
          
          href="https://sns.qzone.qq.com/cgi-bin/qzshare/cgi_qzshare_onekey?url=https://fiveplus.top/2019/08/05/introduction-to-pytorch-bi-ji/&title=Introduction to PyTorch 笔记 | 姬小野的部落&summary="
          
          >
          
            <img src="https://cdn.jsdelivr.net/gh/xaoxuu/assets@19.1.9/logo/128/qzone.png">
          
        </a>
      
    
      
        <a class="-mob-share-weibo" title="微博" rel="external nofollow noopener noreferrer"
          
          href="http://service.weibo.com/share/share.php?url=https://fiveplus.top/2019/08/05/introduction-to-pytorch-bi-ji/&title=Introduction to PyTorch 笔记 | 姬小野的部落&summary="
          
          >
          
            <img src="https://cdn.jsdelivr.net/gh/xaoxuu/assets@19.1.9/logo/128/weibo.png">
          
        </a>
      
    
  </div>
</div>



        
      
    </div>
  </section>


      
      
          <div class="prev-next">
              
                  <section class="prev">
                      <span class="art-item-left">
                          <h6><i class="fas fa-chevron-left" aria-hidden="true"></i>&nbsp;上一页</h6>
                          <h4>
                              <a href="/2019/08/14/zi-bian-ma-qi-autoencoder/" rel="prev" title="自编码器AutoEncoder">
                                
                                    自编码器AutoEncoder
                                
                              </a>
                          </h4>
                          
                              
                              <h6 class="tags">
                                  <a class="tag" href="/tags/深度学习/"><i class="fas fa-tag fa-fw" aria-hidden="true"></i> 深度学习</a>
                              </h6>
                          
                      </span>
                  </section>
              
              
                  <section class="next">
                      <span class="art-item-right" aria-hidden="true">
                          <h6>下一页&nbsp;<i class="fas fa-chevron-right" aria-hidden="true"></i></h6>
                          <h4>
                              <a href="/2019/08/05/li-yong-qian-yi-xue-xi-jin-xing-hua-de-fen-lei-github-xiang-mu-jie-shao/" rel="prev" title="利用迁移学习进行花的分类 - github项目介绍">
                                  
                                      利用迁移学习进行花的分类 - github项目介绍
                                  
                              </a>
                          </h4>
                          
                              
                              <h6 class="tags">
                                  <a class="tag" href="/tags/深度学习/"><i class="fas fa-tag fa-fw" aria-hidden="true"></i> 深度学习</a>
                              </h6>
                          
                      </span>
                  </section>
              
          </div>
      
    </section>
  </article>



  <!-- 显示推荐文章和评论 -->



  






<!-- 根据页面mathjax变量决定是否加载MathJax数学公式js -->



  <script>
    window.subData = {
      title: 'Introduction to PyTorch 笔记',
      tools: true
    }
  </script>


</div>
<aside class='l_side'>
  
    
    
      
      
        
          
          
            
              <section class='widget author'>
  <div class='content pure'>
    
      <div class='avatar'>
        <img class='avatar' src='https://cdn.jsdelivr.net/gh/xaoxuu/assets@master/avatar/avatar.png'/>
      </div>
    
    
    
      <div class="social-wrapper">
        
          
            <a href="/atom.xml"
              class="social fas fa-rss flat-btn"
              target="_blank"
              rel="external nofollow noopener noreferrer">
            </a>
          
        
          
            <a href="mailto:me@xaoxuu.com"
              class="social fas fa-envelope flat-btn"
              target="_blank"
              rel="external nofollow noopener noreferrer">
            </a>
          
        
          
            <a href="https://github.com/xaoxuu"
              class="social fab fa-github flat-btn"
              target="_blank"
              rel="external nofollow noopener noreferrer">
            </a>
          
        
          
            <a href="https://music.163.com/#/user/home?id=63035382"
              class="social fas fa-headphones-alt flat-btn"
              target="_blank"
              rel="external nofollow noopener noreferrer">
            </a>
          
        
      </div>
    
  </div>
</section>

            
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
      
        
          
          
        
          
          
            
              
  <section class='widget toc-wrapper'>
    
<header class='pure'>
  <div><i class="fas fa-list fa-fw" aria-hidden="true"></i>&nbsp;&nbsp;本文目录</div>
  
    <!-- <div class='wrapper'><a class="s-toc rightBtn" rel="external nofollow noopener noreferrer" href="javascript:void(0)"><i class="fas fa-thumbtack fa-fw"></i></a></div> -->
  
</header>

    <div class='content pure'>
      <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Introduction-to-PyTorch-笔记"><span class="toc-text">Introduction to PyTorch 笔记</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Part-1-Tensors-in-PyTorch-Solution-ipynb"><span class="toc-text">Part 1 - Tensors in PyTorch (Solution).ipynb</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Part-2-Neural-Networks-in-PyTorch-Exercises-ipynb"><span class="toc-text">Part 2 - Neural Networks in PyTorch (Exercises).ipynb</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Part-3-Training-Neural-Networks-Exercises-ipynb"><span class="toc-text">Part 3 - Training Neural Networks (Exercises).ipynb</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Part-4-Fashion-MNIST-Exercises-ipynb"><span class="toc-text">Part 4 - Fashion-MNIST (Exercises).ipynb</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Part-5-Inference-and-Validation-Exercises-ipynb"><span class="toc-text">Part 5 - Inference and Validation (Exercises).ipynb</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Part-6-Saving-and-Loading-Models-ipynb"><span class="toc-text">Part 6 - Saving and Loading Models.ipynb</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Part-7-Loading-Image-Data-Exercises-ipynb"><span class="toc-text">Part 7 - Loading Image Data (Exercises).ipynb</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Part-8-Transfer-Learning-Exercises-ipynb"><span class="toc-text">Part 8 - Transfer Learning (Exercises).ipynb</span></a></li></ol></li></ol>
    </div>
  </section>


            
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
      
        
          
          
        
          
          
        
          
          
            
              <section class='widget grid'>
  
<header class='pure'>
  <div><i class="fas fa-map-signs fa-fw" aria-hidden="true"></i>&nbsp;&nbsp;站内导航</div>
  
</header>

  <div class='content pure'>
    <ul class="grid navgation">
      
        <li><a class="flat-box" title="/" href="/"
          
          
          id="home">
          
            <i class="fas fa-clock fa-fw" aria-hidden="true"></i>
          
          近期文章
        </a></li>
      
        <li><a class="flat-box" title="/blog/archives/" href="/blog/archives/"
          
            rel="nofollow"
          
          
          id="blogarchives">
          
            <i class="fas fa-archive fa-fw" aria-hidden="true"></i>
          
          文章归档
        </a></li>
      
        <li><a class="flat-box" title="/projects/" href="/projects/"
          
          
          id="projects">
          
            <i class="fas fa-code-branch fa-fw" aria-hidden="true"></i>
          
          开源项目
        </a></li>
      
        <li><a class="flat-box" title="/friends/" href="/friends/"
          
            rel="nofollow"
          
          
          id="friends">
          
            <i class="fas fa-link fa-fw" aria-hidden="true"></i>
          
          我的友链
        </a></li>
      
        <li><a class="flat-box" title="https://xaoxuu.com/wiki/material-x/" href="https://xaoxuu.com/wiki/material-x/"
          
            rel="nofollow"
          
          
          id="https:xaoxuu.comwikimaterial-x">
          
            <i class="fas fa-book fa-fw" aria-hidden="true"></i>
          
          主题文档
        </a></li>
      
        <li><a class="flat-box" title="/about/" href="/about/"
          
            rel="nofollow"
          
          
          id="about">
          
            <i class="fas fa-info-circle fa-fw" aria-hidden="true"></i>
          
          关于小站
        </a></li>
      
    </ul>
  </div>
</section>

            
          
        
          
          
        
          
          
        
          
          
        
          
          
        
      
        
          
          
        
          
          
        
          
          
        
          
          
            
              
  <section class='widget category'>
    
<header class='pure'>
  <div><i class="fas fa-folder-open fa-fw" aria-hidden="true"></i>&nbsp;&nbsp;文章分类</div>
  
    <a class="rightBtn"
    
      rel="nofollow"
    
    
    href="/blog/categories/"
    title="blog/categories/">
    <i class="fas fa-expand-arrows-alt fa-fw"></i></a>
  
</header>

    <div class='content pure'>
      <ul class="entry">
        
          <li><a class="flat-box" title="/categories/blog/" href="/categories/blog/"><div class='name'>blog</div><div class='badge'>(1)</div></a></li>
        
          <li><a class="flat-box" title="/categories/java/" href="/categories/java/"><div class='name'>java</div><div class='badge'>(1)</div></a></li>
        
          <li><a class="flat-box" title="/categories/开发工具/" href="/categories/开发工具/"><div class='name'>开发工具</div><div class='badge'>(4)</div></a></li>
        
          <li><a class="flat-box" title="/categories/操作系统/" href="/categories/操作系统/"><div class='name'>操作系统</div><div class='badge'>(3)</div></a></li>
        
          <li><a class="flat-box" title="/categories/机器学习/" href="/categories/机器学习/"><div class='name'>机器学习</div><div class='badge'>(3)</div></a></li>
        
          <li><a class="flat-box" title="/categories/深度学习/" href="/categories/深度学习/"><div class='name'>深度学习</div><div class='badge'>(5)</div></a></li>
        
          <li><a class="flat-box" title="/categories/算法/" href="/categories/算法/"><div class='name'>算法</div><div class='badge'>(12)</div></a></li>
        
          <li><a class="flat-box" title="/categories/编译原理/" href="/categories/编译原理/"><div class='name'>编译原理</div><div class='badge'>(1)</div></a></li>
        
          <li><a class="flat-box" title="/categories/网络/" href="/categories/网络/"><div class='name'>网络</div><div class='badge'>(1)</div></a></li>
        
          <li><a class="flat-box" title="/categories/计算机系统/" href="/categories/计算机系统/"><div class='name'>计算机系统</div><div class='badge'>(2)</div></a></li>
        
          <li><a class="flat-box" title="/categories/计算机视觉/" href="/categories/计算机视觉/"><div class='name'>计算机视觉</div><div class='badge'>(1)</div></a></li>
        
      </ul>
    </div>
  </section>


            
          
        
          
          
        
          
          
        
          
          
        
      
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
            
              
  <section class='widget tagcloud'>
    
<header class='pure'>
  <div><i class="fas fa-tags fa-fw" aria-hidden="true"></i>&nbsp;&nbsp;热门标签</div>
  
    <a class="rightBtn"
    
      rel="nofollow"
    
    
    href="/blog/tags/"
    title="blog/tags/">
    <i class="fas fa-expand-arrows-alt fa-fw"></i></a>
  
</header>

    <div class='content pure'>
      <a href="/tags/Anaconda/" style="font-size: 16.5px; color: #888">Anaconda</a> <a href="/tags/Chrome/" style="font-size: 14px; color: #999">Chrome</a> <a href="/tags/blog/" style="font-size: 14px; color: #999">blog</a> <a href="/tags/csapp/" style="font-size: 14px; color: #999">csapp</a> <a href="/tags/gdb/" style="font-size: 14px; color: #999">gdb</a> <a href="/tags/idea/" style="font-size: 14px; color: #999">idea</a> <a href="/tags/java/" style="font-size: 14px; color: #999">java</a> <a href="/tags/opencv/" style="font-size: 14px; color: #999">opencv</a> <a href="/tags/pytorch/" style="font-size: 14px; color: #999">pytorch</a> <a href="/tags/ubuntu/" style="font-size: 19px; color: #777">ubuntu</a> <a href="/tags/v2ray/" style="font-size: 14px; color: #999">v2ray</a> <a href="/tags/人脸识别/" style="font-size: 16.5px; color: #888">人脸识别</a> <a href="/tags/开发工具/" style="font-size: 16.5px; color: #888">开发工具</a> <a href="/tags/开源库/" style="font-size: 21.5px; color: #666">开源库</a> <a href="/tags/操作系统/" style="font-size: 14px; color: #999">操作系统</a> <a href="/tags/数学/" style="font-size: 14px; color: #999">数学</a> <a href="/tags/数据库/" style="font-size: 14px; color: #999">数据库</a> <a href="/tags/机器学习/" style="font-size: 19px; color: #777">机器学习</a> <a href="/tags/汇编/" style="font-size: 14px; color: #999">汇编</a> <a href="/tags/深度学习/" style="font-size: 21.5px; color: #666">深度学习</a> <a href="/tags/目标检测/" style="font-size: 14px; color: #999">目标检测</a> <a href="/tags/科学上网/" style="font-size: 14px; color: #999">科学上网</a> <a href="/tags/算法/" style="font-size: 24px; color: #555">算法</a> <a href="/tags/编译原理/" style="font-size: 14px; color: #999">编译原理</a> <a href="/tags/随机树/" style="font-size: 14px; color: #999">随机树</a>
    </div>
  </section>


            
          
        
          
          
        
          
          
        
      
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
            
              <section class='widget list'>
  
<header class='pure'>
  <div><i class="fas fa-thumbs-up fa-fw" aria-hidden="true"></i>&nbsp;&nbsp;强烈推荐</div>
  
</header>

  <div class='content pure'>
    <ul class="entry">
      
        <li><a class="flat-box" title="https://xaoxuu.com/wiki/hexo.sh/" href="https://xaoxuu.com/wiki/hexo.sh/"
          
          
          >
          <div class='name'>
            
              <i class=" fa-fw" aria-hidden="true"></i>
            
            &nbsp;&nbsp;Hexo脚本（Mac）
          </div>
          
        </a></li>
      
        <li><a class="flat-box" title="https://xaoxuu.com/wiki/vim-cn.sh/" href="https://xaoxuu.com/wiki/vim-cn.sh/"
          
          
          >
          <div class='name'>
            
              <i class=" fa-fw" aria-hidden="true"></i>
            
            &nbsp;&nbsp;图床脚本（Mac）
          </div>
          
        </a></li>
      
        <li><a class="flat-box" title="https://yasuotu.com" href="https://yasuotu.com"
          
          
          >
          <div class='name'>
            
              <i class=" fa-fw" aria-hidden="true"></i>
            
            &nbsp;&nbsp;图片在线压缩
          </div>
          
        </a></li>
      
        <li><a class="flat-box" title="https://realfavicongenerator.net" href="https://realfavicongenerator.net"
          
          
          >
          <div class='name'>
            
              <i class=" fa-fw" aria-hidden="true"></i>
            
            &nbsp;&nbsp;生成Favicon
          </div>
          
        </a></li>
      
        <li><a class="flat-box" title="https://mxclub.github.io/resume/" href="https://mxclub.github.io/resume/"
          
          
          >
          <div class='name'>
            
              <i class=" fa-fw" aria-hidden="true"></i>
            
            &nbsp;&nbsp;简历主题
          </div>
          
        </a></li>
      
    </ul>
  </div>
</section>

            
          
        
      
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
      
    

  
</aside>

<footer id="footer" class="clearfix">
  
  
    <div class="social-wrapper">
      
        
          <a href="/atom.xml"
            class="social fas fa-rss flat-btn"
            target="_blank"
            rel="external nofollow noopener noreferrer">
          </a>
        
      
        
          <a href="mailto:me@xaoxuu.com"
            class="social fas fa-envelope flat-btn"
            target="_blank"
            rel="external nofollow noopener noreferrer">
          </a>
        
      
        
          <a href="https://github.com/xaoxuu"
            class="social fab fa-github flat-btn"
            target="_blank"
            rel="external nofollow noopener noreferrer">
          </a>
        
      
        
          <a href="https://music.163.com/#/user/home?id=63035382"
            class="social fas fa-headphones-alt flat-btn"
            target="_blank"
            rel="external nofollow noopener noreferrer">
          </a>
        
      
    </div>
  
  <br>
  <div><p>博客内容遵循 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh">署名-非商业性使用-相同方式共享 4.0 国际 (CC BY-NC-SA 4.0) 协议</a></p>
</div>
  <div>
    本站使用
    <a href="https://xaoxuu.com/wiki/material-x/" target="_blank" class="codename">Material X</a>
    作为主题
    
      ，
      总访问量为
      <span id="busuanzi_value_site_pv"><i class="fas fa-spinner fa-spin fa-fw" aria-hidden="true"></i></span>
      次
    
    。
  </div>
</footer>
<script>setLoadingBarProgress(80);</script>


      <script>setLoadingBarProgress(60);</script>
    </div>
    <a class="s-top fas fa-arrow-up fa-fw" href='javascript:void(0)'></a>
  </div>
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script>

  <script>
    var GOOGLE_CUSTOM_SEARCH_API_KEY = "";
    var GOOGLE_CUSTOM_SEARCH_ENGINE_ID = "";
    var ALGOLIA_API_KEY = "";
    var ALGOLIA_APP_ID = "";
    var ALGOLIA_INDEX_NAME = "";
    var AZURE_SERVICE_NAME = "";
    var AZURE_INDEX_NAME = "";
    var AZURE_QUERY_KEY = "";
    var BAIDU_API_ID = "";
    var SEARCH_SERVICE = "hexo" || "hexo";
    var ROOT = "/"||"/";
    if(!ROOT.endsWith('/'))ROOT += '/';
  </script>

<script src="//instant.page/1.2.2" type="module" integrity="sha384-2xV8M5griQmzyiY3CDqh1dn4z3llDVqZDqzjzcY+jCBCk/a5fXJmuZ/40JJAPeoU"></script>


  <script async src="https://cdn.jsdelivr.net/npm/scrollreveal@4.0.5/dist/scrollreveal.min.js"></script>
  <script type="text/javascript">
    $(function() {
      const $reveal = $('.reveal');
      if ($reveal.length === 0) return;
      const sr = ScrollReveal({ distance: 0 });
      sr.reveal('.reveal');
    });
  </script>


  <script src="https://cdn.jsdelivr.net/npm/node-waves@0.7.6/dist/waves.min.js"></script>
  <script type="text/javascript">
    $(function() {
      Waves.attach('.flat-btn', ['waves-button']);
      Waves.attach('.float-btn', ['waves-button', 'waves-float']);
      Waves.attach('.float-btn-light', ['waves-button', 'waves-float', 'waves-light']);
      Waves.attach('.flat-box', ['waves-block']);
      Waves.attach('.float-box', ['waves-block', 'waves-float']);
      Waves.attach('.waves-image');
      Waves.init();
    });
  </script>


  <script async src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-busuanzi@2.3/js/busuanzi.pure.mini.js"></script>




  
  
  
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-backstretch/2.0.4/jquery.backstretch.min.js"></script>
    <script type="text/javascript">
      $(function(){
        if ('.cover') {
          $('.cover').backstretch(
          ["https://img.vim-cn.com/29/91197b04c13f512f734a76d4ac422d89dbe229.jpg"],
          {
            duration: "6000",
            fade: "2500"
          });
        } else {
          $.backstretch(
          ["https://img.vim-cn.com/29/91197b04c13f512f734a76d4ac422d89dbe229.jpg"],
          {
            duration: "6000",
            fade: "2500"
          });
        }
      });
    </script>
  











  <script src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-material-x@19.9/js/app.js"></script>


  <script src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-material-x@19.9/js/search.js"></script>




<!-- 复制 -->
<script src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js"></script>
<script>
  let COPY_SUCCESS = "复制成功";
  let COPY_FAILURE = "复制失败";
  /*页面载入完成后，创建复制按钮*/
  !function (e, t, a) {
    /* code */
    var initCopyCode = function(){
      var copyHtml = '';
      copyHtml += '<button class="btn-copy" data-clipboard-snippet="">';
      copyHtml += '  <i class="fa fa-copy"></i><span>复制</span>';
      copyHtml += '</button>';
      $(".highlight .code pre").before(copyHtml);
      var clipboard = new ClipboardJS('.btn-copy', {
        target: function(trigger) {
          return trigger.nextElementSibling;
        }
      });

      clipboard.on('success', function(e) {
        //您可以加入成功提示
        console.info('Action:', e.action);
        console.info('Text:', e.text);
        console.info('Trigger:', e.trigger);
        success_prompt(COPY_SUCCESS);
        e.clearSelection();
      });
      clipboard.on('error', function(e) {
        //您可以加入失败提示
        console.error('Action:', e.action);
        console.error('Trigger:', e.trigger);
        fail_prompt(COPY_FAILURE);
      });
    }
    initCopyCode();

  }(window, document);

  /**
   * 弹出式提示框，默认1.5秒自动消失
   * @param message 提示信息
   * @param style 提示样式，有alert-success、alert-danger、alert-warning、alert-info
   * @param time 消失时间
   */
  var prompt = function (message, style, time)
  {
      style = (style === undefined) ? 'alert-success' : style;
      time = (time === undefined) ? 1500 : time*1000;
      $('<div>')
          .appendTo('body')
          .addClass('alert ' + style)
          .html(message)
          .show()
          .delay(time)
          .fadeOut();
  };

  // 成功提示
  var success_prompt = function(message, time)
  {
      prompt(message, 'alert-success', time);
  };

  // 失败提示
  var fail_prompt = function(message, time)
  {
      prompt(message, 'alert-danger', time);
  };

  // 提醒
  var warning_prompt = function(message, time)
  {
      prompt(message, 'alert-warning', time);
  };

  // 信息提示
  var info_prompt = function(message, time)
  {
      prompt(message, 'alert-info', time);
  };

</script>


<!-- fancybox -->
<script src="https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js"></script>
<script>
  let LAZY_LOAD_IMAGE = "";
  $(".article-entry").find("fancybox").find("img").each(function () {
      var element = document.createElement("a");
      $(element).attr("data-fancybox", "gallery");
      $(element).attr("href", $(this).attr("src"));
      /* 图片采用懒加载处理时,
       * 一般图片标签内会有个属性名来存放图片的真实地址，比如 data-original,
       * 那么此处将原本的属性名src替换为对应属性名data-original,
       * 修改如下
       */
       if (LAZY_LOAD_IMAGE) {
         $(element).attr("href", $(this).attr("data-original"));
       }
      $(this).wrap(element);
  });
</script>





  <script>setLoadingBarProgress(100);</script>
</body>
</html>
