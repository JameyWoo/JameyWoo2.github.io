{"meta":{"title":"姬小野的部落","subtitle":"曾梦想仗剑走天涯","description":"湖南大学 | 计算机科学与技术","author":"姬小野","url":"https://fiveplus.top","root":"/"},"pages":[{"title":"404","date":"2019-07-19T08:41:10.000Z","updated":"2019-08-11T08:46:53.000Z","comments":true,"path":"404.html","permalink":"https://fiveplus.top/404.html","excerpt":"","text":""},{"title":"archives","date":"2019-07-19T08:39:20.000Z","updated":"2019-08-11T08:46:53.000Z","comments":true,"path":"archives/index.html","permalink":"https://fiveplus.top/archives/index.html","excerpt":"","text":""},{"title":"about","date":"2019-08-15T04:18:10.000Z","updated":"2019-09-14T16:04:36.427Z","comments":true,"path":"about/index.html","permalink":"https://fiveplus.top/about/index.html","excerpt":"","text":"教育经历湖南大学本科 项目经历 呵呵 哈哈 吼吼 所获奖项无"},{"title":"categories","date":"2019-07-19T08:39:20.000Z","updated":"2019-08-11T08:46:53.000Z","comments":true,"path":"categories/index.html","permalink":"https://fiveplus.top/categories/index.html","excerpt":"","text":""},{"title":"contact","date":"2019-07-26T09:17:02.000Z","updated":"2019-08-11T08:46:53.000Z","comments":true,"path":"contact/index.html","permalink":"https://fiveplus.top/contact/index.html","excerpt":"","text":""},{"title":"friends","date":"2019-07-19T08:42:10.000Z","updated":"2019-08-11T08:46:53.000Z","comments":true,"path":"friends/index.html","permalink":"https://fiveplus.top/friends/index.html","excerpt":"","text":""},{"title":"pages","date":"2019-09-15T04:18:10.000Z","updated":"2019-09-15T02:36:34.841Z","comments":true,"path":"pages/index.html","permalink":"https://fiveplus.top/pages/index.html","excerpt":"","text":"一个测试page"},{"title":"我的简历","date":"2019-08-15T04:18:10.000Z","updated":"2019-09-15T02:43:18.430Z","comments":true,"path":"resume/index.html","permalink":"https://fiveplus.top/resume/index.html","excerpt":"","text":"教育经历湖南大学本科 项目经历 呵呵 哈哈 吼吼 所获奖项无"},{"title":"tags","date":"2019-07-19T08:40:27.000Z","updated":"2019-08-11T08:46:53.000Z","comments":true,"path":"tags/index.html","permalink":"https://fiveplus.top/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"正则表达式转化为DFA状态图","slug":"正则表达式转化为DFA状态图","date":"2019-11-02T09:48:59.000Z","updated":"2019-11-22T16:35:33.622Z","comments":true,"path":"2019/11/02/zheng-ze-biao-da-shi-zhuan-hua-wei-dfa-zhuang-tai-tu/","link":"","permalink":"https://fiveplus.top/2019/11/02/zheng-ze-biao-da-shi-zhuan-hua-wei-dfa-zhuang-tai-tu/","excerpt":"","text":"话不多说, 这是一个将正则表达式转化为DFA状态图的小工具, 是在做编译原理实验的时候在基础实验之上进行扩展的. demo: ./main -r “(a|b)*a” -o test.png 下面是文档和链接, 欢迎 star哦. 在线文档@author 姬小野 点击查看文档与Demo Github地址 项目依赖此项目的图片生成部分依赖于项目 graphviz, 这是他们的主页 致谢~ 如何安装 graphviz 可以参考这篇文章 致谢~ 请安装好graphviz并配置好环境变量之后再使用本程序的画图功能. 字符串匹配功能不受影响 配置好环境的标志是终端命令dot --version 或者 circo --version 能正确执行.确认操作无误可重启电脑再尝试 程序结构在工程根目录下, 执行 make 编译程序, 可得到目标文件 main.exe tmp 文件夹为临时文件, 保存了中间过程产生的nfa, dfa以及dot文件. image 文件夹为图片文件夹, 保存了生成的图片 如果出现make时无法识别.o文件的情况, 可以尝试make -f Makefile-win 正则表达式支持支持以下简单规则 123456( )*+[]a-z| 如 [0-9a-zA-Z]+@(gmail|qq|163).com 注意: 输入字符过多时比如上面的re请不要开启 -g 的 d 参数. 因为边和点太多无法绘制出来. 注意, 默认不适用-g是会绘制三种图片的. 所以这种情况需要指定-g m 或者 -g nm才会正确执行程序. 不然会一直尝试绘制nfa图 参数解析执行 make 得到目标程序 输入 ./main -h 得到参数提示 1234567891011121314151617181920212223242526272829Usage: ./main [options hir:s:o:p:g:] [:argument]options: -h 说明: 打印提示信息并退出程序 -i 说明: 手动输入正则表达式 和 待匹配字符串 -r &lt;re_exp&gt; 说明: 作为模式的正则表达式 -s &lt;string&gt; 说明: 待匹配的字符串 -o &lt;png_file&gt; 说明: 要输出的png文件路径 -p &lt;pattern_name&gt; 说明: 输出的状态图要布局的模式: circo | dot | neato | twopi | fdp | patchwork -g &lt;graph_type&gt; 说明: 要画的状态图的类型, 默认为三个类型: n | d | m, 可连起来写成字符串如 nm. 他们分别为 nfa | dfa | mindfademos: ./main -i 说明: 手动输入正则表达式 和 待匹配字符串, 程序打印匹配结果 ./main -r \"(ab*|b)*ca*\" -s aabbacaa 说明: 用正则表达式 (ab*|b)*ca* 去匹配字符串 aabbacaa ./main -r \"(ab*|b)*ca*\" -o test.png 说明: 将 正则表达式 (ab*|b)*ca* 转化到 test_nfa.png, test_dfa.png, test_mindfa.png 系列图片 ./main -r \"(ab*|b)*ca*\" -o test.png -p dot 说明: 用 dot模式 生成状态图 ./main -r \"(ab*|b)*ca*\" -o test.png -p dot -g nm 说明: 指定生成 nfa 和 mindfa 状态图good luck!","categories":[{"name":"编译原理","slug":"编译原理","permalink":"https://fiveplus.top/categories/编译原理/"}],"tags":[{"name":"编译原理","slug":"编译原理","permalink":"https://fiveplus.top/tags/编译原理/"}]},{"title":"自编码器AutoEncoder","slug":"自编码器AutoEncoder","date":"2019-08-14T01:25:00.000Z","updated":"2019-11-22T16:31:59.060Z","comments":true,"path":"2019/08/14/zi-bian-ma-qi-autoencoder/","link":"","permalink":"https://fiveplus.top/2019/08/14/zi-bian-ma-qi-autoencoder/","excerpt":"","text":"一. 什么是自编码器自动编码器 autoencoder, 简单表现编码器为将一组数据进行压缩编码(降维), 解码器将这组数据恢复成高维的数据. 这种编码和解码的过程不是无损的, 因此最终的输出和输入是有一些差异的, 且非常依赖于训练的数据集. 如图所示 如上面这张图所示, 对于一个简单的三层线性神经网络组成的自编码器, 我们在进行神经网络的搭建过程中, 将(input, hidden) 这个过程叫做编码器, 将(hidden, output) 这个过程叫做解码器. 对于mnist数据集而言, 它的维度变化是 784 -&gt; x -&gt; 784, 其中, x &lt; 784, 是编码的维度. 二. 有什么作用1) 图像去噪看上去很强啊 2) 可视化降维 三. 如何实现训练神经网络需要定义损失函数, 那么这个自编码器的损失衡量值是什么? 衡量损失的值是由网络的输出结果和输入决定的. 也就是说, 是由这两个784维数据的差别决定的. 1) 全连接层实现首先定义一个神经网络 12345678910111213141516171819202122class Autoencoder(nn.Module): def __init__(self, encoding_dim): super(Autoencoder, self).__init__() ## encoder ## self.encoder = nn.Linear(784, encoding_dim) ## decoder ## self.decoder = nn.Linear(encoding_dim, 784) def forward(self, x): # define feedforward behavior # and scale the *output* layer with a sigmoid activation function# print(x.shape) x = x.view(-1, 784) x = F.relu(self.encoder(x)) x = torch.sigmoid(self.decoder(x)) return x# initialize the NNencoding_dim = 128model = Autoencoder(encoding_dim) 定义损失函数和优化器 12345# specify loss functioncriterion = nn.MSELoss()# specify loss functionoptimizer = torch.optim.Adam(model.parameters(), lr=0.001) 训练过程, 一共20个epochs, 话说pytorch还真慢, 这么简单的网络都要训练好一会 1234567891011121314151617181920212223242526272829303132333435# number of epochs to train the modeln_epochs = 20for epoch in range(1, n_epochs+1): # monitor training loss train_loss = 0.0 ################### # train the model # ################### for data in train_loader: # _ stands in for labels, here images, _ = data # flatten images images = images.view(images.size(0), -1) # clear the gradients of all optimized variables optimizer.zero_grad() # forward pass: compute predicted outputs by passing inputs to the model# print(images.shape) outputs = model(images) # calculate the loss loss = criterion(outputs, images) # backward pass: compute gradient of the loss with respect to model parameters loss.backward() # perform a single optimization step (parameter update) optimizer.step() # update running training loss train_loss += loss.item()*images.size(0) # print avg training statistics train_loss = train_loss/len(train_loader) print('Epoch: &#123;&#125; \\tTraining Loss: &#123;:.6f&#125;'.format( epoch, train_loss )) 训练过程的损失变化 1234567891011121314151617181920Epoch: 1 Training Loss: 0.342308Epoch: 2 Training Loss: 0.081272Epoch: 3 Training Loss: 0.058724Epoch: 4 Training Loss: 0.051274Epoch: 5 Training Loss: 0.047382Epoch: 6 Training Loss: 0.044760Epoch: 7 Training Loss: 0.043184Epoch: 8 Training Loss: 0.042066Epoch: 9 Training Loss: 0.041246Epoch: 10 Training Loss: 0.040589Epoch: 11 Training Loss: 0.040059Epoch: 12 Training Loss: 0.039646Epoch: 13 Training Loss: 0.039272Epoch: 14 Training Loss: 0.038980Epoch: 15 Training Loss: 0.038733Epoch: 16 Training Loss: 0.038524Epoch: 17 Training Loss: 0.038328Epoch: 18 Training Loss: 0.038162Epoch: 19 Training Loss: 0.038012Epoch: 20 Training Loss: 0.037874 那么效果如何呢? 上面一排是输入图像, 下面一排是输出图像. 经过自编码器之后, 还原度还是很高的. 2) 测试: 对有噪声图像的自编码首先查看一张图片 123456a_img = np.squeeze(images[0])print(a_img.shape)print(np.max(a_img))print(np.min(a_img))plt.imshow(a_img, cmap='gray') 然后向其中加入噪声 123a_img_x = a_img + 0.08 * np.random.normal(loc=0.0, scale=1.0, size=a_img.shape)plt.imshow(a_img_x, cmap='gray') 这是加入噪声之后的图片, 可以看出差别还是很大的. 那么我们的编码器能还原出如何的效果呢? 1234567a_img_output = model(torch.Tensor(a_img_x).view(1, -1))print(a_img_output.shape)output_img = a_img_output.view(28, 28)output_img = output_img.detach().numpy()plt.imshow(output_img, cmap='gray') 这是还原后的, 说实话看到这个图片我心里也是很惊讶的. 就在于加入那么多噪声之后, 居然还可以还原的如此清晰. 当然这是对于MNIST数据集而言, 这个数据集比较简单. 3) 卷积层实现不同之处在于定义自编码器的神经网络结构如图所示可以看到在decoder中经过了两个反卷积层, 但是由于水平有限, 这个反卷积层看着好奇怪, 不知道是怎么反卷积的. pytorch实现 1234567891011121314151617181920212223242526272829303132333435363738import torch.nn as nnimport torch.nn.functional as F# define the NN architectureclass ConvAutoencoder(nn.Module): def __init__(self): super(ConvAutoencoder, self).__init__() ## encoder layers ## self.conv1 = nn.Conv2d(1, 16, 3, padding=1) self.conv2 = nn.Conv2d(16, 4, 3, padding=1) self.pool = nn.MaxPool2d(2, 2) ## decoder layers ## ## a kernel of 2 and a stride of 2 will increase the spatial dims by 2 self.t_conv1 = nn.ConvTranspose2d(4, 16, 2, stride=2) self.t_conv2 = nn.ConvTranspose2d(16, 1, 2, stride=2) def forward(self, x): ## encode ## ## decode ## ## apply ReLu to all hidden layers *except for the output layer ## apply a sigmoid to the output layer x = F.relu(self.conv1(x)) x = self.pool(x) x = F.relu(self.conv2(x)) x = self.pool(x) x = F.relu(self.t_conv1(x)) x = torch.sigmoid(self.t_conv2(x)) return x# initialize the NNmodel = ConvAutoencoder()print(model) 训练起来比全连接层的网络还要慢很多, 而损失值的降低也慢很多, 不像之前从epoch 1 到 epoch 2 直接就断崖式下跌了. 下面是损失值的变化过程, 只训练了 15个epoch. 从损失之上看这个效果好像差很多? 123456789101112131415Epoch: 1 Training Loss: 0.448799Epoch: 2 Training Loss: 0.266815Epoch: 3 Training Loss: 0.251290Epoch: 4 Training Loss: 0.240823Epoch: 5 Training Loss: 0.231836Epoch: 6 Training Loss: 0.220550Epoch: 7 Training Loss: 0.210341Epoch: 8 Training Loss: 0.202768Epoch: 9 Training Loss: 0.197010Epoch: 10 Training Loss: 0.193259Epoch: 11 Training Loss: 0.190589Epoch: 12 Training Loss: 0.188406Epoch: 13 Training Loss: 0.186529Epoch: 14 Training Loss: 0.184983Epoch: 15 Training Loss: 0.183579 观察下图的数字9的话, 可以看到损失了不少. 再看看噪声图片的处理能力如何 原图:加入噪声:经过自编码器呃, 效果似乎有点不是很对, 可能是训练的epoch太少了, 毕竟我们可以前面看到训练15个epoch的损失值还是达到了0.18, 而在全连接层的简单自编码器上第二个epoch的损失值就达到了0.08 四. 一些小细节 numpy 的 squeeze 函数参考博客作用：从数组的形状中删除单维度条目，即把shape中为1的维度去掉 给MNIST图片加入噪声的方法 1test_img_x = test_img + 0.08 * np.random.normal(loc=0.0, scale=1.0, size=test_img.shape) 就是加入一些随机值, 在原图的基础上进行小幅度修改.","categories":[{"name":"深度学习","slug":"深度学习","permalink":"https://fiveplus.top/categories/深度学习/"}],"tags":[{"name":"深度学习","slug":"深度学习","permalink":"https://fiveplus.top/tags/深度学习/"}],"author":"姬小野"},{"title":"Introduction to PyTorch 笔记","slug":"Introduction to PyTorch 笔记","date":"2019-08-05T14:28:00.000Z","updated":"2019-09-15T01:20:28.958Z","comments":true,"path":"2019/08/05/introduction-to-pytorch-bi-ji/","link":"","permalink":"https://fiveplus.top/2019/08/05/introduction-to-pytorch-bi-ji/","excerpt":"","text":"Introduction to PyTorch 笔记Part 1 - Tensors in PyTorch (Solution).ipynb 最基本的神经网络, 使用矩阵计算. 激活函数, sigmoid, softmax, relu等 使用pytorch生成随机数(用来初始化weights). 似乎用不同的norm函数影响较大 介绍了前向传播的实现方式, 矩阵相乘 + 偏置 矩阵改变形状, 从numpy转化来/去 Part 2 - Neural Networks in PyTorch (Exercises).ipynb 加载MNIST数据集, 设置是训练或者测试, 用DataLoader进行分批加载, 可设置随机化 使用了transforms转换器转换数据, 比如归一化, 转化为tensor, 改变图片大小等 123456train_transforms = transforms.Compose([transforms.RandomRotation(30), transforms.RandomResizedCrop(224), transforms.RandomHorizontalFlip(), transforms.ToTensor(), transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])]) 练习自定义网络权重, 并实现网络的前向传播 自己用pytorch实现了softmax. 使用sum, argmax等函数需要注意设置dim 12def softmax(x): return torch.exp(out) / torch.exp(out).sum(dim=1).view(64, 1) 自定义网络结构(class方式), 继承自nn.Module. 自定义层次, 激活函数等, 实现init, forward函数 123456789101112131415161718192021class Network(nn.Module): def __init__(self): super().__init__() # Inputs to hidden layer linear transformation self.hidden = nn.Linear(784, 256) # Output layer, 10 units - one for each digit self.output = nn.Linear(256, 10) # Define sigmoid activation and softmax output self.sigmoid = nn.Sigmoid() self.softmax = nn.Softmax(dim=1) def forward(self, x): # Pass the input tensor through each of our operations x = self.hidden(x) x = self.sigmoid(x) x = self.output(x) x = self.softmax(x) return x 有model对象, 可方便地查看模型的权重, 偏置值, 还可以进行更改, 如使用随机值 使用nn.Sequential()搭建网络, 和之前其实类似 123456model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]), nn.ReLU(), nn.Linear(hidden_sizes[0], hidden_sizes[1]), nn.ReLU(), nn.Linear(hidden_sizes[1], output_size), nn.Softmax(dim=1)) 多次出现helper辅助代码, 实现一些功能, 如下所示 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394import matplotlib.pyplot as pltimport numpy as npfrom torch import nn, optimfrom torch.autograd import Variabledef test_network(net, trainloader): criterion = nn.MSELoss() optimizer = optim.Adam(net.parameters(), lr=0.001) dataiter = iter(trainloader) images, labels = dataiter.next() # Create Variables for the inputs and targets inputs = Variable(images) targets = Variable(images) # Clear the gradients from all Variables optimizer.zero_grad() # Forward pass, then backward pass, then update weights output = net.forward(inputs) loss = criterion(output, targets) loss.backward() optimizer.step() return Truedef imshow(image, ax=None, title=None, normalize=True): \"\"\"Imshow for Tensor.\"\"\" if ax is None: fig, ax = plt.subplots() image = image.numpy().transpose((1, 2, 0)) if normalize: mean = np.array([0.485, 0.456, 0.406]) std = np.array([0.229, 0.224, 0.225]) image = std * image + mean image = np.clip(image, 0, 1) ax.imshow(image) ax.spines['top'].set_visible(False) ax.spines['right'].set_visible(False) ax.spines['left'].set_visible(False) ax.spines['bottom'].set_visible(False) ax.tick_params(axis='both', length=0) ax.set_xticklabels('') ax.set_yticklabels('') return axdef view_recon(img, recon): ''' Function for displaying an image (as a PyTorch Tensor) and its reconstruction also a PyTorch Tensor ''' fig, axes = plt.subplots(ncols=2, sharex=True, sharey=True) axes[0].imshow(img.numpy().squeeze()) axes[1].imshow(recon.data.numpy().squeeze()) for ax in axes: ax.axis('off') ax.set_adjustable('box-forced')def view_classify(img, ps, version=\"MNIST\"): ''' Function for viewing an image and it's predicted classes. ''' ps = ps.data.numpy().squeeze() fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2) ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze()) ax1.axis('off') ax2.barh(np.arange(10), ps) ax2.set_aspect(0.1) ax2.set_yticks(np.arange(10)) if version == \"MNIST\": ax2.set_yticklabels(np.arange(10)) elif version == \"Fashion\": ax2.set_yticklabels(['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot'], size='small'); ax2.set_title('Class Probability') ax2.set_xlim(0, 1.1) plt.tight_layout() Part 3 - Training Neural Networks (Exercises).ipynb 梯度下降与反向传播. 反向传播算法是求导过程中链式法则的应用 $$ \\large \\frac{\\partial \\ell}{\\partial W_1} = \\frac{\\partial L_1}{\\partial W_1} \\frac{\\partial S}{\\partial L_1} \\frac{\\partial L_2}{\\partial S} \\frac{\\partial \\ell}{\\partial L_2} $$ $$\\large W^\\prime_1 = W_1 - \\alpha \\frac{\\partial \\ell}{\\partial W_1}$$ 通常会导入的包 1234import torchfrom torch import nnimport torch.nn.functional as Ffrom torchvision import datasets, transforms 介绍了损失函数. 比如交叉熵nn.CrossEntropyLoss(), 一般赋值给criterion 还有比如nn.NLLLoss() 介绍了自动求导autograd, 调用.backward()可查看导数 介绍了optimizer, 在torch.optim中. 有SGD(随机梯度下降等). Adam更好. 1234from torch import optim# Optimizers require the parameters to optimize and a learning rateoptimizer = optim.SGD(model.parameters(), lr=0.01) 训练中记得清零梯度optimizer.zero_grad() optimizer调用step()方法更新模型的权重 一个较完整的训练过程 123456789101112131415161718192021222324252627282930313233## Your solution heremodel = nn.Sequential(nn.Linear(784, 128), nn.ReLU(), nn.Linear(128, 64), nn.ReLU(), nn.Linear(64, 10), nn.LogSoftmax(dim=1))criterion = nn.NLLLoss()optimizer = optim.SGD(model.parameters(), lr=0.003)epochs = 5for e in range(epochs): running_loss = 0 for images, labels in trainloader: # Flatten MNIST images into a 784 long vector images = images.view(images.shape[0], -1) # TODO: Training pass optimizer.zero_grad() output = model.forward(images)# print(output.shape)# print(labels.shape) loss = criterion(output, labels) running_loss += loss.item() loss.backward() optimizer.step() else: print(f\"Training loss: &#123;running_loss/len(trainloader)&#125;\") Part 4 - Fashion-MNIST (Exercises).ipynb使用pytorch对数据集Fashion-MNIST进行分类的练习, 有如下过程 导入必要的库 导入数据集并格式化 定义网络结构 定义optimizer, loss函数等 开始训练, 分epoch和batch 前向传播后计算损失函数, 求梯度, 反向传播更新权重 训练结束, 输出正确率, 损失值等等 完整代码如下 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869import torchimport torch.nn.functional as Ffrom torch import nn, optimfrom torchvision import datasets, transforms# Define a transform to normalize the datatransform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])# Download and load the training datatrainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=True, transform=transform)trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)# Download and load the test datatestset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=False, transform=transform)testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)# 定义网络结构class MyFashionMnist(nn.Module): def __init__(self): super().__init__() self.fc1 = nn.Linear(784, 256) self.fc2 = nn.Linear(256, 64) self.fc3 = nn.Linear(64, 10) def forward(self, x): x = x.view(-1, 784) x = F.relu(self.fc1(x)) x = F.relu(self.fc2(x)) x = F.log_softmax(self.fc3(x)) return x model = MyFashionMnist()optimizer = optim.Adam(model.parameters(), lr=0.003)criterion = nn.NLLLoss()epochs = 20for e in range(epochs): running_loss = 0 # 损失 for images, labels in trainloader: output = model(images) loss = criterion(output, labels) optimizer.zero_grad() loss.backward() optimizer.step() running_loss += loss.item() else: print(\"loss: \", running_loss / len(trainloader)) sum = correct = 0# 用测试集测试正确率for images, labels in testloader: output = torch.exp(model(images)) result = torch.argmax(output, dim=1) correct += (result == labels).sum() sum += len(images) print(\"correct = \", correct.item())print(\"sum = \", sum)print(\"rate = &#123;&#125;\".format(correct.item() / sum)) 写了一份基于keras的代码做对比, 过程是类似的. 相对而言keras更黑箱所以代码短一些 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950import tensorflow as tffrom tensorflow.keras import datasets, models, layersimport osos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'(train_images, train_labels), (test_images, test_labels) = datasets.fashion_mnist.load_data()train_images = tf.reshape(train_images, [-1, 784])test_images = tf.reshape(test_images, [-1, 784])print(train_images.shape, train_labels.shape, test_images.shape, test_labels.shape)model = models.Sequential()model.add(layers.Dense(256, activation='relu', input_shape=(784, )))model.add(layers.Dense(64, activation='relu'))model.add(layers.Dense(10, activation='softmax'))print(\"model build!\")model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])# 将训练集随机化idx = tf.range(len(train_images))idx = tf.random.shuffle(idx)print(idx)train_images = tf.gather(train_images, indices=idx)# train_images = train_images[idx]train_labels = tf.gather(train_labels, indices=idx)# train_labels = train_labels[idx]# 将label转化成one hottrain_labels = tf.one_hot(train_labels, depth=10)test_labels = tf.one_hot(test_labels, depth=10)# 划分出训练集和验证集partial_x_train = train_images[3000:]x_val = train_images[:3000]partial_y_train = train_labels[3000:]y_val = train_labels[:3000]print(partial_x_train.shape, partial_y_train.shape, x_val.shape, y_val.shape)history = model.fit(partial_x_train, partial_y_train, epochs=20, batch_size=64, validation_data=(x_val, y_val))result = model.evaluate(test_images, test_labels) 差别是: keras的训练起来要比pytorch快得多. 不知道是不是因为keras在gpu条件满足情况下自动调用了gpu, 而pytorch用的是cpu 准确率用pytorch写的反而要高, 这么一个简单的网络正确率达到了86%-87%, 而反观keras的, 在和pytorch的超参数差不多的情况下, 正确率只有70%左右. 设置其他的超参数才能稍高一些 Part 5 - Inference and Validation (Exercises).ipynb 这部分主要讲验证, 比如用topk()来衡量正确 但用topk()时总是出错, 所以后面改用argmax()了 介绍了dropout的使用, 可以明显地减少过拟合. 也就是训练时的损失和验证损失差不多, 但同时训练时正确率更低一些 dropout也真是玄学 定义了自己的带dropout层的网络 12345678910111213141516171819202122232425## TODO: Define your model with dropout addedfrom torch import nn, optimimport torch.nn.functional as Fclass Classifier(nn.Module): def __init__(self): super().__init__() self.fc1 = nn.Linear(784, 256) self.fc2 = nn.Linear(256, 128) self.fc3 = nn.Linear(128, 64) self.fc4 = nn.Linear(64, 10) self.dropout = nn.Dropout(p=0.2) def forward(self, x): # make sure input tensor is flattened x = x.view(x.shape[0], -1) x = self.dropout(F.relu(self.fc1(x))) x = self.dropout(F.relu(self.fc2(x))) x = self.dropout(F.relu(self.fc3(x))) x = F.log_softmax(self.fc4(x), dim=1) return x 在训练时记录了各个时间点的损失, 所以用下面的代码可以轻松画出损失的变化值, 来判断是否发生过拟合 12345678import matplotlib.pyplot as plttrain_losses = torch.Tensor(train_losses) / len(trainloader)test_losses = torch.Tensor(test_losses) / len(testloader)plt.plot(train_losses.numpy(), label='train_losses')plt.plot(test_losses.numpy(), label='test_losses')plt.legend() 在验证时需要调用model.eval(), 避免验证进入dropout. 训练时要验证, 验证之后要用model.train()进入训练模式 Part 6 - Saving and Loading Models.ipynb这部分将如何保存和恢复模型, 因为这一节notebook运行较麻烦原因没有很认真去看… Part 7 - Loading Image Data (Exercises).ipynb这部分讲如何从文件夹中加载数据集 文件夹格式, 主文件夹下有多个子文件夹, 分别代表图片的类别. 可以在这两层文件夹之间加一层来区分训练集和测试集. 常规步骤: 定义转化器transform(改变图片大小, 中心裁剪部分图片, 转化成tensor, 翻转图片等) 使用datasets.ImageFolder()方法加载数据集 使用torch.utils.data.DataLoader()方法得到生成器dataloader 代码实现: 12345678910data_dir = 'Cat_Dog_data/train'transform = transforms.Compose([transforms.Resize(255), transforms.CenterCrop(224), transforms.ToTensor()])# TODO: compose transforms heredataset = datasets.ImageFolder(data_dir, transform=transform)# TODO: create the ImageFolderdataloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)# TODO: use the ImageFolder dataset to create the DataLoader 最后一部分是用之前所学网络结构实现猫狗分类(老师说很可能不成功, 因为之前只学了full connection net, 且只训练过MNIST这种简单的数据集, 像这种彩色的, 大图片的分类, 那些简单的网络可能效果非常不好, 所以我没尝试) Part 8 - Transfer Learning (Exercises).ipynb 这部分讲的是迁移学习, 用别人预训练好的模型就可以做好多很厉害的东西啦. 样例使用的是densenet121, 分为feature和classifier部分, 我们需要改动的是classifier部分, 从开始的ImageNet输出1000类改成2类的分类器(猫狗分类). 直观上, 感觉像是那很复杂很复杂的feature部分是将图片的特征提取出来了, 作为一个1024长度的向量是输入, 然后我们再用之前学过的知识对这个输入进行分类??? 自定义classifier, 看着有点怪, 不像之前自己定义的网络 12345678910111213# Freeze parameters so we don't backprop through themfor param in model.parameters(): param.requires_grad = Falsefrom collections import OrderedDictclassifier = nn.Sequential(OrderedDict([ ('fc1', nn.Linear(1024, 500)), ('relu', nn.ReLU()), ('fc2', nn.Linear(500, 2)), ('output', nn.LogSoftmax(dim=1)) ])) model.classifier = classifier 最后有一个自己使用预训练模型进行猫狗分类的练习, 我自己做出来正确率居然是51%(嗯, 不错, 对了一半…). 视频里讲的跟我差不多的方法是95+%的正确率. 我果然太天真. 不过过程就是这样了, 从torchvision.models加载某一预训练模型, 然后查看他的网络结构, 修改最后一部分(分类器), 注意freeze网络参数. 然后开始使用gpu训练(据比较gpu和cpu的训练速度是几百倍的差别, 然而在colab上进行训练即使是一个epoch也要训练几分钟的…), 这部分和普通的网络训练一样, 最后是测试(或者将验证部分嵌入到训练部分, 在训练过程中不断获悉正确率)","categories":[{"name":"深度学习","slug":"深度学习","permalink":"https://fiveplus.top/categories/深度学习/"}],"tags":[{"name":"深度学习","slug":"深度学习","permalink":"https://fiveplus.top/tags/深度学习/"},{"name":"pytorch","slug":"pytorch","permalink":"https://fiveplus.top/tags/pytorch/"}],"author":"姬小野"},{"title":"利用迁移学习进行花的分类 - github项目介绍","slug":"利用迁移学习进行花的分类 - github项目介绍","date":"2019-08-05T14:28:00.000Z","updated":"2019-09-15T01:19:33.796Z","comments":true,"path":"2019/08/05/li-yong-qian-yi-xue-xi-jin-xing-hua-de-fen-lei-github-xiang-mu-jie-shao/","link":"","permalink":"https://fiveplus.top/2019/08/05/li-yong-qian-yi-xue-xi-jin-xing-hua-de-fen-lei-github-xiang-mu-jie-shao/","excerpt":"","text":"前几天写了个小项目, 利用深度学习里的迁移学习方法做花的分类, 下面是项目的github地址.https://github.com/JameyWoo/transfer-learning 感兴趣的同学可以了解一下, 源码比较简单, 下面是项目的说明 transfer learning@ author 姬小野 — 迁移学习对五种花分类 环境ubuntu 18.04 requirements torch==1.1.0 numpy==1.17.0 torchvision==0.3.0 使用方法训练下载vgg的预训练模型download.pytorch.org/models/vgg16-397923af.pth放到目录/home/jamey/.cache/torch/checkpoints下执行python train.py 即可在当前目录下训练自己的模型 ps. 在普通笔记本上生成模型的时间较久 测试执行 python test.py 即可测试模型对花分类的准确率 当epoch为3时, 模型的准确率达到了83%, 其中, 除roses外准确率都极高. (大多数错误都是由roses引起的) 1234567Test Accuracy of daisy: 84% (78/92)Test Accuracy of dandelion: 94% (125/132)Test Accuracy of roses: 59% (54/91)Test Accuracy of sunflowers: 85% (86/101)Test Accuracy of tulips: 87% (108/124)Test Accuracy (Overall): 83% (451/540) 运行对一张图片进行分类 1234567----------------usage---------------- run the demo with: python demo.py -m model_name -i image_name.jpg python demo.py --image image_name.jpg python demo.py -i image_name.jpg or use `python demo.py -h` to get help -----------------end----------------- 例子demo 1 12$ python demo.py -m my_vgg16_3epochs.pth -i image/yvjingxiang_1.png郁金香 demo.py 的输出结果是图片的识别的花的中文名","categories":[{"name":"深度学习","slug":"深度学习","permalink":"https://fiveplus.top/categories/深度学习/"}],"tags":[{"name":"深度学习","slug":"深度学习","permalink":"https://fiveplus.top/tags/深度学习/"}],"author":"姬小野"},{"title":"java连接mysql数据库(jdbc增删改查)","slug":"java连接mysql数据库(jdbc增删改查)","date":"2019-07-09T16:00:00.000Z","updated":"2019-08-15T08:40:07.283Z","comments":true,"path":"2019/07/10/java-lian-jie-mysql-shu-ju-ku-jdbc-zeng-shan-gai-cha/","link":"","permalink":"https://fiveplus.top/2019/07/10/java-lian-jie-mysql-shu-ju-ku-jdbc-zeng-shan-gai-cha/","excerpt":"","text":"刚学java连接数据库, 放一个代码实例, 以作参考 由于是学习测试用, 因此代码并不规范, 并没有将增删改查等操作写在单独的函数里, 整个90+行的代码只有一个函数. 不过代码中有很多清晰的注释 菜鸟的教程写的非常好 经过这次学习, 了解到了以下几点 在java中设置数据表的字符集, 使其支持中文 很多异常捕获, 这是以前写代码很少见得 了解了很多sql语句在java中调用要使用的方法 数据库的表目录是(id, name, major) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596/** * @author 姬小野 * 2019/7/9 下午9:25 */import java.sql.*;import java.util.List;import java.util.ArrayList;public class ZenShanGaiCha &#123; // 据说这样能读中文? static String url = \"jdbc:mysql://localhost:3306/studydb?useUnicode=true&amp;characterEncoding=utf8\"; static String user = \"root\"; static String password = \"fiveplus\"; public static void main(String[] args) &#123; Connection con = null; Statement stmt = null; try &#123; Class.forName(\"com.mysql.cj.jdbc.Driver\"); System.out.println(\"数据库加载成功\"); con = DriverManager.getConnection(url, user, password); System.out.println(\"数据库连接成功\"); stmt = con.createStatement(); // 生成(学号, 名字, 专业)的虚拟数据 List ids = new ArrayList&lt;&gt;(); List&lt;String&gt; names = new ArrayList&lt;&gt;(); List&lt;String&gt; majors = new ArrayList&lt;&gt;(); String[] all_names = &#123;\"赵\", \"钱\", \"孙\", \"李\", \"周\", \"吴\", \"郑\", \"王\"&#125;; String[] all_majors = &#123;\"计科\", \"软件\", \"信安\", \"通信\"&#125;; for (int i = 1; i &lt; 10; ++i) &#123; ids.add(i * 12345 % 1000); names.add(all_names[(11*i + 7) % 8] + all_names[(i*123) % 8] + all_names[(i*111 / 3) % 8]); majors.add(all_majors[i*2357 % 4]); &#125; for (int i = 0; i &lt; ids.size(); ++i) &#123; System.out.println(ids.get(i) + \", \" + names.get(i) + \", \" + majors.get(i)); &#125; String sql; ResultSet res; // 首先删除数据表的所有行, 权当是做一个初始化 sql = \"delete from student\"; stmt.executeUpdate(sql); // 增操作 // sql = \"insert into student values(3, \\\"名字\\\", \\\"major\\\")\"; // 一条测试的语句, 测试中文 // 用这条语句来设置数据库使用utf-8, 设置一次就好 // stmt.executeUpdate(\"set character_set_database=\\\"utf8\\\"\"); // int count = stmt.executeUpdate(sql); for (int i = 0; i &lt; ids.size(); ++i) &#123; sql = \"insert into student values(\\'\" + ids.get(i) + \"\\', \\'\" + names.get(i) + \"\\', \\'\" + majors.get(i) + \"\\');\"; System.out.println(sql); int count = stmt.executeUpdate(sql); System.out.println(\"插入\" + count + \"条数据\"); &#125; // 删除操作, 删除指定姓的行 sql = \"delete from student where name like \\\"孙%\\\"\"; // 通配符删除孙姓的行 stmt.executeUpdate(sql); // 接下来查看数据表的话, 会发现姓孙的行已经没有了 // 改操作(更新) // 我们假设信安合并进入了计科, 下面在数据库中操作. 用即可表示新的计科 sql = \"update student set major = \\'即可\\' where major = \\'信安\\'\"; stmt.executeUpdate(sql); // 查操作, 查一下id在(100, 500) 以外的行 sql = \"select * from student where not id between 100 and 500\"; res = stmt.executeQuery(sql); System.out.println(\"当前数据库数据:\"); while (res.next()) &#123; int id = res.getInt(\"id\"); String name = res.getString(\"name\"); String major = res.getString(\"major\"); System.out.println(\"id: \" + id + \", name: \" + name + \", major: \" + major); &#125; // 统统关闭 res.close(); stmt.close(); con.close(); &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; catch (ClassNotFoundException e) &#123; e.printStackTrace(); &#125; &#125;&#125;","categories":[{"name":"java","slug":"java","permalink":"https://fiveplus.top/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://fiveplus.top/tags/java/"},{"name":"数据库","slug":"数据库","permalink":"https://fiveplus.top/tags/数据库/"}],"author":"姬小野"},{"title":"IDEA及其他开发工具日常使用指南","slug":"IDEA及其他开发工具日常使用指南","date":"2019-07-07T16:00:00.000Z","updated":"2019-09-15T01:19:47.716Z","comments":true,"path":"2019/07/08/idea-ji-qi-ta-kai-fa-gong-ju-ri-chang-shi-yong-zhi-nan/","link":"","permalink":"https://fiveplus.top/2019/07/08/idea-ji-qi-ta-kai-fa-gong-ju-ri-chang-shi-yong-zhi-nan/","excerpt":"","text":"1. 引入依赖包通过如图所示的路径添加tar文件, 即可引入外部包. 2. 单独运行一个java文件在java文件上右键, 如果你写好了main函数就可以编译运行. 之前由于不熟悉java, 所以main的参数没有写String[] args, 所以一直无法运行. 3. 修改class的模板如加入作者, 时间等信息 4. 生成javadoc刚学java, 知道了这个工具觉得好神奇啊, 居然这么方便开发者.效果如图不过在我的电脑上, 用jdk11生成不了, 得换成jdk8. 5. git版本控制在idea上进行版本控制很方便在vcs这一栏开启之后就可以用git了.有比较友好的图形操作界面. 6. 操作数据库在view这一栏找到工具, 配置好数据库就可以连接了.然后在窗口上写sql语言, 下面的console就出现结果 7. ctrl + 点击 可跳转到类的实现处8. 设置终端cmd真难受, 换成powershell好用多了 9. 设置代理应该就不用每次都在代码里面弄了, scrapy配置socks真是麻烦死了啊. 10. 格式化html原先Code-&gt;Reformat Code 快捷键 Ctrl+Alt+L 11. Sphinx 自动生成python文档官网: http://www.sphinx-doc.org/en/master/#confval-language sphinx_rtd_theme 主题github 简书上的好教程 效果 安装pip install sphinxmkdir doc_testcd doc_test执行sphinx-quickstart下面是配置 123456789101112131415161718192021222324252627282930313233343536373839PS C:\\Users\\姬小野\\PycharmProjects\\get_nlp_data\\doc_test&gt; sphinx-quickstartWelcome to the Sphinx 2.1.2 quickstart utility.Please enter values for the following settings (just press Enter toaccept a default value, if one is given in brackets).Selected root path: .You have two options for placing the build directory for Sphinx output.Either, you use a directory &quot;_build&quot; within the root path, or you separate&quot;source&quot; and &quot;build&quot; directories within the root path.&gt; Separate source and build directories (y/n) [n]: nThe project name will occur in several places in the built documentation.&gt; Project name: NLP_Books&gt; Author name(s): Jamey&gt; Project release []: v0.6If the documents are to be written in a language other than English,you can select a language here by its language code. Sphinx will thentranslate text that it generates into that language.For a list of supported codes, seehttps://www.sphinx-doc.org/en/master/usage/configuration.html#confval-language.&gt; Project language [en]: zh_cnCreating file .\\conf.py.Creating file .\\index.rst.Creating file .\\Makefile.Creating file .\\make.bat.Finished: An initial directory structure has been created.You should now populate your master file .\\index.rst and create other documentationsource files. Use the Makefile to build the docs, like so: make builderwhere &quot;builder&quot; is one of the supported builders, e.g. html, latex or linkcheck.PS C:\\Users\\姬小野\\PycharmProjects\\get_nlp_data\\doc_test&gt; 找到conf.py, 取消注释, 路径改成自己项目路径修改extensions为如下 12345extensions = [ 'sphinx.ext.autodoc', 'sphinx.ext.todo', 'sphinx.ext.viewcode'] 执行 sphinx-apidoc -o ./source ../ 其中 ./source 为rst文件所在目录 使用make 查看可用的make命令这里我们make html 12. 使用read the Doc 托管文档看这网站logo, 难道大多数python包的文档都是托管到这的? 13. IDEA补全快捷键1. for循环打一个for循环, 些fori, 然后回车, 马上就有 2. main函数补全输入psvm然后回车 3.System.out.println();输入sout, 回车 4. 按ctrl+j查看所有代码生成参考: https://juejin.im/entry/5a0eaf38f265da431955d9a6 5. 自定义自己的快捷键https://blog.csdn.net/qq_27093465/article/details/52691572 6. 技能表https://www.cnblogs.com/jx17/p/6244491.html 14. 使用mkdocs生成快速文档mkdocs能够根据markdown快速生成文档网站, 然后部署在github page上, 这样可以给每个项目都部署一个文档网站了比如这个文档页面, 就是我用来测试mkdocs效果的页面效果如图可以方便地更换各种主题 甚至可以单独把它作为一个博客网站来玩 输入命令mkdocs -h 即可查看他的功能 12345678910111213141516(torch)$ mkdocs -hUsage: mkdocs [OPTIONS] COMMAND [ARGS]... MkDocs - Project documentation with Markdown.Options: -V, --version Show the version and exit. -q, --quiet Silence warnings -v, --verbose Enable verbose output -h, --help Show this message and exit.Commands: build Build the MkDocs documentation gh-deploy Deploy your documentation to GitHub Pages new Create a new MkDocs project serve Run the builtin development server 15. github gist代码片段管理服务 今天偶然知道了github还提供这样一个服务, 之前知道贴代码可以用Pastebin. 简而言之就是大家可以把自己的代码片段贴上去, 然后分享. 支持匿名, 私密, markdown等. 而且我突然发现之前我colab上有一个选项保存到github gist上就是这个! 恍然大悟.在gist链接后面加一个.pibb后缀, 直接将这部分内容变成一个干净的html网页了.","categories":[{"name":"开发工具","slug":"开发工具","permalink":"https://fiveplus.top/categories/开发工具/"}],"tags":[{"name":"idea","slug":"idea","permalink":"https://fiveplus.top/tags/idea/"}],"author":"姬小野"},{"title":"darknet--目标检测开源库学习记录","slug":"darknet--目标检测开源库学习记录","date":"2019-06-27T16:00:00.000Z","updated":"2019-08-15T09:44:57.933Z","comments":true,"path":"2019/06/28/darknet-mu-biao-jian-ce-kai-yuan-ku-xue-xi-ji-lu/","link":"","permalink":"https://fiveplus.top/2019/06/28/darknet-mu-biao-jian-ce-kai-yuan-ku-xue-xi-ji-lu/","excerpt":"","text":"1. 效果展示官网链接 darknet 实现了c语言版本的yolo v3, 不依赖任何其他库. 因此安装非常简单. 效果图: 2. 安装方法如何安装? 123git clone https://github.com/pjreddie/darknetcd darknetmake 然后下载yolov3权重, 放到darknet根目录下wget https://pjreddie.com/media/files/yolov3.weights 执行命令./darknet detector test cfg/coco.data cfg/yolov3.cfg yolov3.weights data/dog.jpg 测试一下效果, 生成的图片保存在darknet根目录下 3. 常用命令以下是几个常用的检测命令 1234567891011121314151617# 调用摄像头进行目标检测./darknet detector demo cfg/coco.data cfg/yolov3.cfg yolov3.weights# 对视频进行目标检测./darknet detector demo cfg/coco.data cfg/yolov3.cfg yolov3.weights &lt;video_file&gt;# 检测单独的一张图片./darknet detect cfg/yolov3.cfg yolov3.weights data/dog.jpg# 设置阈值的检测./darknet detect cfg/yolov3.cfg yolov3.weights data/dog.jpg -thresh 0# 对多张图片的检测, 输入命令后, 输入图片路径./darknet detect cfg/yolov3.cfg yolov3.weights# 指定摄像头设备, 加参数 -c./darknet detector demo cfg/coco.data cfg/yolov3.cfg yolov3.weights -c 1 4. GPU加速用CPU进行测试非常的慢, 下面是官网的描述, 一张图10s(在我的电脑上还不止) 使用GPU可以大幅提高速度, 提升有多少呢? 在我的Geforce 940MX 辣鸡显卡上, 都可以实现比较卡顿的摄像头目标检测了! 如果是高性能的显卡, 想必会非常流畅(羡慕) 当然, 用GPU是需要安装好cuda的. 我用的是cuda 10.0 如何开启GPU模式? 修改makefile, GPU=0 改成GPU=1, 然后重新make. 5. 安装opencv建议安装C++版本的opencv, 安装好了同样是改成OPENCV=1. (因为装了opencv他才会在屏幕上显示出检测的结果) 如何在ubuntu 18.04 上安装opencv 3.4.6 ? 看这篇教程, 亲测有效. 除了后期有一丁点的不同基本顺利安装. 6. 几点小提示查看./cfg/yolov3.cfg 文件, 有两种模式, 根据自己的实际需要进行注释. 比如说我们做测试, 就改成testing模式.如果GPU太垃圾(比如我), 一测试就报显存溢出错误, 可以设置下面的width 和 height, 将它设小一点就可以了. 7. 使用网络摄像头(手机)之一使用网络摄像头, 用手机作为外接摄像头而不只是笔记本的摄像头来做目标检测, 下面是效果图. 我使用的是Droidcam ip摄像头 手机需要下载Droidcam app, 可以直接在google play上下载 官网: http://www.dev47apps.com/ 以及一篇非常好的安装教程 ubuntu 18.04 (linux)下的安装方法是复制下面这段代码做一个bash脚本, 然后执行它. 1234567891011cd /tmp/sudo apt-get install linux-headers-`uname -r`bits=`getconf LONG_BIT`wget https://www.dev47apps.com/files/600/droidcam-$&#123;bits&#125;bit.tar.bz2[[ $&#123;bits&#125; -eq 32 ]] &amp;&amp; checksum=90cd43b4745c51cffedc352090912eb1[[ $&#123;bits&#125; -eq 64 ]] &amp;&amp; checksum=9507c0b738f427c5f1dde7b2a364fdfbecho \"$&#123;checksum&#125; droidcam-$&#123;bits&#125;bit.tar.bz2\" | md5sum -c --# OK?tar xjf droidcam-$&#123;bits&#125;bit.tar.bz2cd droidcam-$&#123;bits&#125;bit/sudo ./install 建立启动器gedit ~/.local/share/applications/droidcam.desktop拷贝下面的代码进去 12345678910[Desktop Entry]Version=1.0Type=ApplicationTerminal=falseName=DroidCamExec=droidcamComment=Use your Android phone as a wireless webcam or an IP Cam!Icon=droidcamCategories=GNOME;GTK;Video;Name[it]=droidcam 就可以找到图形程序的图标 然后就可以使用wifi连接手机上的摄像头. 也可以用usb连接的方式. 用命令ls /dev/video* 查看电脑上的摄像头设备. 目前有两个. 这个video1就是ip摄像头了.在使用darknet的时候, 在后面加参数-c 1 就可以指定摄像头设备了. 比如./darknet detector demo cfg/coco.data cfg/yolov3.cfg yolov3.weights -c 1 8. 使用网络摄像头(手机)之二但如果用ip摄像头的话, 一来比较卡顿, 二来如果在外面没有wifi怎么办呢? 那么用usb就是个更好的选择. 参考这篇文章弄好了usb摄像头https://xpenxpen.iteye.com/blog/2182397 安装adb sudo apt-get install adb 查看设备adb devices 输入adb forward tcp:4747 tcp:4747 启用摄像头 (改成自己的端口) 手机打开开发者模式, 进开发者选项把usb调试打开 客户端开启usb模式 9. 保存检测视频到本地darknet官方似乎并没有一个简单的参数可以将检测的视频保存在本地, 找了好多文章后终于找到一个靠谱的方法. 来源链接 思路是, darknet提供了一种参数, -prefix, 可以将视频检测的结果输出为一系列的图片. 我们将这些图片保存在tmp文件夹, 然后使用视频转化工具ffmpeg 将这一系列的图片转化为视频. 下面是修改了的bash脚本, 保存为run.sh 123456#!/bin/bash./darknet detector demo cfg/coco.data cfg/yolov3.cfg yolov3.weights $1 -prefix ./tmp/picturesffmpeg -i ./tmp/pictures_%08d.jpg $2rm ./tmp/pictures_*.jpg 我稍微修改了github issue上的脚本, 使得我们可以指定输入和输出的文件.执行这条命令就可以保存视频了 1./run.sh ./data/test-5.mp4 ./outputfiles/test-5.mp4 调用摄像头然后保存的话, 也稍微修改一下脚本就好了 perfect","categories":[{"name":"计算机视觉","slug":"计算机视觉","permalink":"https://fiveplus.top/categories/计算机视觉/"}],"tags":[{"name":"目标检测","slug":"目标检测","permalink":"https://fiveplus.top/tags/目标检测/"},{"name":"开源库","slug":"开源库","permalink":"https://fiveplus.top/tags/开源库/"}],"author":"姬小野"},{"title":"使用face_recognition进行人脸特征检测","slug":"使用face_recognition进行人脸特征检测","date":"2019-06-26T14:28:00.000Z","updated":"2019-08-15T09:01:51.537Z","comments":true,"path":"2019/06/26/shi-yong-face-recognition-jin-xing-ren-lian-te-zheng-jian-ce/","link":"","permalink":"https://fiveplus.top/2019/06/26/shi-yong-face-recognition-jin-xing-ren-lian-te-zheng-jian-ce/","excerpt":"","text":"效果图调用face_recognition.face_landmarks()方法即可得到人脸特征点, 返回一个字典, 下图是返回的数据, 包括chin(下巴), left_eye(左眼)等.我画了两种图, 一种是遍历所有的点, 直接给点画图的图(点用实心圆绘制). 第二个是单独画下巴, 连成线, 用的是polylines方法. 我是4.10版本的opencv. 查阅官方py文档, 这是链接完整代码: 1234567891011121314151617181920212223242526import face_recognitionimport numpy as npimport cv2image = face_recognition.load_image_file(\"./data/奥巴马.png\")image2 = image.copy()face_landmarks_list = face_recognition.face_landmarks(image)# print(face_landmarks_list)for each in face_landmarks_list: print(each) for i in each.keys(): print(i, end=': ') print(each[i]) for any in each[i]: image = cv2.circle(image, any, 3, (0,0,255), -1)cv2.imshow(\"奥巴马\", image)# 单独画下巴for each in face_landmarks_list: pts = np.array(each['chin']) pts = pts.reshape((-1, 1, 2)) cv2.polylines(image2, [pts], False, (0, 255, 255)) # false 参数使其不闭合cv2.imshow(\"奥巴马2\", image2)cv2.waitKey(0)cv2.destroyAllWindows() 在线摄像机版本: 123456789101112131415161718192021222324252627282930313233import face_recognitionimport numpy as npimport cv2camera = cv2.VideoCapture(0)while True: ret, image = camera.read() image = cv2.flip(image, 1) image2 = image.copy() face_landmarks_list = face_recognition.face_landmarks(image) # print(face_landmarks_list) for each in face_landmarks_list: print(each) for i in each.keys(): print(i, end=': ') print(each[i]) for any in each[i]: image = cv2.circle(image, any, 3, (0,0,255), -1) cv2.imshow(\"奥巴马\", image) # 单独画下巴 for each in face_landmarks_list: pts = np.array(each['chin']) pts = pts.reshape((-1, 1, 2)) cv2.polylines(image2, [pts], False, (0, 255, 255)) # false 参数使其不闭合 cv2.imshow(\"奥巴马2\", image2) if cv2.waitKey(1000 // 12) &amp; 0xff == ord(\"q\"): breakcv2.destroyAllWindows()camera.release() 附一份在线的人脸搜索代码, 人脸数据保存在相对路径./data/mans 下 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556import cv2import face_recognitionimport numpy as npimport osimport re# 人脸数据, 文件, 编码, 名字files = os.listdir(\"./data/mans\")face_images = [0]*len(files)face_encodings = [0]*len(files)face_names = [0]*len(files)# 获取编码和名称for i in range(len(files)): face_images[i] = face_recognition.load_image_file('./data/mans/' + files[i]) face_encodings[i] = face_recognition.face_encodings(face_images[i]) if len(face_encodings[i]) &gt; 0: face_encodings[i] = face_encodings[i][0] else: face_encodings[i] = None face_names[i] = re.findall(r'(.*)\\..*', files[i])[0]print(face_names)# 人脸比较# results = face_recognition.compare_faces(face_encodings[0], face_encodings[1])# print(results)# 人脸距离# face_distances = face_recognition.face_distance(face_encodings[0], face_encodings[1])# index = np.argmin(face_distances)# print(index)# camera = cv2.VideoCapture('./data/test.avi') # 从视频文件camera = cv2.VideoCapture(0) # 从摄像头while True: ret, img = camera.read() img = cv2.flip(img, 1) # img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) # 灰度处理 locations = face_recognition.face_locations(img) for top, right, bottom, left in locations: cv2.rectangle(img, (left, top), (right, bottom), (255, 0, 0), 2) sub_img = img[top:bottom, left:right] sub_img_code = face_recognition.face_encodings(sub_img) if len(sub_img_code) != 0: face_distances = face_recognition.face_distance(face_encodings, sub_img_code[0]) print(face_distances) index = np.argmin(face_distances) name = face_names[index] cv2.putText(img, name, (left, top - 20), cv2.FONT_HERSHEY_SIMPLEX, 1, 255, 2) cv2.imshow('Face', img) if cv2.waitKey(1000 // 12) &amp; 0xff == ord(\"q\"): breakcv2.destroyAllWindows()camera.release()","categories":[{"name":"深度学习","slug":"深度学习","permalink":"https://fiveplus.top/categories/深度学习/"}],"tags":[{"name":"开源库","slug":"开源库","permalink":"https://fiveplus.top/tags/开源库/"},{"name":"深度学习","slug":"深度学习","permalink":"https://fiveplus.top/tags/深度学习/"},{"name":"人脸识别","slug":"人脸识别","permalink":"https://fiveplus.top/tags/人脸识别/"}],"author":"姬小野"},{"title":"优雅地使用ubuntu18.04（二）","slug":"优雅地使用ubuntu18.04（二）","date":"2019-06-09T16:00:00.000Z","updated":"2019-08-15T09:45:24.242Z","comments":true,"path":"2019/06/10/you-ya-di-shi-yong-ubuntu18.04-er/","link":"","permalink":"https://fiveplus.top/2019/06/10/you-ya-di-shi-yong-ubuntu18.04-er/","excerpt":"","text":"文章链接优雅地使用ubuntu18.04（一）优雅地使用ubuntu18.04（二） 12、设置默认终端使用命令sudo update-alternatives --config x-terminal-emulator然后就可以选择了 13、设置开启自动启动找到启动应用程序 就可以直接添加自启动了 14、自定义右键想实现文件夹右键，可以执行打开某一指定程序（如我们下载的终端），并设置工作目录为当前目录。但还没有实现，挖个坑。 15、使用albert这个工具类似于windows中的everything但感觉不是很好用的样子？虽然有人强烈推荐可以直接下载deb文件进行安装了 16、设置终端复制黏贴快捷键习惯了用Ctrl+C复制，所以也直接把终端的快捷方式给改了。里面有各种快捷方式，可以根据自己的习惯自定义啊。 17、几个好玩的命令boxessudo apt install boxes 终端跑小火车sudo apt install slsl 黑客帝国代码雨sudo apt install cmatrixcmatrixctrl+z 退出 screenfetchsudo apt install screenfetchscreenfetch 18、顶栏自动隐藏安装Hide Top Bar插件https://extensions.gnome.org/extension/545/hide-top-bar/ 在全屏显示窗口时就会自动隐藏深色难看的顶栏了 19、设置字体缩放比例。在字体这里设置缩放比例为1.25，看起来就大很多了，接近我在win 10 的大小习惯 20、安装Mac OS 风格主题参考https://blog.csdn.net/jasonzhoujx/article/details/80400245 到这个网站找各种主题效果如图 21、修改登录界面的图片修改这个文件夹/etc/alternatives/gdm3.css找到这段，修改成自己的图片路径, 以及下面几行css设置. 22、添加应用启动图标安装好pycharm后，没有启动的图标，所以自己设置一个。 首先找到图标文件，链接 然后在/usr/share/applications/ 目录下添加Pycharm.desktop。 修改这个文件。注意，其中的Exec改成执行的命令，Icon改成自己图标的路径。 123456789[Desktop Entry]Type=ApplicationName=PycharmGenericName=Pycharm3Comment=Pycharm3:The Python IDEExec=bash /home/jamey/programs/pycharm-2019.1.3/bin/pycharm.shIcon=/home/jamey/programs/pycharm-2019.1.3/pycharm.icoTerminal=pycharmCategories=Pycharm; 出现图标","categories":[{"name":"操作系统","slug":"操作系统","permalink":"https://fiveplus.top/categories/操作系统/"}],"tags":[{"name":"ubuntu","slug":"ubuntu","permalink":"https://fiveplus.top/tags/ubuntu/"},{"name":"开源库","slug":"开源库","permalink":"https://fiveplus.top/tags/开源库/"}],"author":"姬小野"},{"title":"优雅地使用ubuntu18.04（一）","slug":"优雅地使用ubuntu18.04（一）","date":"2019-06-08T16:00:00.000Z","updated":"2019-08-15T09:12:45.073Z","comments":true,"path":"2019/06/09/you-ya-di-shi-yong-ubuntu18.04-yi/","link":"","permalink":"https://fiveplus.top/2019/06/09/you-ya-di-shi-yong-ubuntu18.04-yi/","excerpt":"","text":"文章链接优雅地使用ubuntu18.04（一）优雅地使用ubuntu18.04（二） 1、ubuntu 截图理论上来说应该是可以直接下面这样，但是我的截图出来不会弹出窗口，所以直接搜索截图程序进行截图。shift+ctrl+prtSc 能够选中区域截图，并复制到剪切板 2、终端快捷方式ctrl+alt+t 3、ubuntu自定义程序快捷方式首先查看设置-键盘；发现有很多快捷键的记录比如我们可以设置移动工作区的快捷方式关于截图的快捷键 4、ubuntu快速回到桌面win + D点击ubuntu的小图标不会自动消失真是难受。 5、安装tim、微信等应用使用deepin-wine安装别看别人写的博客安装了，看官方github说明吧https://github.com/wszqkzqk/deepin-wine-ubuntu 6、rtl8821CE系列 安装ubuntu 找不到wifi适配器参考下面这个博客，thinkpad e系列还真是坑https://blog.csdn.net/fljhm/article/details/79281655 7、ubuntu 手势操作找了网上很多的手势操作的程序，很多都没弄成功，最后弄好了这个comfortable swipe这是它的github，里面如何安装讲的非常清楚可以实现多指滑动自定义，虽然没有win 10 那么舒服，但好歹更方便了。 8、二次点击dock图标隐藏窗口初始的程序窗口点击不会消失，设置二次点击dock能够让程序消失先输入export GIO_EXTRA_MODULES=/usr/lib/x86_64-linux-gnu/gio/modules/再输入gsettings set org.gnome.shell.extensions.dash-to-dock click-action &#39;minimize&#39;即可设置dock最小化 9、设置dock为mac风格看这篇文章但我用这总有bug预期图 10、设定制终端的提示符原先终端提示符有冗长的主机名，然而这东西没一点用处，拜拜占了那么多位置。查看~/.bashrc文件中的PS1参数，这个参数就是提示符的格式。主机名代表\\h，那么我们找到\\h删除掉。其他很多还可以自定义如图，变得简洁了不少 参考https://blog.csdn.net/sunbocong/article/details/82971477 11、下载多种终端我下载了两个终端，一个是下拉式终端guake可设置透明、在顶栏还是下面、失去焦点隐藏、F12开关第二个是tilix，功能比原生的多，特别是这窗口，比较丰富如图为三种终端的比较","categories":[{"name":"操作系统","slug":"操作系统","permalink":"https://fiveplus.top/categories/操作系统/"}],"tags":[{"name":"ubuntu","slug":"ubuntu","permalink":"https://fiveplus.top/tags/ubuntu/"},{"name":"开源库","slug":"开源库","permalink":"https://fiveplus.top/tags/开源库/"}],"author":"姬小野"},{"title":"opencv-python 人脸识别尝试——knn与深度学习","slug":"opencv-python 人脸识别尝试——knn与深度学习","date":"2019-06-07T16:00:00.000Z","updated":"2019-08-15T09:14:32.877Z","comments":true,"path":"2019/06/08/opencv-python-ren-lian-shi-bie-chang-shi-knn-yu-shen-du-xue-xi/","link":"","permalink":"https://fiveplus.top/2019/06/08/opencv-python-ren-lian-shi-bie-chang-shi-knn-yu-shen-du-xue-xi/","excerpt":"","text":"引言人脸识别和人脸检测不同，人脸检测时检测到人脸位置，而人脸识别是基于人脸数据库，进行一些识别操作如识别某一个人像是数据库中的哪个标签。 需要说明的是，使用knn和Dense层的神经网络作为人脸识别算法只是我的尝试，在实际的使用中基本不使用这两种算法的。同时，经过实际测试，这样得到的结果极不准确，甚至可以说毫无效果（苦笑）。 人脸数据获取进行人脸识别首先要有人脸数据库，我们可以用opencv调用摄像头，进行人脸检测，并将人脸灰度图片写入到(200, 200)的pgm文件作为我们的人脸数据库。 code 1234567891011121314151617181920212223242526272829303132333435363738import cv2def generate(): face_cascade = cv2.CascadeClassifier( # haar级联文件-人脸 './cascades/haarcascade_frontalface_default.xml' ) camera = cv2.VideoCapture(0) count = 0 while True: ret, frame = camera.read() frame = cv2.flip(frame, 1) # 翻转为正常角度 gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) #转灰度处理 faces = face_cascade.detectMultiScale(gray, 1.3, 5) # 识别 for (x, y, w, h) in faces: img = cv2.rectangle( # 画框图 frame, (x, y), (x + w, y + h), (255, 0, 0), 2 ) # cv2.putText( # img, 'name', (x, y - 20), cv2.FONT_HERSHEY_SIMPLEX, 1, 255, 2 # ) f = cv2.resize(gray[y: y+h, x: x+w], (200, 200)) # 统一大小 cv2.imwrite('./data/at/name/%s.pgm' % str(count), f) # 将人脸数据写入到pgm文件中 count += 1 if count == 200: break cv2.imshow('camera', frame) if cv2.waitKey(int(1000 / 12)) &amp; 0xff == ord(\"q\"): # 等待ｑ键 break camera.release() cv2.destroyAllWindows() returnif __name__ == '__main__': generate() 处理图片读取到并数组中这个代码是读取数据的模块，在后面的代码中多次调用以获取数据。将上一步存储的图片数据转化为可处理的numpy数组，提供了两种相似的接口函数。 read_images 为普通的读取到灰度的pgm图片返回的数组read_images_binary 是将pgm图片进行了二值化处理得到的数组数据 返回的数据类型为 list, list, dict分别为 图片数据、图片标签、标签和人名的映射字典 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162import os, sys, reimport cv2import numpy as npdef read_images(path, sz=None): # 读取自己的图片数据库 c = 0 X, y = [], [] dic = &#123;&#125; for dirname, dirnames, filenames in os.walk(path): # 遍历文件夹下文件 for subdirname in dirnames: subject_path = os.path.join(dirname, subdirname) # print(\"subdirname = \", dirname) # print(\"subject_path = \", subject_path) for filename in os.listdir(subject_path): if filename[-4:] != '.pgm': # 如果文件不是pgm文件,那么跳过 continue filepath = os.path.join(subject_path, filename) # 生成完整的文件名 # print(filepath) im = cv2.imread(os.path.join(subject_path, filename), \\ cv2.IMREAD_GRAYSCALE) # 读取pgm图片 # print(np.shape(im)) # 改变大小 if sz is not None: im = cv2.resize(im, (200, 200)) # 调整图片大小 X.append(np.asarray(im, dtype=np.uint8)) y.append(c) # print(re.findall(r'./data/at/(.*)', subject_path)) dic[c] = re.findall(r'./data/at/(.*)', subject_path)[0] c = c + 1 # print(\"c = \", c) # print(X) return [X, y], dicdef read_images_binary(path, sz=None): # 读取自己的图片数据库 c = 0 X, y = [], [] dic = &#123;&#125; for dirname, dirnames, filenames in os.walk(path): # 遍历文件夹下文件 for subdirname in dirnames: subject_path = os.path.join(dirname, subdirname) # print(\"subdirname = \", dirname) # print(\"subject_path = \", subject_path) for filename in os.listdir(subject_path): if filename[-4:] != '.pgm': # 如果文件不是pgm文件,那么跳过 continue filepath = os.path.join(subject_path, filename) # 生成完整的文件名 # print(filepath) im = cv2.imread(os.path.join(subject_path, filename), \\ cv2.IMREAD_GRAYSCALE) # 读取pgm图片 ret, im = cv2.threshold(im, 120, 255, cv2.THRESH_BINARY) if sz is not None: im = cv2.resize(im, (200, 200)) # 调整图片大小 X.append(np.asarray(im, dtype=np.uint8)) y.append(c) # print(re.findall(r'./data/at/(.*)', subject_path)) dic[c] = re.findall(r'./data/at/(.*)', subject_path)[0] c = c + 1 # print(\"c = \", c) # print(X) return [X, y], dic 调用opencv内置函数进行人脸识别内置的三种人脸识别函数 123model = cv2.face.EigenFaceRecognizer_create() # 这个版本的opencv名字改了,和书上的有点不一样model = cv2.face.LBPHFaceRecognizer_create(1, 8, 8, 90)model = cv2.face.FisherFaceRecognizer_create() 调用opencv-python提供的这三种人脸识别函数，发现效果都不好。人脸总是检测错误，准确率极低，要它何用？（不知道是不是我使用姿势不太正确）于是我催生出自己实现人脸识别算法那的念头。 观察框出的人脸，觉得一个人的人脸图片，单单框出了人脸，那应该相似度很高啊。类似于手写数字识别，简单的knn算法可以达到很高的正确率，那么是不是可以用knn较好的解决这个问题。 实践出来的结果是：不是的。 code 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960import cv2import numpy as npfrom PIL import Image, ImageDraw, ImageFontfrom getData import read_imagesdef cv2ImgAddText(img, text, left, top, textColor=(0, 255, 0), textSize=20): img = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)) draw = ImageDraw.Draw(img) fontText = ImageFont.truetype( \"SimHei.ttf\", textSize, encoding=\"utf-8\") draw.text((left, top), text, textColor, font=fontText) return cv2.cvtColor(np.asarray(img), cv2.COLOR_RGB2BGR)def face_rec(): # 人脸识别 [X, y], label2name = read_images('./data/at') print(\"label2name:\", label2name) print(np.shape(X)) print(\"label2name = \", label2name) print(np.shape(X)) # print(\"y = \", y) y = np.asarray(y, dtype=np.int32) # 调用人脸识别函数生成模型 # model = cv2.face.EigenFaceRecognizer_create() # 这个版本的opencv名字改了,和书上的有点不一样 model = cv2.face.LBPHFaceRecognizer_create(1, 3, 8, 8) model.train(np.asarray(X), np.asarray(y)) # 训练 camera = cv2.VideoCapture(0) face_cascade = cv2.CascadeClassifier( # 分类器检测人脸 './cascades/haarcascade_frontalface_default.xml' ) while True: read, img = camera.read() img = cv2.flip(img, 1) # 翻转为正常角度 faces = face_cascade.detectMultiScale(img, 1.3, 5) for (x, y, w, h) in faces: img = cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2) gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) roi = gray[x: x+2, y: y+h] roi = cv2.resize(roi, (200, 200), interpolation=cv2.INTER_LINEAR) params = model.predict(roi) # 预测 print(params) # 返回 (图片标签, 置信度) if params[0] &gt;= 0: name = label2name[params[0]] else: name = \"未知\" print(\"检测到%s\" % name) print(\"label: %s, Confidence: %.2f\" % (params[0], params[1])) img = cv2ImgAddText(img, name, x, y - 20, (255, 255, 0), 20) # cv2.putText(img, name, (x, y - 20), # cv2.FONT_HERSHEY_SIMPLEX, 1, 255, 2) # putText只能写上ascii中的部分字符, 呵呵 # print(img) cv2.imshow('camera', img) if cv2.waitKey(1000 // 12) &amp; 0xff == ord(\"q\"): break cv2.destroyAllWindows()if __name__ == \"__main__\": face_rec() # 人脸识别 knn算法进行人脸识别简单的knn模板 knn 实现 1234567891011121314151617181920212223242526272829303132333435import numpy as npimport matplotlib.pyplot as pltfrom getData import read_imagesdef knn(xtest, data, label, k): # xtest为测试的特征向量，data、label为“训练”数据集，k为设定的阈值# print(xtest.shape)# print(label.shape) exp_xtest = np.tile(xtest, (len(label), 1)) - data sq_diff = exp_xtest**2 sum_diff = sq_diff.sum(axis=1) distance = sum_diff**0.5 # print(distance) sort_index = distance.argsort() classCount = &#123;&#125; for i in range(k): one_label = label[sort_index[i]] classCount[one_label] = classCount.get(one_label, 0) + 1 sortedClassCount = sorted(classCount.items(), key = lambda x:x[1], reverse=True) print(distance.sum()) print(classCount) print(sortedClassCount) return sortedClassCount[0][0]def main(): [X, y], label2name = read_images('./data/at/') print(np.shape(X)) X = np.array(X) Xx = X.reshape(X.shape[0], 40000) xdata, label = Xx, y result = knn(np.array(xdata[67]), xdata, label, 3) print(\"result = \", label2name[result]) return resultif __name__ == '__main__': main() 调用knn的主体部分 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849import cv2import numpy as npfrom PIL import Image, ImageDraw, ImageFontfrom getData import read_images_binaryfrom knn import knndef cv2ImgAddText(img, text, left, top, textColor=(0, 255, 0), textSize=20): img = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)) draw = ImageDraw.Draw(img) fontText = ImageFont.truetype( \"SimHei.ttf\", textSize, encoding=\"utf-8\") draw.text((left, top), text, textColor, font=fontText) return cv2.cvtColor(np.asarray(img), cv2.COLOR_RGB2BGR)def face_rec(): # 人脸识别 [X, y], label2name = read_images_binary('./data/at') X = np.array(X) Xx = X.reshape(X.shape[0], 40000) xdata, label = Xx, y y = np.asarray(y, dtype=np.int32) face_cascade = cv2.CascadeClassifier( # 分类器检测人脸 './cascades/haarcascade_frontalface_default.xml' ) videoCapture = cv2.VideoCapture(0) while True: read, img = videoCapture.read() img = cv2.flip(img, 1) faces = face_cascade.detectMultiScale(img, 1.3, 5) for (x, y, w, h) in faces: img = cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2) gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) roi = gray[x: x+2, y: y+h] roi = cv2.resize(roi, (200, 200), interpolation=cv2.INTER_LINEAR) roi = np.array(roi).reshape(40000, ) result = knn(roi, xdata, label, 3) print(result) # 返回结果的标签 name = label2name[result] print(\"检测到%s\" % name) img = cv2ImgAddText(img, name, x, y - 20, (255, 255, 0), 20) cv2.imshow('camera', img) if cv2.waitKey(1000 // 12) &amp; 0xff == ord(\"q\"): break cv2.destroyAllWindows()if __name__ == \"__main__\": face_rec() # 人脸识别 使用Dense层神经网络进行人脸识别简单的神经网络多分类器实现（效果不好，大概是数据太少，每个人只有200张(200, 200) 的pgm图片数据。 调用keras的高级API，搭积木一样的建立神经网络。 即使是这么少的数据，训练一次的时间也要好几分钟。调参调了好久，关键是调不出效果啊～ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182from getData import read_images, read_images_binaryimport numpy as npfrom tensorflow.keras import modelsfrom tensorflow.keras import layersdef to_onehot(y): # 将标签转化为独热码oen-hot print(\"max of y = \", np.max(y)) onehots = np.zeros((len(y), np.max(y) + 1), dtype=np.float) for i in range(len(y)): onehots[i][y[i]] = 1.0 print(\"shape of onehots : \", np.shape(onehots)) return onehotsdef get_model_dense(size=(200, 200)): # 设置一个全连接层网络，返回模型，未训练 model = models.Sequential([ layers.Dense(16, activation='relu', input_shape=((40000, ))), layers.Dense(16, activation='relu'), layers.Dense(16, activation='relu'), layers.Dense(4, activation='softmax') ]) model.compile( optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'] ) return modeldef k_fold_validation(train_data, train_targets): k = 4 num_val_samples = len(train_data) // k num_epochs = 5 all_scores = [] for i in range(k): print('processing fole # ', i) val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples] val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples] partial_train_data = np.concatenate( [train_data[:i * num_val_samples], train_data[(i + 1) * num_val_samples:]], axis=0 ) partial_train_targets = np.concatenate( [train_targets[:i * num_val_samples], train_targets[(i + 1) * num_val_samples:]], axis = 0 ) model = get_model_dense() model.fit( partial_train_data, partial_train_targets, epochs=num_epochs, batch_size=3 ) ''' model5开始，对图片进行了阈值为１２０的图片二值化处理 model6调整了参数（防止过拟合），从６４调成１６ model7加了一层 ''' model.save('dense_model_7.h5') val_mse, val_mae = model.evaluate(val_data, val_targets) all_scores.append(val_mae)def main(): [X, y], label2name = read_images_binary('./data/at/') # 调用人脸数据 X = np.array(X).reshape(len(X), 40000) / 255 y = to_onehot(np.array(y)) index = np.arange(len(X)) np.random.shuffle(index) # 生成打乱的索引 print(\"index = \", index) X = X[index] # 得到打乱的数据 y = y[index] print(X) print(y) print(X.shape) print(y.shape) k_fold_validation(X, y)if __name__ == \"__main__\": main() 主体部分 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556import cv2import numpy as npfrom PIL import Image, ImageDraw, ImageFontfrom getData import read_imagesfrom knn import knnfrom tensorflow.keras import modelsdef cv2ImgAddText(img, text, left, top, textColor=(0, 255, 0), textSize=20): img = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)) draw = ImageDraw.Draw(img) fontText = ImageFont.truetype( \"SimHei.ttf\", textSize, encoding=\"utf-8\") draw.text((left, top), text, textColor, font=fontText) return cv2.cvtColor(np.asarray(img), cv2.COLOR_RGB2BGR)def face_rec(): # 人脸识别 [X, y], label2name = read_images('./data/at') print(\"label2name: \", label2name) X = np.array(X) Xx = X.reshape(X.shape[0], 40000) xdata, label = Xx, y y = np.asarray(y, dtype=np.int32) face_cascade = cv2.CascadeClassifier( # 分类器检测人脸 './cascades/haarcascade_frontalface_default.xml' ) videoCapture = cv2.VideoCapture(0) model = models.load_model('dense_model_6.h5') while True: read, img = videoCapture.read() img = cv2.flip(img, 1) faces = face_cascade.detectMultiScale(img, 1.3, 5) for (x, y, w, h) in faces: img = cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2) gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) roi = gray[x: x+2, y: y+h] roi = cv2.resize(roi, (200, 200), interpolation=cv2.INTER_LINEAR) roi = np.array(roi).reshape(40000, ) prediction = model.predict(np.array([roi])) # print(np.shape(roi)) print(\"dnn predict result :\", prediction) index = np.argmax(prediction) # 最大值所在的索引 name = label2name[index] print(\"检测到%s\" % name) img = cv2ImgAddText(img, name, x, y - 20, (255, 255, 0), 20) cv2.imshow('camera', img) if cv2.waitKey(1000 // 12) &amp; 0xff == ord(\"q\"): break cv2.destroyAllWindows()if __name__ == \"__main__\": face_rec() # 人脸识别 一些小知识点opencv putText无法写中文putText()不能直接写上中文，那就用PIL库曲线救国了。下面是一个demo。 1234567891011121314151617181920#coding=utf-8#中文乱码处理import cv2import numpyfrom PIL import Image, ImageDraw, ImageFontdef cv2ImgAddText(img, text, left, top, textColor=(0, 255, 0), textSize=20): img = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)) draw = ImageDraw.Draw(img) fontText = ImageFont.truetype( \"SimHei.ttf\", textSize, encoding=\"utf-8\") draw.text((left, top), text, textColor, font=fontText) return cv2.cvtColor(numpy.asarray(img), cv2.COLOR_RGB2BGR)img = cv2.imread('./test.png')img = cv2ImgAddText(img, \"你好世界\", 140, 60, (255, 255, 0), 20)cv2.imshow('image', img)cv2.waitKey(0)cv2.destroyAllWindows() 二值化图片使用cv2.threshold()函数，设置cv2.THRESH_BINARY参数进行二值化。可以设置阈值。 1234567891011import cv2import numpy as npimg = cv2.imread('test.jpg')# img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)cv2.imwrite('test.jpg', cv2.Canny(img, 50, 120))cv2.imshow('canny', cv2.imread('test.jpg'))ret, img = cv2.threshold(img, 110, 255, cv2.THRESH_BINARY)cv2.imshow('binary', img)cv2.waitKey()cv2.destroyAllWindows() 路径目录测试由于代码文件和图片文件中间隔了两个文件夹，且图片所在文件夹名称代表图片标签名称，所以如何遍历文件夹，读取到有用的信息是个技术活。 1234567891011import ospath = './data'for dirname, dirnames, filenames in os.walk(path): for subdirname in dirnames: subject_path = os.path.join(dirname, subdirname) # print(subject_path) for filename in os.listdir(subject_path): if filename[-4:] == '.pgm': filepath = os.path.join(subject_path, filename) print(filepath) np.random.shuffle() 测试np.random.shuffle() 能够将某一迭代对象进行打乱。会直接改变传递给他的对象，而不会返回值，需要注意。 用这个函数，生成索引的随机排列，可以很方便的得到打乱的数据和标签，从而更好的进行训练。 123456789101112import numpy as npa = range(0, 10)print(a)print(type(a[9]))print(np.array(a))index = np.array(a)np.random.shuffle(index)print(index)index = np.arange(7)print(index) keras保存和恢复模型from tensorflow.keras import modelsmodel.save(&#39;dense_model_7.h5&#39;)model = models.load_model(&#39;dense_model_6.h5&#39;)就不用每次都重新训练了。","categories":[{"name":"深度学习","slug":"深度学习","permalink":"https://fiveplus.top/categories/深度学习/"}],"tags":[{"name":"人脸识别","slug":"人脸识别","permalink":"https://fiveplus.top/tags/人脸识别/"},{"name":"opencv","slug":"opencv","permalink":"https://fiveplus.top/tags/opencv/"}],"author":"姬小野"},{"title":"Anaconda虚拟环境及PyCharm项目环境设置","slug":"Anaconda虚拟环境及PyCharm项目环境设置","date":"2019-05-04T16:00:00.000Z","updated":"2019-09-14T10:47:01.545Z","comments":true,"path":"2019/05/05/anaconda-xu-ni-huan-jing-ji-pycharm-xiang-mu-huan-jing-she-zhi/","link":"","permalink":"https://fiveplus.top/2019/05/05/anaconda-xu-ni-huan-jing-ji-pycharm-xiang-mu-huan-jing-she-zhi/","excerpt":"","text":"Anaconda虚拟环境1、创建环境conda create --name your_env_name python=3.6或者conda create -n your_env_name python=3.7新建一个环境 2、查看环境进入Anaconda Prompt，使用conda info -e查看所有环境和当前环境 3、激活环境使用activate py36 激活虚拟环境 4、复制环境老环境到新的环境中conda create --name new_env_name --clone old_env_name 5、删除某个环境conda remove --name your_env_name --all 6、导出和导入环境（分享）切换到了要导出的环境之后，使用命令conda env export &gt; environment.yml将当前环境导出 使用命令conda env create -f environment.yml建立（导入）新的环境 7、查看指定环境的包conda list -n your_env_name 8、为某个指定环境安装包conda install -n env_name package_name 9、添加conda虚拟环境为jupyter kernelconda install ipykernelpython -m ipykernel install --user --name 环境名称 --display-name 名称(不需要引号)注意这个命令要在安装了ipykernel的环境下进行。如果出一些奇怪的故障，重启jupyter notebook。 参考：https://blog.csdn.net/menc15/article/details/71477949/ 10、ubuntu 中的激活环境用命令source activate env-name 因为最近使用opencv，4版本的有很多不兼容的地方，所以我安装一个3.4版本的虚拟环境。编辑批量安装包 123opencv-python==3.4.2.16pip install opencv-contrib-python==3.4.2.16numpy 使用命令pip install -r requirements.txt 安装 PyCharm项目环境配置之前每次新建一个PyCharm项目，他给我的环境都是一个新的虚拟环境，所以很不方便而且还要项目文件很冗余，打开项目的速度又慢。于是设置了默认的本地python环境。 1、找到file-&gt;settings-&gt;project interpreter，里面有很多的project interpreter。点击右边的设置，然后点击+，即可添加新的环境。如果他没有检索到我们使用的python环境，就需要手动添加。2、选择Existing environment，从目录里面选择自己需要使用的python环境。如我在anaconda里面添加的新的虚拟环境就在下面这个目录下，找到python.exe添加即可。3、需要注意的是，在我的电脑里面，C:\\ProgramData这个目录默认是隐藏的，所以无法直接从pycharm中找到这个目录。只需要找到这个隐藏文件夹，取消隐藏即可。4、选择好了环境之后，我们可以设置当前项目的环境 5、在新建一个项目时，我们可以设置环境为已存在的，找到目录中这个环境，并勾选对所有项目生效。这样我们的默认环境设置就大功告成了。","categories":[{"name":"开发工具","slug":"开发工具","permalink":"https://fiveplus.top/categories/开发工具/"}],"tags":[{"name":"开发工具","slug":"开发工具","permalink":"https://fiveplus.top/tags/开发工具/"},{"name":"Anaconda","slug":"Anaconda","permalink":"https://fiveplus.top/tags/Anaconda/"}],"author":"姬小野"},{"title":"随机树生成算法（就是树！）","slug":"随机树生成算法（就是树！）","date":"2019-04-01T16:00:00.000Z","updated":"2019-08-15T09:28:00.034Z","comments":true,"path":"2019/04/02/sui-ji-shu-sheng-cheng-suan-fa-jiu-shi-shu/","link":"","permalink":"https://fiveplus.top/2019/04/02/sui-ji-shu-sheng-cheng-suan-fa-jiu-shi-shu/","excerpt":"","text":"一个生成随机树（此树非彼数）的算法，树的结点编号从1开始，这个算法生成了树的结点个数、树的结点的权值、树的每条边的结点。如下面是一棵10结点的二叉树的生成结果： 123456789101110-23 -44 -51 -9 13 51 62 11 -63 19 6 96 49 29 34 74 12 52 83 10 第一次更新想到一种O(n)复杂度的随机树生成算法。 设想有树结点1、2、3、4、5，生成它们的一个随机排列，如4、1、3、5、2；那么，如果我们设定每个结点的子节点数量为2，或者设置其他区间（如[1, 3]）。那么根节点就是4，它的子节点为1、3，以BFS的方式遍历生成子节点，1的子节点为5、2，就可以生成随机树了。 生成随机排列的算法复杂度为O(n)。对于a[0], a[1], a[2], a[3], a[4]，如何生成随机排列？获得x = random(0, 3)，（区间[0, 3]的下标），然后交换a[x], a[3]，就生成了一个随机值接下来，x = random(0, 2),然后交换a[x], a[2]不断地依次生成，就可以得到一个随机排列，且时间复杂度为O(n)。 所以整个算法的时间复杂度为O(n)。 下面的代码将生成随机排列和BFS遍历的过程融合在了一起，建议分开实现，更加清晰、模块化。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647#include &lt;iostream&gt;#include &lt;fstream&gt;#include &lt;cstdlib&gt;#include &lt;queue&gt;#define random(a, b) rand()%(b-a+1) + ausing namespace std;void creatData(int n, string filename) &#123; fstream file(filename.c_str(), ios::out); int *tree = new int [n]; for (int i = 0; i &lt; n; ++i) &#123; tree[i] = i + 1; &#125; int root = random(0, n - 1); swap(tree[root], tree[n - 1]); int nxt_idx = n - 2; queue&lt;int&gt; Que; file &lt;&lt; n &lt;&lt; endl; for (int i = 0; i &lt; n; ++i) &#123; file &lt;&lt; random(-1024, 1024) &lt;&lt; ' '; &#125; file &lt;&lt; endl; Que.push(tree[n - 1]); while (!Que.empty()) &#123; int now = Que.front(); Que.pop(); int cnt = random(1, 3); for (int i = 0; i &lt; cnt; ++i) &#123; int tmp_idx = random(0, nxt_idx); swap(tree[tmp_idx], tree[nxt_idx]); file &lt;&lt; now &lt;&lt; ' ' &lt;&lt; tree[nxt_idx] &lt;&lt; endl; Que.push(tree[nxt_idx]); nxt_idx--; if (nxt_idx == -1) break; &#125; if (nxt_idx == -1) break; &#125;&#125;int main()&#123; creatData(10, \"creatTree10.txt\"); creatData(1000, \"creatTree1000.txt\"); creatData(10000, \"creatTree10000.txt\"); creatData(100000, \"creatTree100000.txt\"); creatData(1000000, \"creatTree1000000.txt\");&#125; 原文思路是将结点编号1-n push进vector中，然后随机选一个点为root，并从vector中删除这个点。然后使用基于BFS的方式，从root扩展，随机选在（m, n）区间的子节点个数，同时使用随机方法获取在剩余的vector中获取子节点编号，然后从vector中删除。就这样不断地扩散，当vector的size为0时，说明无子节点可选，从而可以结束算法。 可以设置子节点的随机范围，结点权值的随机范围。 需要注意的是，该算法时间复杂度大概高达O(n^2)，生成100000个数据要40+s，所以要生成更大规模的数据需要较长的时间。 代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960#include &lt;iostream&gt;#include &lt;vector&gt;#include &lt;cstdlib&gt;#include &lt;queue&gt; #include &lt;fstream&gt;#define random(a, b) rand()%(b-a+1) + ausing namespace std;vector&lt;int&gt; que;queue&lt;int&gt; seq;void deleteOne(int one) &#123; vector&lt;int&gt;::iterator it = que.begin(); while (it != que.end()) &#123; if (*it == one) &#123; que.erase(it); break; &#125; it++; &#125;&#125;void creat(int n, string filename) &#123; que.clear(); fstream outfile(filename.c_str(), ios::out); outfile &lt;&lt; n &lt;&lt; endl; for (int i = 1; i &lt;= n; ++i) &#123; int x = random(-64, 64); outfile &lt;&lt; x &lt;&lt; ' '; que.push_back(i); &#125; outfile &lt;&lt; endl; int root = random(0, n - 1); root = que[root];// outfile &lt;&lt; \"root = \" &lt;&lt; root &lt;&lt; endl; deleteOne(root); seq.push(root); while (que.size()) &#123; int now = seq.front(); seq.pop(); int ns = random(2, 2); // 将子节点范围取做（2，2）就生成了二叉树 int len = que.size(); for (int i = 0; i &lt; ns; ++i) &#123; int x = random(0, len - 1); outfile &lt;&lt; now &lt;&lt; ' ' &lt;&lt; que[x] &lt;&lt; endl; seq.push(que[x]); deleteOne(que[x]); len--; if (len == 0) break; &#125; &#125;&#125;int main()&#123; creat(10, \"creatTree10.txt\"); creat(1000, \"creatTree1000.txt\"); creat(10000, \"creatTree10000.txt\"); creat(100000, \"creatTree100000.txt\");&#125;","categories":[{"name":"算法","slug":"算法","permalink":"https://fiveplus.top/categories/算法/"}],"tags":[{"name":"随机树","slug":"随机树","permalink":"https://fiveplus.top/tags/随机树/"}],"author":"姬小野"},{"title":"hands-on-ml chapter2 笔记1","slug":"handson-ml-Chp2","date":"2019-03-30T15:06:26.000Z","updated":"2019-08-15T05:38:19.655Z","comments":true,"path":"2019/03/30/handson-ml-chp2/","link":"","permalink":"https://fiveplus.top/2019/03/30/handson-ml-chp2/","excerpt":"","text":"批量学习（batch learning），一次性批量输入给学习算法，可以被形象的称为填鸭式学习。在线学习（online learning），按照顺序，循序的学习，不断的去修正模型，进行优化。 batch learning 如果数据很大的话，可以使用MapReduce技术，或者使用online learning。 performance measure 使用RMSE（root mean square error），也就是均方根误差。看https://www.jianshu.com/p/9ee85fdad150 。学到了root 是根号的意思。 hypothesis ：假设outlier ：异常值 有很多异常值（很大）的话，可能倾向于用MAE。 RMSE 和 MAE 都是测量预测值和目标值两个向量距离的方法。有多种测量距离的方法，或范数：计算对应欧几里得范数的平方和的根（RMSE）：这个距离介绍过。它也称作ℓ2范数，标记为 （或只是 ）。计算对应于ℓ1（标记为 ）范数的绝对值和（MAE）。有时，也称其为曼哈顿范数，因为它测量了城市中的两点，沿着矩形的边行走的距离。更一般的，包含n个元素的向量v的ℓk范数（K 阶闵氏范数），定义成 ℓ0（汉明范数）只显示了这个向量的基数（即，非零元素的个数），ℓ∞（切比雪夫范数）是向量中最大的绝对值。 范数的指数越高，就越关注大的值而忽略小的值。这就是为什么 RMSE 比 MAE 对异常值更敏感。但是当异常值是指数分布的（类似正态曲线），RMSE 就会表现很好。 entry ：条目，entrieshistogram ：统计直方图histogram ：后端 数据可能经过预处理，这不一定会出错，但你得知道数据是怎么来的。 feature scaling ：特征缩放 如果右边的属性很长，会处理这些属性，使其变为正态分布。 P49：生成随机排列以获得比较随机的train和test集划分。random seed控制结果。P50：使用hash方法来生成稳定的train、test集，当得到新的数据时，原来的划分保持不变，新的实例同样进行划分。调用的库是hashlib，可以稍微研究一下python中的hash方法。增加一列索引index。可以使用scikit learn提供的函数 P51：讲到要使用分层采样，因为不同层次的样本数量是不一样的，如果全都随机采样的话，误差会比较大。strata：层stratify：分层使用sklearn提供的分层类，配合pandas的where等，分层正确可以获得较大的性能提升。还可以查看分层比例。 pandas的where方法 Series.where(cond, other=nan, inplace=False, axis=None, level=None, errors=‘raise’, try_cast=False, raise_on_error=None)如果 cond 为真，保持原来的值，否则替换为other， inplace为真标识在原数据上操作，为False标识在原数据的copy上操作。 insight：见解，洞察力density：密度 分析数据，数据的可视化：可以得到数据之间的联系，哪些数据更有用，从而更加有技巧地进行训练；而且，从数据的可视化中，就可以得出一些只是看数据得不到的结论，图像能使信息暴露出来，所以matplotlib在机器学习中会有那么重要的作用，而看到的哪些讲机器学习的书、比赛的notebook，他们都有大量的数据可视化，这是呈现数据，探索数据的过程，也是：为什么此模型能够比其他人的模型更加强大的原因。但是数据分析有套路，要多看熟悉这些套路。 alpha参数的作用：它是一个设置透明度的参数。看到书上用它时，觉得没啥用啊，不是每个点都会设置一样的透明度吗？但是转念一想，存在透明度的话，点多的地方，颜色就会深，而点少的地方颜色就会浅。这就是透明度的作用啊！ correlation：相关；关联median：中位数coefficient：率；系数correlation coefficient：相关系数 可以使用corr方法获取属性两两之间的（linear）相关性。（可以说是很强了！没想到居然还提供了这种方法。不过相关系数是怎么计算的？）得到了相关性，然后呢？有什么作用吗？书上说：想要移除掉相关性大的属性，避免重复。所谓数据清洗。 属性的结合，可能会获取更加有效的数据。 数据清洗：missing features三种策略sklearn提供了一种Imputer类来实现确实数据的填充 要设计自己的读取、划分数据函数，一种通用的方法，能够对不同的数据进行划分。 想到一个问题：如何将自己写的类，在python中import？就像numpy那样？但是numpy不是一个类而是一个包，那么如何制作自己的包？ interfeace：接口 P61讲述了sklearn的设计风格评估器、转换器等的设计模式，统一性。 将文本属性转化成数字。标签编码。 sklearn.preprocessing 独热编码OneHotEncoder sparse matrix：稀疏矩阵。书上一般说SciPy sparse matrix text attribute -&gt; num -&gt; one hot; text -&gt; one hot; 可选scipy 设计自定义的transformers，三种method，fit，transform，fit_transform。使用两个基类，提供一些功能。 feature scaling：特征缩放normalization、standardization(less attected by outliers)只能向数据集拟合：这样更准确。 pipelines class数值属性和文本属性的特征可以分开设置pipeline，然后可以使用FeatureUnion来合并，真是方便！不过这个pipeline的设计有点麻烦。 选择模型、拟合、计算error。underfitting and overfittingcross validation：交叉验证。比较可靠的评估方式。utility function：效用函数。越大越好cost function：成本函数。越小越好 overfitting的可怕，还以为放出决策树回归出来会吊打线性回归呢，结果被吊打了，哈哈。 ensemble learning：集成学习。如random forests 把模型和训练结果保存下来，以便以后的对比。可以使用pickle，或者sklearn.externals.joblib。可以说是很方便了。 fine tune：微调 超参数：hyperparameter 在机器学习的上下文中，超参数是在开始学习过程之前设置值的参数，而不是通过训练得到的参数数据。通常情况下，需要对超参数进行优化，给学习机选择一组最优超参数，以提高学习的性能和效果。在机器学习的上下文中，超参数是在开始学习过程之前设置值的参数。 相反，其他参数的值通过训练得出。超参数：定义关于模型的更高层次的概念，如复杂性或学习能力。不能直接从标准模型培训过程中的数据中学习，需要预先定义。可以通过设置不同的值，训练不同的模型和选择更好的测试值来决定 超参数的一些示例： 树的数量或树的深度 矩阵分解中潜在因素的数量 学习率（多种模式） 深层神经网络隐藏层数 k均值聚类中的簇数 amazing Grid Search！直译是网格搜索，但是显然不能这么理解。这是sklearn提供的一种超级方便的选择hyperparameter的工具，简直是开挂啊。fine tune果然不赖。还有一些分析的技巧。不过话说想要选好一组适合的超参数要训练好多组啊。甚至直接获取the best estimator Randomized Search 和 Gird相比，有几个有点。但目的和作用是一样的。 Ensemble Method 集成方法 分析最佳模型和他们的误差，可以获得更深的对问题的理解。比如可以给出每个属性对于做出准确预测的相对重要性，然后去掉某些属性，是否会使得分类更加准确。 maintain：维护","categories":[{"name":"机器学习","slug":"机器学习","permalink":"https://fiveplus.top/categories/机器学习/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://fiveplus.top/tags/机器学习/"}]},{"title":"csapp datalab实验","slug":"csapp-datalab实验","date":"2019-03-29T08:54:16.000Z","updated":"2019-08-15T05:49:25.595Z","comments":true,"path":"2019/03/29/csapp-datalab-shi-yan/","link":"","permalink":"https://fiveplus.top/2019/03/29/csapp-datalab-shi-yan/","excerpt":"datalab 实验 代码如下","text":"datalab 实验 代码如下 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389/* * CS:APP Data Lab * * &lt;Please put your name and userid here&gt; * * bits.c - Source file with your solutions to the Lab. * This is the file you will hand in to your instructor. * * WARNING: Do not include the &lt;stdio.h&gt; header; it confuses the dlc * compiler. You can still use printf for debugging without including * &lt;stdio.h&gt;, although you might get a compiler warning. In general, * it's not good practice to ignore compiler warnings, but in this * case it's OK. */#if 0/* * Instructions to Students: * * STEP 1: Read the following instructions carefully. */You will provide your solution to the Data Lab byediting the collection of functions in this source file.INTEGER CODING RULES: Replace the \"return\" statement in each function with one or more lines of C code that implements the function. Your code must conform to the following style: int Funct(arg1, arg2, ...) &#123; /* brief description of how your implementation works */ int var1 = Expr1; ... int varM = ExprM; varJ = ExprJ; ... varN = ExprN; return ExprR; &#125; Each \"Expr\" is an expression using ONLY the following: 1. Integer constants 0 through 255 (0xFF), inclusive. You are not allowed to use big constants such as 0xffffffff. 2. Function arguments and local variables (no global variables). 3. Unary integer operations ! ~ 4. Binary integer operations &amp; ^ | + &lt;&lt; &gt;&gt; Some of the problems restrict the set of allowed operators even further. Each \"Expr\" may consist of multiple operators. You are not restricted to one operator per line. You are expressly forbidden to: 1. Use any control constructs such as if, do, while, for, switch, etc. 2. Define or use any macros. 3. Define any additional functions in this file. 4. Call any functions. 5. Use any other operations, such as &amp;&amp;, ||, -, or ?: 6. Use any form of casting. 7. Use any data type other than int. This implies that you cannot use arrays, structs, or unions. You may assume that your machine: 1. Uses 2s complement, 32-bit representations of integers. 2. Performs right shifts arithmetically. 3. Has unpredictable behavior when shifting an integer by more than the word size.EXAMPLES OF ACCEPTABLE CODING STYLE: /* * pow2plus1 - returns 2^x + 1, where 0 &lt;= x &lt;= 31 */ int pow2plus1(int x) &#123; /* exploit ability of shifts to compute powers of 2 */ return (1 &lt;&lt; x) + 1; &#125; /* * pow2plus4 - returns 2^x + 4, where 0 &lt;= x &lt;= 31 */ int pow2plus4(int x) &#123; /* exploit ability of shifts to compute powers of 2 */ int result = (1 &lt;&lt; x); result += 4; return result; &#125;FLOATING POINT CODING RULESFor the problems that require you to implent floating-point operations,the coding rules are less strict. You are allowed to use looping andconditional control. You are allowed to use both ints and unsigneds.You can use arbitrary integer and unsigned constants.You are expressly forbidden to: 1. Define or use any macros. 2. Define any additional functions in this file. 3. Call any functions. 4. Use any form of casting. 5. Use any data type other than int or unsigned. This means that you cannot use arrays, structs, or unions. 6. Use any floating point data types, operations, or constants.NOTES: 1. Use the dlc (data lab checker) compiler (described in the handout) to check the legality of your solutions. 2. Each function has a maximum number of operators (! ~ &amp; ^ | + &lt;&lt; &gt;&gt;) that you are allowed to use for your implementation of the function. The max operator count is checked by dlc. Note that '=' is not counted; you may use as many of these as you want without penalty. 3. Use the btest test harness to check your functions for correctness. 4. Use the BDD checker to formally verify your functions 5. The maximum number of ops for each function is given in the header comment for each function. If there are any inconsistencies between the maximum ops in the writeup and in this file, consider this file the authoritative source./* * STEP 2: Modify the following functions according the coding rules. * * IMPORTANT. TO AVOID GRADING SURPRISES: * 1. Use the dlc compiler to check that your solutions conform * to the coding rules. * 2. Use the BDD checker to formally verify that your solutions produce * the correct answers. */#endif/* * bitAnd - x&amp;y using only ~ and | * Example: bitAnd(6, 5) = 4 * Legal ops: ~ | * Max ops: 8 * Rating: 1 */int bitAnd(int x, int y) &#123; return ~((~x)|(~y));&#125;/* * getByte - Extract byte n from word x * Bytes numbered from 0 (LSB) to 3 (MSB) * Examples: getByte(0x12345678,1) = 0x56 * Legal ops: ! ~ &amp; ^ | + &lt;&lt; &gt;&gt; * Max ops: 6 * Rating: 2 */ int getByte(int x, int n) &#123; int tmp = ((x &lt;&lt; ((4 + (~n)) &lt;&lt; 3)) &gt;&gt; 24); return tmp&amp;0x000000ff;&#125;/*????Byte???????????????????24????????????????????n????????????????(3 - n = 3 + ~n + 1) &lt;&lt; 3????????*//* * logicalShift - shift x to the right by n, using a logical shift * Can assume that 0 &lt;= n &lt;= 31 * Examples: logicalShift(0x87654321,4) = 0x08765432 * Legal ops: ! ~ &amp; ^ | + &lt;&lt; &gt;&gt; * Max ops: 20 * Rating: 3 */int logicalShift(int x, int n) &#123; int t = (0x1 &lt;&lt; 31) ^ ((!n) &lt;&lt; 31); return (x &gt;&gt; n) &amp; ~(t &gt;&gt; (n + ~1 + 1));&#125;/*??????????????????????1???????n = 0?????????????????*//* * bitCount - returns count of number of 1's in word * Examples: bitCount(5) = 2, bitCount(7) = 3 * Legal ops: ! ~ &amp; ^ | + &lt;&lt; &gt;&gt; * Max ops: 40 * Rating: 4 */int bitCount(int x) &#123; // ??????????????2?4?8?16?32?01??1???? int bitcount; int tmp1 = (0x55)|(0x55&lt;&lt;8); int mask1 = (tmp1)|(tmp1&lt;&lt;16); //????? 01010101��01010101 int tmp2 = (0x33)|(0x33&lt;&lt;8); int mask2 = (tmp2)|(tmp2&lt;&lt;16); //????? 00110011��00110011 int tmp3 = (0x0f)|(0x0f&lt;&lt;8); int mask3 = (tmp3)|(tmp3&lt;&lt;16); //????? 00001111��00001111 int mask4 = (0xff)|(0xff&lt;&lt;16); //????? 0000 0000 1111 1111 0000 0000 1111 1111 int mask5 = (0xff)|(0xff&lt;&lt;8); //????? 0000 0000 0000 0000 1111 1111 1111 1111 bitcount = (x &amp; mask1) + ((x&gt;&gt;1) &amp; mask1); //??????2??????1??????????2??????1???????? bitcount = (bitcount &amp; mask2) + ((bitcount &gt;&gt; 2) &amp; mask2); bitcount = (bitcount + (bitcount &gt;&gt; 4)) &amp; mask3; bitcount = (bitcount + (bitcount &gt;&gt; 8)) &amp; mask4; bitcount = (bitcount + (bitcount &gt;&gt; 16)) &amp; mask5; return bitcount;&#125;/* * bang - Compute !x without using ! * Examples: bang(3) = 0, bang(0) = 1 * Legal ops: ~ &amp; ^ | + &lt;&lt; &gt;&gt; * Max ops: 12 * Rating: 4 */int bang(int x) &#123; int t = ~x + 1; return ((t | x) &gt;&gt; 31) + 1;&#125;//??0??+1????0?????x?0?????31???0?+1?????1. ????????????????????????????????31??????-1?+1?????0./* * tmin - return minimum two's complement integer * Legal ops: ! ~ &amp; ^ | + &lt;&lt; &gt;&gt; * Max ops: 4 * Rating: 1 */int tmin(void) &#123; return 1 &lt;&lt; 31;&#125;// ???????????1????31??????????????????/* * fitsBits - return 1 if x can be represented as an * n-bit, two's complement integer. * 1 &lt;= n &lt;= 32 * Examples: fitsBits(5,3) = 0, fitsBits(-4,3) = 1 * Legal ops: ! ~ &amp; ^ | + &lt;&lt; &gt;&gt; * Max ops: 15 * Rating: 2 */int fitsBits(int x, int n) &#123; // x????n???? ??32-n????32-n????????? int shift = 32 + ~n + 1; int t = x &lt;&lt; shift &gt;&gt; shift; return !(t ^ x);&#125;// x?????n???? ??32-n????32-n????????????????/* * divpwr2 - Compute x/(2^n), for 0 &lt;= n &lt;= 30 * Round toward zero * Examples: divpwr2(15,1) = 7, divpwr2(-33,4) = -2 * Legal ops: ! ~ &amp; ^ | + &lt;&lt; &gt;&gt; * Max ops: 15 * Rating: 2 */int divpwr2(int x, int n) &#123; // ?????????????????????????????????????-5/2 = -3??? int sign = x &gt;&gt; 31; // ?? // cout &lt;&lt; (1 &lt;&lt; n) + ~0 &lt;&lt; endl; // cout &lt;&lt; \"(sign &amp; ((1 &lt;&lt; n) + ~0)) = \" &lt;&lt; (sign &amp; ((1 &lt;&lt; n) + ~0)) &lt;&lt; endl; return (x + (sign &amp; ((1 &lt;&lt; n) + ~0))) &gt;&gt; n;&#125;// ???????0???????????????????-5/2 = -3???????0????????????????????????????????????/* * negate - return -x * Example: negate(1) = -1. * Legal ops: ! ~ &amp; ^ | + &lt;&lt; &gt;&gt; * Max ops: 5 * Rating: 2 */int negate(int x) &#123; return ~x + 1;&#125;// ?????????+1./* * isPositive - return 1 if x &gt; 0, return 0 otherwise * Example: isPositive(-1) = 0. * Legal ops: ! ~ &amp; ^ | + &lt;&lt; &gt;&gt; * Max ops: 8 * Rating: 3 */int isPositive(int x) &#123; return (!((x &gt;&gt; 31) &amp; 1) &amp; !!(x)); // ????????????0 // ????????????????&#125;// ????????????0/* * isLessOrEqual - if x &lt;= y then return 1, else return 0 * Example: isLessOrEqual(4,5) = 1. * Legal ops: ! ~ &amp; ^ | + &lt;&lt; &gt;&gt; * Max ops: 24 * Rating: 3 */int isLessOrEqual(int x, int y) &#123; // ??????????int xl = (x &gt;&gt; 31) &amp; 1;int yl = (y &gt;&gt; 31) &amp; 1;int zl = ((y + ~x + 1) &gt;&gt; 31) &amp; 1; return ((xl ^ yl) &amp; xl) | (!(xl ^ yl) &amp; !zl);&#125;// ??????????????isPositive?????????????????????// ???????????????x&lt;0?y&gt;=0,????????1???????????y-x???????0???x????y?/* * ilog2 - return floor(log base 2 of x), where x &gt; 0 * Example: ilog2(16) = 4 * Legal ops: ! ~ &amp; ^ | + &lt;&lt; &gt;&gt; * Max ops: 90 * Rating: 4 */int ilog2(int x) &#123; // ???????1???+?????&lt;&lt;????????? int id; id = (!!(x &gt;&gt; 16)) &lt;&lt; 4; id = id + ((!!(x &gt;&gt; (id + 8))) &lt;&lt; 3); id = id + ((!!(x &gt;&gt; (id + 4))) &lt;&lt; 2); id = id + ((!!(x &gt;&gt; (id + 2))) &lt;&lt; 1); id = id + ((!!(x &gt;&gt; (id + 1))) &lt;&lt; 0); return id;&#125;// ??????log2?log2n?????????1???????????????1???????16?????????????????id??????id???????+?????&lt;&lt;????????? /* * float_neg - Return bit-level equivalent of expression -f for * floating point argument f. * Both the argument and result are passed as unsigned int's, but * they are to be interpreted as the bit-level representations of * single-precision floating point values. * When argument is NaN, return argument. * Legal ops: Any integer/unsigned operations incl. ||, &amp;&amp;. also if, while * Max ops: 10 * Rating: 2 */unsigned float_neg(unsigned uf) &#123; unsigned tmp = (uf &lt;&lt; 1); if (((tmp &amp; 0xFF000000) == 0xFF000000) &amp;&amp; (tmp != 0xFF000000)) &#123; return uf; &#125; return (uf + 0x80000000);&#125;// 1????????NAN??????????NAN// 2?????????????????????????????????????????????????+1??????????????/* * float_i2f - Return bit-level equivalent of expression (float) x * Result is returned as unsigned int, but * it is to be interpreted as the bit-level representation of a * single-precision floating point values. * Legal ops: Any integer/unsigned operations incl. ||, &amp;&amp;. also if, while * Max ops: 30 * Rating: 4 */unsigned float_i2f(int x) &#123; // ????????????????????????????? int sign, id, shr, mid; unsigned tmp; if (x == 0) return 0; sign = x &amp; 0x80000000; if (sign) x = -x; id = -1; tmp = x; while (tmp) &#123; tmp &gt;&gt;= 1; id++; // x = 5, id = 2, ??????1?? &#125; tmp = x &lt;&lt; (32 - id); // 23???????? shr = (tmp &amp; 0x1ff) &gt;&gt; 1; // ???? tmp = tmp &gt;&gt; 9; // ????? mid = (127 + id) &lt;&lt; 23; // ??? if (shr &gt; 128 || (shr == 128 &amp;&amp; (tmp &amp; 1) == 1)) &#123; tmp = tmp + 1; &#125; return (tmp + mid + sign);&#125;/* * float_twice - Return bit-level equivalent of expression 2*f for * floating point argument f. * Both the argument and result are passed as unsigned int's, but * they are to be interfrpreted as the bit-level representation of * single-precision floating point values. * When argument is NaN, return argument * Legal ops: Any integer/unsigned operations incl. ||, &amp;&amp;. also if, while * Max ops: 30 * Rating: 4 */unsigned float_twice(unsigned uf) &#123; int s = uf &amp; 0x80000000; int e = uf &amp; 0x7f800000; int m = uf &amp; 0x007fffff; int ans = 0; if (e == 0x7f800000) return uf; if (e == 0) ans = s + (m &lt;&lt; 1); else ans = s + e + 0x00800000 + m; return ans;&#125;// ????????????M??????????","categories":[{"name":"计算机系统","slug":"计算机系统","permalink":"https://fiveplus.top/categories/计算机系统/"}],"tags":[{"name":"csapp","slug":"csapp","permalink":"https://fiveplus.top/tags/csapp/"}]},{"title":"汇编与gdb调试学习","slug":"汇编与gdb调试学习","date":"2019-03-09T09:48:59.000Z","updated":"2019-08-15T05:48:40.869Z","comments":true,"path":"2019/03/09/hui-bian-yu-gdb-diao-shi-xue-xi/","link":"","permalink":"https://fiveplus.top/2019/03/09/hui-bian-yu-gdb-diao-shi-xue-xi/","excerpt":"","text":"1、在gdb中如何列出汇编代码应该是不可以用list 命令列出汇编代码的。但可以使用display /i $pc 命令在调试的时候出了列出一行源码，也列出相应的汇编代码同时，s和si等的区别还是比较大的：si按汇编一行一行执行，有的源码一行会有很多条汇编；我认为这是个学习汇编的好方法：使用gdb一步一步调试，对比汇编和源码 2、如何将一个可执行文件或者是.o文件得到它的汇编码或者是源码？可以使用objdump -d test.out 获取汇编代码（右侧）以及机器码（左侧）；要查看但里面有很多除我写的东西之外的东西，要具体定位到自己写的东西，可根据函数名查看。 如果编译时使用了-g参数的话，使用objdump -dS test 就可以得到机器码，源码，汇编码一一对应了！但如果没用-g的话，可执行文件是没有源码信息的，这时需要通过特殊手段得到。 3、将c源码变成.o文件，会不会很干净，和变成可执行文件的区别？体量？编译过程图，来源：https://blog.csdn.net/misskissC/article/details/38020151和期待的相符，没有目标文件的链接过程，.o 文件果然很干净，使用-d命令查看的话，可以只看我自己写的代码部分！但是没有 -g 的话没有源码。同样和期待的相符，加了-g之后，成功出现源码 4、c代码变成.s文件，如何精确捕捉到我写的函数的内容？额，我发现.s 文件还是非常干净的，没有什么特别多的其他文件，想要找哪个函数，前面都有名字的。 尝试是由-g会有什么区别码？加了-g 参数后，生成的.s 文件果然多了很多不认识的东西，仔细找了下后，发现并没有看到源码的字符串，可能是以某种特殊的方式编码了？如图是对比，左侧是加了 -g的，而右侧是没有加的。我们来验证以下，这个加了-g的.s文件，是否真的是包含了我源码的信息？ 验证通过，确实有，哈哈 5、各种情况的编译失败是在编译的过程是哪一步？在编译c语言的时候，通常是一步全编译，我们来尝试分部编译，探究不同错误的编译失败地点。1、如果我只是写一个函数而没有main函数，可以进行到哪一步？编译成汇编代码居然就报错了！预处理的话还是可以的 2、不小心没写分号 ;额，看来还是这个源码变成汇编的过程过程我突然想到，整个编译的大过程分为预处理-&gt;编译-&gt;汇编-&gt;链接，那么可能语法问题之类的都是在编译这个小过程被发现的吧。 6、list命令用法默认显示10行，可使用list 1,1000 来获取更多行的代码使用list +/- 用以继续，和查看更前的源码set listsize 20 设置显示行数show listsize 查看显示行数 7、删除断点：d b查看断点：info binfo watch 查表","categories":[{"name":"计算机系统","slug":"计算机系统","permalink":"https://fiveplus.top/categories/计算机系统/"}],"tags":[{"name":"汇编","slug":"汇编","permalink":"https://fiveplus.top/tags/汇编/"},{"name":"gdb","slug":"gdb","permalink":"https://fiveplus.top/tags/gdb/"}]},{"title":"python查看包版本、全部可更新包、更新单个包、更新全部包","slug":"python查看包版本、全部可更新包、更新单个包、更新全部包","date":"2019-03-06T16:00:00.000Z","updated":"2019-08-15T09:34:24.867Z","comments":true,"path":"2019/03/07/python-cha-kan-bao-ban-ben-quan-bu-ke-geng-xin-bao-geng-xin-dan-ge-bao-geng-xin-quan-bu-bao/","link":"","permalink":"https://fiveplus.top/2019/03/07/python-cha-kan-bao-ban-ben-quan-bu-ke-geng-xin-bao-geng-xin-dan-ge-bao-geng-xin-quan-bu-bao/","excerpt":"","text":"一、如何查看python某个包的版本？1、pip list // 全部，在里面找 2、pip freeze // 全部 3、pip show numpy // 单个 4、conda list numpy // 单个 二、列出全部outdated（可更新）的包pip list --outdated --format=legacy pip list --outdated --format=columns 这两个命令的区别是列表的方式不一样。且他们的命令执行时间都非常的长。 三、更新单个包如numpypip install --upgrade numpy 或者 pip install -U numpy 四、更新全部包需要用到一个叫pip-review的执行程序 首先通过pip下载pip install pip-review 然后执行以下命令：pip-review --local --interactive 或者执行下面python程序 1234from pip._internal.utils.misc import get_installed_distributionsfrom subprocess import callfor dist in get_installed_distributions(): call(\"pip install --upgrade \" + dist.project_name, shell=True) :（ 不过更新全部包不是非常靠谱，毕竟更新一个包都经常出问题！何况是更新所有的。 五、卸载包的方法和安装的方法类似 pip uninstall numpy","categories":[{"name":"开发工具","slug":"开发工具","permalink":"https://fiveplus.top/categories/开发工具/"}],"tags":[{"name":"开发工具","slug":"开发工具","permalink":"https://fiveplus.top/tags/开发工具/"},{"name":"Anaconda","slug":"Anaconda","permalink":"https://fiveplus.top/tags/Anaconda/"}],"author":"姬小野"},{"title":"Ubuntu常见命令及使用技巧","slug":"Ubuntu常见命令及使用技巧","date":"2019-03-01T16:00:00.000Z","updated":"2019-08-15T05:50:04.158Z","comments":true,"path":"2019/03/02/ubuntu-chang-jian-ming-ling-ji-shi-yong-ji-qiao/","link":"","permalink":"https://fiveplus.top/2019/03/02/ubuntu-chang-jian-ming-ling-ji-shi-yong-ji-qiao/","excerpt":"","text":"一个查询Linux命令比较方便的网址http://man.linuxde.net/ 1、在ubuntu 12.04系统中，使用Ctrl+Alt+F1~6切换到shell，使用Ctrl+Alt+F7切换到图形界面 2、使用touch新建一个文件 3、在命令前使用sudo获取root权限 4、使用nano进入nano编辑器，比用vi进入的vim编辑器使用更简便 5、安装g++使用 sudo apt-get install g++ 6、查看gcc位置使用 which gcc 7、使用rm删除文件 8、使用mv移动文件，也可以移动目录 9、g++编译文件时，-o参数给文件命名， g++ test.cpp -o program_name 10、ls列出当前目录下的文件列表 11、pwd输出当前工作区目录 12、cd转到某一指定目录 13、mkdir新建目录（文件夹） 14、rmdir删除目录 15、cp复制文件 16、cat在终端上显示文本信息 17、grep文本搜索工具 18、tar文件压缩命令 19、在终端，可以使用shift + PgUp/PgDn 进行翻页 20、在终端，可以将输出的文本重定向到某一文件如see.txt，然后使用cat（或其他）查看，然后使用cat see.txt | more，或者cat see.txt | less. 一页一页查看 21、exit，终止当前的终端会话 22、who显示目前登录系统的用户信息 23、ping测试网络 24、ctrl + q 退出程序 25、axel与aria2c据说比wget更快的多线程下载。 26、sudo dpkg -i 软件包名.deb 安装deb文件","categories":[{"name":"操作系统","slug":"操作系统","permalink":"https://fiveplus.top/categories/操作系统/"}],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"https://fiveplus.top/tags/操作系统/"},{"name":"ubuntu","slug":"ubuntu","permalink":"https://fiveplus.top/tags/ubuntu/"}],"author":"姬小野"},{"title":"高斯朴素贝叶斯方法进行鸢尾花分类","slug":"高斯朴素贝叶斯方法进行鸢尾花分类","date":"2018-11-16T16:00:00.000Z","updated":"2019-08-15T05:48:31.441Z","comments":true,"path":"2018/11/17/gao-si-po-su-bei-xie-si-fang-fa-jin-xing-yuan-wei-hua-fen-lei/","link":"","permalink":"https://fiveplus.top/2018/11/17/gao-si-po-su-bei-xie-si-fang-fa-jin-xing-yuan-wei-hua-fen-lei/","excerpt":"","text":"贝叶斯方法完整代码1234567891011121314151617import seaborn as sns iris = sns.load_dataset('iris')X_iris = iris.drop('species', axis=1)y_iris = iris['species']print(X_iris)from sklearn.cross_validation import train_test_splitXtrain, Xtest, ytrain, ytest = train_test_split(X_iris, y_iris, random_state=1)from sklearn.naive_bayes import GaussianNBmodel = GaussianNB()model.fit(Xtrain, ytrain)y_model = model.predict(Xtest)from sklearn.metrics import accuracy_scoreaccuracy_score(ytest, y_model) 步骤分析一-首先获取数据.这里我们在线导入seaborn库的iris(鸢尾花)数据 12import seaborn as snsiris = sns.load_dataset('iris') 这是github上的说明, 可直接下载csv文件 二-将数据格式化12X_iris = iris.drop('species', axis=1)y_iris = iris['species'] 将类别那一列删除生成新的对象赋值给X_iris, y_iris为分类.pandas的drop方法参考 三-将数据切分为训练数据和测试数据12from sklearn.cross_validation import train_test_splitXtrain, Xtest, ytrain, ytest = train_test_split(X_iris, y_iris, random_state=1) cross validation是交叉验证的意思, 参考文章参数random_state是固定的随机种子, 参考文章 四-调用高斯朴素贝叶斯实现训练1234from sklearn.naive_bayes import GaussianNBmodel = GaussianNB()model.fit(Xtrain, ytrain)y_model = model.predict(Xtest) # 进行预测 调用Gaussian naive Bayes模型, 并进行拟合, 预测 五-对测试结果进行评估评估方法介绍 12from sklearn.metrics import accuracy_scoreaccuracy_score(ytest, y_model) 得到准确率为0.9736842105263158metrics是指标的意思. 说明对特征明显的数据, 即使是非常简单的分类算法也可以高效地进行分析.","categories":[{"name":"机器学习","slug":"机器学习","permalink":"https://fiveplus.top/categories/机器学习/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://fiveplus.top/tags/机器学习/"}],"author":"姬小野"},{"title":"IDA*算法解十六宫格拼图问题","slug":"IDA-star算法解十六宫格拼图问题","date":"2018-09-30T16:00:00.000Z","updated":"2019-08-15T05:49:46.803Z","comments":true,"path":"2018/10/01/ida-star-suan-fa-jie-shi-liu-gong-ge-pin-tu-wen-ti/","link":"","permalink":"https://fiveplus.top/2018/10/01/ida-star-suan-fa-jie-shi-liu-gong-ge-pin-tu-wen-ti/","excerpt":"","text":"IDA*算法, ID(Iterative Deepening)指的是迭代加深. 它的思想是重复进行限制最大深度的深度优先搜索(此限制从某个最小值遍历到最大值), 也称为深度受限搜索. 一般情况下, 为了提高搜索速度, 迭代加深不会记录已搜索过的状态, 但同时, 需要做一些调整, 以避免出现马上回溯到上一状态的情况. IDA*算法的步骤 1) 首先对初始状态进行评估, 评估值作为最小限度, 而最大限度为自己的设置.这个评估值在这个问题中可以用此状态到正确状态的每个位置的曼哈顿距离来表示. 2) 从最小限度到最大限度进行遍历, 此值作为当前dfs的限度值, 这个限度不断在有效范围内递增的过程就称作迭代加深 3) 进行dfs, 调整状态, 将新状态加入到新的dfs中, 直到找到了一个解(由于迭代加深, 此解为最优解). 进行回溯, 加入路径, 算法结束. PS. 如果在限度内都没有找到解, 就输出unsolved. 从上面的分析中可见, 即使是IDA*算法, 其局限性依然很大, 比如它需要设置一个最大限制, 而超出这个限制的状态将无法求解出. 一些解释: 曼哈顿距离预处理, 每个点在另一个位置的曼哈顿距离16*16x坐标距离 abs(i / N - j / N)y坐标距离 abs(i % N - j % N)曼哈顿距离可以将x坐标和y坐标相互独立开来, 且曼哈顿距离是相对的. 而在上面的表达式中, 可以理解为他们以(0, 0)为参照点;即abs((i / N - 0 - (j / N - 0)) 状态的定义在这个IDA*算法中, 每个状态包含了以下信息. 1) 16个数的位置 2) 空格所在位置 3) 当前状态距离正确状态的曼哈顿距离 简单的结构体可实现 dfs难道要遍历所有可能的情况? 不, 别忘了我们是迭代加深(Iterative Deepeni)!所谓迭代, 就是一代一代更迭, 所以, 既然我们确定了最大范围(LIMIT), 那么我们就可以在这个范围里再设置范围限制, 然后搜索(dfs).每当找到了一个解, 这个解就是最优解, 因为更优解在我们之前的搜索中没有出现. 不会绕圈吗?答: 会绕圈, 但是不会有很大影响, 因为我们设置了搜索次数, 所以绕圈多消耗步骤的自然会淘汰掉. 如何理解sum += MDT[i][pz.f[i] - 1];MDT[i][pz.f[i] - 1]这个状态可以理解为, 在第i格位置, 当它的值为pz.f[i]时, 他们的曼哈顿距离之差. 为什么要减一? 因为输入的值为1...15, 而代码中都位置下标都是从0开始的. IDA*完整代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100#include &lt;iostream&gt;#include &lt;cmath&gt;using namespace std;#define N 4#define N2 16#define LIMIT 57static const int dx[4] = &#123;0, -1, 0, 1&#125;;static const int dy[4] = &#123;1, 0, -1, 0&#125;;static const char dir[4] = &#123;'r', 'u', 'l', 'd'&#125;;int MDT[N2][N2];struct Puzzle &#123; int f[N2], space, MD; // 位置, 空格, 曼哈顿距离&#125;;Puzzle state;int limit;int path[LIMIT];int getALLMD(Puzzle pz) &#123; int sum = 0; for (int i = 0; i &lt; N2; ++i) &#123; if (pz.f[i] == N2) continue; sum += MDT[i][pz.f[i] - 1]; &#125; return sum;&#125;bool isSolved() &#123; for (int i = 0; i &lt; N2; ++i) &#123; if (state.f[i] != i + 1) return false; &#125; return true;&#125;bool dfs(int depth, int prev) &#123; if (state.MD == 0) return true; // 搜索到了答案. if (depth + state.MD &gt; limit) return false; // 超过当前迭代限制 int sx = state.space / N; int sy = state.space % N; Puzzle tmp; for (int r = 0; r &lt; 4; ++r) &#123; int tx = sx + dx[r]; int ty = sy + dy[r]; if (tx &lt; 0 || ty &lt; 0 || tx &gt;= N || ty &gt;= N) continue; if (max(prev, r) - min(prev, r) == 2) continue; // 妙! 避免迂回. 减少了很多不必要搜索 tmp = state; state.MD -= MDT[tx * N + ty][state.f[tx * N + ty] - 1]; // 消除原位置的曼哈顿距离 state.MD += MDT[sx * N + sy][state.f[tx * N + ty] - 1]; // 添加新位置的曼哈顿距离, 注意, MDT由非0/16产生 swap(state.f[tx * N + ty], state.f[sx * N + sy]); state.space = tx * N + ty; if (dfs(depth + 1, r)) &#123; // 先搜索, 搜索成功后再添加路径. 巧妙, 值得学习 path[depth] = r; return true; &#125; state = tmp; // 回溯复原 &#125; return false;&#125;string iterative_deepening(Puzzle in) &#123; in.MD = getALLMD(in); for (limit = in.MD; limit &lt;= LIMIT; limit++) &#123; // 绝了, 原来是这样加一个常数 state = in; if (dfs(0, -100)) &#123; string ans = \"\"; for (int i = 0; i &lt; limit; ++i) ans += dir[path[i]]; return ans; &#125; &#125; return \"unsolvable\";&#125;int main()&#123; for (int i = 0; i &lt; N2; ++i) &#123; for (int j = 0; j &lt; N2; ++j) &#123; MDT[i][j] = abs(i / N - j / N) + abs(i % N - j % N); &#125; &#125; Puzzle in; for (int i = 0; i &lt; N2; ++i) &#123; cin &gt;&gt; in.f[i]; if (in.f[i] == 0) &#123; in.f[i] = N2; in.space = i; &#125; &#125; string ans = iterative_deepening(in); if (ans != \"unsolvable\") cout &lt;&lt; ans.size() &lt;&lt; endl; cout &lt;&lt; ans &lt;&lt; endl;&#125; 参考数据: 123456789101112131415161718192021222324252627282930313233346 13 5 28 1 10 123 7 15 914 4 0 11 // 531 2 3 46 7 8 05 10 11 129 13 14 15 // 85 8 9 1410 13 1 612 2 7 154 0 3 11 // 5612 7 2 45 1 0 914 13 6 83 15 10 11 // 475 11 10 713 0 9 314 2 4 81 15 6 12 // 385 1 4 72 0 11 39 6 10 813 14 15 12 // 149 14 13 155 3 11 68 12 2 110 7 4 0 // unsolvable 十六宫格随机数据: 排列置乱算法 123456789101112131415161718192021222324#include &lt;iostream&gt;#include &lt;cstdlib&gt;#include &lt;ctime&gt;#define RAND(l, r) l+(int)(r-l+1)*rand()/(RAND_MAX+1)using namespace std;int main()&#123; srand(time(NULL)); int data[16]; for (int i = 0; i &lt; 16; ++i) &#123; data[i] = i; &#125; for (int i = 15; i &gt;= 0; --i) &#123; int ind = RAND(0, i); swap(data[i], data[ind]); &#125; for (int i = 0; i &lt; 4; ++i) &#123; for (int j = 0; j &lt; 4; ++j) &#123; cout &lt;&lt; data[i*4 + j] &lt;&lt; ' '; &#125; cout &lt;&lt; endl; &#125;&#125;","categories":[{"name":"算法","slug":"算法","permalink":"https://fiveplus.top/categories/算法/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://fiveplus.top/tags/算法/"}],"author":"姬小野"},{"title":"数组中出现次数超过一半的数字","slug":"数组中出现次数超过一半的数字","date":"2018-09-22T16:00:00.000Z","updated":"2019-08-15T05:48:54.927Z","comments":true,"path":"2018/09/23/shu-zu-zhong-chu-xian-ci-shu-chao-guo-yi-ban-de-shu-zi/","link":"","permalink":"https://fiveplus.top/2018/09/23/shu-zu-zhong-chu-xian-ci-shu-chao-guo-yi-ban-de-shu-zi/","excerpt":"","text":"用头脑风暴学算法，对于一个问题，我们不只是要解决它，还要去思考有什么好的方法，差的方法去解决，甚至是一些错误的但可以提供思想借鉴的方法。 此问题“数组中出现次数超过一半的数字”是一道非常经典的算法题，我把它放在算法风暴系列第一篇来解析，探讨学习一个算法的过程，从慢到快，从最直观的方法到脑洞大开的方法，由表面深入本质。 下一篇：算法风暴之二—最小的k个数 问题描述给定一个数组，且已知数组中有一个数出现次数超过一半（严格），请求出这个数。 问题很简单，方法也多样，但什么方法是最好的呢？为什么它最好？各种方法之间有什么优缺点？下面我们一一展开。 方法一：给数组排序这大概是最直观的方法了，最容易想到，也是最多人能够想出来的。如果我们使用快排的话，只需要O(nlogn)的时间就可以找到这个数。 那么思考这样一个问题：给数组排序了，然后怎么找这个数呢？有两种方法 1、从小到大遍历已排序数组，同时统计每个数出现的次数（某个数和上一个数不同则计数置为1），如果出现某个计数超过一半，那么正在计数的数就是所求数。 PS：这种方法可行，相比于快排的时间复杂度是可以忽略的，但是我们还有更好的方法，直击本质。 2、对一个已排好序的序列，出现次数超过一半的数必定是中位数。因此，我们只要输出中位数即可。 复杂度分析：| 时间复杂度 | O(nlogn) ||–|–|| 空间复杂度 | O(n) | 手写快排代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647#include &lt;algorithm&gt;#include &lt;iostream&gt;#include &lt;cstdlib&gt;#include &lt;ctime&gt;#define RAND(start, end) start+(int)(end-start+1)*rand()/(RAND_MAX+1);using namespace std;const int maxn = 10005;int Partition(int *data, int length, int start, int end)&#123; if (start == end) return start; srand((unsigned)time(NULL)); int index = RAND(start, end); swap(data[index], data[end]); int one = start - 1; for (index = start; index &lt; end; ++index) &#123; if (data[index] &lt; data[end]) &#123; ++one; if (one != index) swap(data[one], data[index]); &#125; &#125; ++one; swap(data[one], data[end]); return one;&#125;void QuickSort(int *data, int length, int start, int end)&#123; if (length &lt;= 1) return; int mid = Partition(data, length, start, end); if (mid &gt; start) QuickSort(data, length, start, mid - 1); if (mid &lt; end) QuickSort(data, length, mid + 1, end);&#125;int main()&#123; int n, data[maxn]; cin &gt;&gt; n; for (int i = 0; i &lt; n; ++i) &#123; cin &gt;&gt; data[i]; &#125; QuickSort(data, n, 0, n - 1); cout &lt;&lt; data[n &gt;&gt; 1];&#125; 方法二：桶排序计数如果我们需要统计的数组元素都是正整数呢？那么我们就可以使用桶排序，给他们计数，然后超过数组大小一半的就是结果了。 然而桶排序看上去很简单，“复杂度也不高”，却有很多的限制。 1、首先，数组统计的数需得是可hash的，不然无法将他们在hash数组上计数。但是某些情况，如元素有负值，可进行灵活转化，使其可hash。2、其次，桶排序方法空间换时间，需要消耗额外的空间，取决于数据的范围。3、桶排序并非真的那么快。桶排序的时间复杂度并非是普通的O(n), 它的n指的是最大数据范围，如果有这样一组数据1 100 10000 1000000，那么桶排序将会有至少1000000次循环，且开出1e6的空间，大大浪费资源。 桶排序方法适合数据范围不大，且数据密度较大的数据。非也，则在此问题上算不上好方法。 代码 1234567891011121314151617181920212223#include &lt;iostream&gt;using namespace std;int main()&#123; int n, max_size = 0, ans = 0; cin &gt;&gt; n; int *data = new int[n]; for (int i = 0; i &lt; n; ++i) &#123; cin &gt;&gt; data[i]; max_size = max(max_size, data[i]); &#125; int *hash = new int[max_size + 1]; for (int i = 0; i &lt;= max_size; ++i) hash[i] = 0; for (int i = 0; i &lt; n; ++i) hash[data[i]]++; for (int i = 0; i &lt;= max_size; ++i) if (hash[i] &gt; n &gt;&gt; 1) ans = i; cout &lt;&lt; ans; delete [] data; delete [] hash;&#125; 方法三：巧用栈其实我们可以发现，上面的方法一和方法二，固然是这道题的解法之一，但不是非常具有针对性。也就是说，那两种方法是功能过剩的，而这所谓功能过剩，也正是导致它性能不是最佳的原因。 那么，我们就应该思考某种算法，只针对这个问题，完全的利用好效率。那么就要从题目出发，找蕴含在问题中的本质规律了。 其实这个问题的核心就是：出现次数超过一半。 我们做这样的思考： 假设k就是我们要求的那个数，那么对这个数组，删掉其中任意两个数所剩下的数组，其对应的k值会改变吗？答案是会的。但是，如果删掉任意两个不相同的数呢？答案是不会！ 为什么不会？相信聪明的读者瞬间就明白原因，只需进行简单的推导就可以了。 具体的实现过程就是：每遍历一个数，就将其入栈，同时查询它和栈内前一个元素的大小，如果不同，就同时出栈，否则不变。 以上，就是用栈的方法解决这个问题的核心。 时间复杂度 O(n) 空间复杂度 O(n) 栈实现代码： 123456789101112131415161718192021#include &lt;iostream&gt;using namespace std;int main()&#123; int n; cin &gt;&gt; n; int *data = new int[n]; int *stack = new int[n]; int top = 0; cin &gt;&gt; data[0]; stack[++top] = data[0]; for (int i = 1; i &lt; n; ++i) &#123; cin &gt;&gt; data[i]; stack[++top] = data[i]; if (top &gt; 1 &amp;&amp; stack[top] != stack[top - 1]) top -= 2; &#125; cout &lt;&lt; stack[top]; delete [] data; delete [] stack;&#125; 方法四：找中位数（第n/2大数）从方法一的分析中我们知道，这个数组的中位数就是答案。方法一是通过给所有的数进行排序找出这个中位数，而我们思考，排序是否有些大材小用？找这个中位数的方法是否可以更简单些？ 答案是有的，而且这类问题被称为找第k个数。 思想是快排的思想。时间复杂度为O(n) 利用快排思想，我们可以找出第n/2大的数，同时在第n/2th数左边的数都小于它，右边的数都大于它。这个数就是数组的中位数。 快速排序简称快排，利用分治的思想，在数组中随机选择一个数，然后以这个数为基准，把大于它的数划分到它的右侧，小于它的数划分到它的左侧，并且递归的分别对左右两侧数据进行处理，直到所有的区间都按照这样的规律划分好。 那么在这个问题中，如何利用快排的方法呢？快排是对每一个区间进行分治处理，而此问题不必，我们只要找到第n/2小的数。每次随机划分得的第m个数，如果m &lt; n/2, 那么对[m + 1, n - 1]这个区间继续递归；如果m &gt; n/2，那么对[0, m - 1]这个区间进行递归；如果刚好有m = n/2，那么函数结束，区间[0, n/2 - 1]的数就是最小的n/2个数。 此算法的平均时间复杂度为O(n), 快速排序的详细证明可参考“算法导论”。 12345678910111213141516171819202122232425262728293031323334353637383940414243#include &lt;iostream&gt;#include &lt;cstdlib&gt;#include &lt;ctime&gt;#define RAND(start, end) start + (int)(end - start + 1)*(rand()/(RAND_MAX + 1))using namespace std;int Partition(int *data, int length, int start, int end)&#123; if (start == end) return start; srand((unsigned)time(NULL)); int index = RAND(start, end); swap(data[index], data[end]); int one = start - 1; for (index = start; index &lt; end; ++index) &#123; if (data[index] &lt; data[end]) &#123; ++one; if (one != index) swap(data[one], data[index]); &#125; &#125; ++one; swap(data[one], data[end]); return one;&#125;void FindIt(int *data, int length, int start, int end)&#123; int mid = Partition(data, length, start, end); if (mid == length &gt;&gt; 1) return; else if (mid &gt; length &gt;&gt; 1) FindIt(data, length, start, mid - 1); else FindIt(data, length, mid + 1, end);&#125;int main()&#123; int n; cin &gt;&gt; n; int *data = new int[n]; for (int i = 0; i &lt; n; ++i) &#123; cin &gt;&gt; data[i]; &#125; FindIt(data, n, 0, n - 1); cout &lt;&lt; data[n &gt;&gt; 1];&#125; 下一篇：算法风暴之二—最小的k个数","categories":[{"name":"算法","slug":"算法","permalink":"https://fiveplus.top/categories/算法/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://fiveplus.top/tags/算法/"}],"author":"姬小野"},{"title":"Python实现简单分类器","slug":"Python实现简单分类器","date":"2018-09-20T16:00:00.000Z","updated":"2019-08-15T05:49:52.709Z","comments":true,"path":"2018/09/21/python-shi-xian-jian-dan-fen-lei-qi/","link":"","permalink":"https://fiveplus.top/2018/09/21/python-shi-xian-jian-dan-fen-lei-qi/","excerpt":"","text":"今天重新开始学习机器学习，训练了一个简单的分类器。 如何工作的呢？给定一组训练数据，他们的参数有三个，x轴坐标，y轴坐标，类别。即(x, y, c)。如图所示红色的圆点代表第一类点，类别编号为1；蓝色的倒三角形代表第二类点，类别编号为0. 我们的目的，是根据这些训练数据，拟合出一条边界线，来将两种类别的数据划分开来，这个系统就叫做分类器。鉴于笔者水平尚浅，故暂时只能训练从原点出发的线性分类器。 下面就讨论这个简单分类器的具体实现，对于入门者来说，其实也可以学到不少东西。 第一步，导入我们需要的python库在这份代码中，我用到了numpy库和matplotlib库，并且在jupyter notebook中实现了内置matplotlib。 123%matplotlib inlineimport matplotlib.pyplot as pltimport numpy as np 第二步，获取训练数据并解析坐标我们的输入格式是这样的： 1.0 3.0 1,3.0 1.0 0,2.0 2.0 1,4.0 1.0 0,2.0 4.0 1,4.5 1.0 0,3.0 2.5 1,5.0 2.0 0 每行代表一个坐标的信息，分别是横坐标，纵坐标，类别。每组数据间用, 分隔，因此可以很简单的用split函数将数据划分。具体到每个坐标的信息，我们可以利用numpy的fromstring函数获取一个字符串信息，并把他们转化为float类型。 12345678910111213141516get = input(\"请输入训练数据，第三个参数为类别\")get = get.split(',')train_data = []x1 = []y1 = []x0 = []y0 = []for each in get: train_data.append(np.fromstring(each, dtype=float, sep=' '))for each in train_data: if each[2] == 1: x1.append(each[0]) y1.append(each[1]) else: x0.append(each[0]) y0.append(each[1]) 第三步，随机化数据为了使我们的数据更加准确，我们需要用到随机化数据。如果不随机化会怎么样呢？不随机化，我们的分类器就可能陷入某种极端情况，从而得出错误的解。 代码中，我们使用numpy的随机技术。 1、首先初始化随机种子，由于我希望每次都随机，所以我给随机种子传递的参数也是随机的2、随机化排列，这样可以得到一个随机的排列，以在后续处理数据时相对公平。 123np.random.seed(np.random.randint(0, 10000, size=1, dtype=int))order1 = np.random.permutation(len(x1))order0 = np.random.permutation(len(x0)) 第四步、生成分界线斜率这一步是最核心的一步，我们通过输入的训练数据对直线斜率进行调整。方法就是利用预测值与期望值之间的误差进行拟合，同时使用学习率learn和一些调整量adjust，使得过去和现在的训练能同时起到作用，而不偏颇。 1234567slope = 1.0adjust = 0.0learn = 0.5for i in range(len(x1)): slope += (y1[order1[i]] - slope*x1[order1[i]] + adjust)/x1[order1[i]]*learn slope += (y0[order0[i]] - slope*x0[order0[i]] - adjust)/x0[order0[i]]*learnprint(slope) 第五步、处理测试数据对测试数据的读入，我们的处理和训练数据是一样的。通过对预边界测试和实际值的对比，我们得出测试数据的类别信息，从而实现分类。 123456789101112131415get = input(\"请输入测试数据：\")get = get.split(',')test_data = []x2 = []y2 = []for i in get: test_data.append(np.fromstring(i, dtype=float, sep=' '))for i in test_data: x2.append(i[0]) y2.append(i[1])for i in range(len(x2)): if x2[i]*slope &gt; y2[i]: print(0) else: print(1) 第六步、输出展示分类结果图像是最直观的，因此我们利用matplotlib来展示结果。 1234567891011x = np.array(range(7))y = []for i in x: y.append(slope*i)plt.figure(figsize=(12, 10))plt.xlim(0, 6)plt.ylim(0, 5)plt.plot(x, y, linestyle='-')plt.plot(x1, y1, 'o', color='red')plt.plot(x0, y0, 'v', color='blue')plt.plot(x2, y2, 'x', color='black') 如图可见，我们的分类器准确度还是比较高的。 输入数据123456789101112131415# 训练集1.0 3.0 1,3.0 1.0 0,2.0 2.0 1,4.0 1.0 0,2.0 4.0 1,4.5 1.0 0,3.0 2.5 1,5.0 2.0 0# 测试集4.0 3.0,2.5 2.5,3.6 1.5,5.0 1.5 完整代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960%matplotlib inlineimport matplotlib.pyplot as pltimport numpy as npget = input(\"请输入训练数据，第三个参数为类别\")get = get.split(',')train_data = []x1 = []y1 = []x0 = []y0 = []for each in get: train_data.append(np.fromstring(each, dtype=float, sep=' '))for each in train_data: if each[2] == 1: x1.append(each[0]) y1.append(each[1]) else: x0.append(each[0]) y0.append(each[1])np.random.seed(np.random.randint(0, 10000, size=1, dtype=int))order1 = np.random.permutation(len(x1))order0 = np.random.permutation(len(x0))slope = 1.0adjust = 0.0learn = 0.5for i in range(len(x1)): slope += (y1[order1[i]] - slope*x1[order1[i]] + adjust)/x1[order1[i]]*learn slope += (y0[order0[i]] - slope*x0[order0[i]] - adjust)/x0[order0[i]]*learnprint(slope)get = input(\"请输入测试数据：\")get = get.split(',')test_data = []x2 = []y2 = []for i in get: test_data.append(np.fromstring(i, dtype=float, sep=' '))for i in test_data: x2.append(i[0]) y2.append(i[1])for i in range(len(x2)): if x2[i]*slope &gt; y2[i]: print(0) else: print(1)x = np.array(range(7))y = []for i in x: y.append(slope*i)plt.figure(figsize=(12, 10))plt.xlim(0, 6)plt.ylim(0, 5)plt.plot(x, y, linestyle='-')plt.plot(x1, y1, 'o', color='red')plt.plot(x0, y0, 'v', color='blue')plt.plot(x2, y2, 'x', color='black')","categories":[{"name":"机器学习","slug":"机器学习","permalink":"https://fiveplus.top/categories/机器学习/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://fiveplus.top/tags/机器学习/"}],"author":"姬小野"},{"title":"Chrome浏览器使用指南","slug":"Chrome浏览器使用指南","date":"2018-09-07T16:00:00.000Z","updated":"2019-09-15T01:19:39.745Z","comments":true,"path":"2018/09/08/chrome-liu-lan-qi-shi-yong-zhi-nan/","link":"","permalink":"https://fiveplus.top/2018/09/08/chrome-liu-lan-qi-shi-yong-zhi-nan/","excerpt":"","text":"目录 废话从ie到国产，从国产到火狐，最后终于到了Chrome，这条路可谓是曲折，与Chrome相见恨晚。用过这么多浏览器，对现在用的Chrome最满意。尤其是十周年更新了69版本后，配合自己搭建的梯子，越用越舒服，简直爱不释手。先放张美图这是浏览器打开的界面，简洁唯美，清新灵动。 Chrome 10周年之际，我打算写一篇Chrome使用指北⚘，把我使用的觉得有用的经验技巧分享出来。但由于每个人的身份不一样，所以同样的内容有的人觉得有用有的人却觉得没用，大家各自取舍吧。 快速进入网页我平常有记忆网站域名的习惯，所以我要进入一个网站通常不用在书签里面查找或者在搜索引擎搜索，而是直接输入域名。而配合Chrome浏览器的url自动补全功能，我通常只要输入一两个字母，即可快速进入想要进入的网站。极大地提高了工作学习效率。 如图，分别是快速进入谷歌google.com, 洛谷luogu.org, QQ邮箱mail.qq.com的展示。不能更方便。 快速切换搜索引擎有时候我们会用百度，有时候会用谷歌，诚然在切换时我们可以直接进入他们的网站进行搜索，但是，还有更快的方法，那就是在搜索栏里输入自定义的关键字，然后按空格或tab键，实现搜索引擎的快速切换。 可以用来快速网购商品，搜索豆瓣某电影，进行谷歌翻译，搜索维基百科，盘搜搜搜资源。。。 步骤是：Settings -&gt; Search engine -&gt; Manage search engines; 然后就请为所欲为吧。 同步账号信息Chrome是多平台浏览器，它提供的同步功能使得我们更换平台或重装浏览器时非常方便。账号密码，历史纪录，书签，甚至是PC端的插件，一键同步，当然前提是你得能够FQ。如何FQ？自己动手丰衣足食，可以参考我写的一篇博客，自己动手搭建梯子（曾有数千访问量,被CSDN一日腰斩，重发后一直处于潜水状态） Chrome插件所谓无插件不Chrome，插件可谓是Chrome的灵魂所在。网上关于Chrome插件的分享有很多，我推荐几个我常用的。 Chrome插件谷歌版Chrome插件百度版 如何安装Chrome插件一般说来有两种方法 第一种最官方最正式最方便但对国内最不友好。那就是到Chrome Web Store, 找到插件安装即可。不会FQ的童鞋只能WTF。 第二种是打开More tools -&gt; Extensions 页面，把下载好的crx扩展文件拖拽进去就好了。但是，在2018-9-8这一日，在Version 69.0.3497.81 (Official Build) (64-bit)这一版本，我是无法拖拽了，也许是谷歌提升了对插件安装来源的要求。 下面推荐几个插件 VIP看看此插件可以看各大视频网站的vip视频，只要在视频页点击右键，会找到有个vip看看的选项，点击即可跳转，然后开心的看视频了。不过分辨率不高，会模糊。 给大家推荐一个看VIP视频的盗版网站. 以后工作了一定要买正版VIP吖 Adblock Plus屏蔽广告屏蔽广告插件是必装的了，对比了几个屏蔽广告插件，发现Adblock Plus效果最好。体现在用它们把百度搜索页面的百度热搜屏蔽掉，这个插件最稳定而无复发。屏蔽百度热搜可以参考我写的这篇文章。 书签 这是一个很好用也比较漂亮的书签插件，虽然我平时很少用书签但觉得它挺不错就推荐了。书签图片就不放出来了（有隐私吖），应该不会让大家失望的。 OneTab 管理标签页打开的标签页太多又不想把他们删除怎么办？别急，OneTab来帮你。使用OneTab，你就可以一键将所有标签页合到一个OneTab标签页里面了，之后需要用哪个就点哪个，或者一键回复呀。 油猴这个可是插件中的神器呀，如果说Chrome是一个有丰富插件的平台，那么油猴就是有丰富脚本的插件，对于我来说，它相当于很多个“插件”。 它有什么用呢？它里面有全网音乐下载脚本，百度网盘外链脚本，比价脚本，youtube视频下载脚本，破解VIP视频脚本，小说阅读模式脚本。。。好用的东西简直不能更多。 小伙伴们可以到这个网站去寻找好用的插件啦 SetupVP_N这个得偷偷地说，这是一个非常好用的FQ插件，只需注册一个账号，就可以免费使用啦，不限流量不限时的哦。经过实际测试，俄罗斯结点是连的最快的，在油管上看1080P的视频都毫无压力哦。 后记关于Chrome的使用经验就分享到这里了，希望能帮大家提高工作效率吧: &gt; 如果觉得对你有所帮助，就请点个赞吧。","categories":[{"name":"开发工具","slug":"开发工具","permalink":"https://fiveplus.top/categories/开发工具/"}],"tags":[{"name":"Chrome","slug":"Chrome","permalink":"https://fiveplus.top/tags/Chrome/"}],"author":"姬小野"},{"title":"Tarjan算法缩点+DAG最长路(DP)","slug":"Tarjan算法缩点+DAG最长路(DP)","date":"2018-08-12T16:00:00.000Z","updated":"2019-11-22T16:30:57.046Z","comments":true,"path":"2018/08/13/tarjan-suan-fa-suo-dian-dag-zui-chang-lu-dp/","link":"","permalink":"https://fiveplus.top/2018/08/13/tarjan-suan-fa-suo-dian-dag-zui-chang-lu-dp/","excerpt":"","text":"我们按照复杂程度来讨论不同的Tarjan算法变形的差异. 第一个问题: Tarjan算法找出一个图里面的全部强连通分量(包括单独的点).但此时只是有所区分的将所有的点划分为一个个的强连通分量, 尚且没有缩点. 上面这个功能实现起来最简单. 它的Tarjan函数内部是这样的. 12345678910111213141516171819202122void tarjan(int u)&#123; dfn[u] = low[u] = ++index; stack[++top] = u; in_stack[u] = true; for (int i = 0; i &lt; G[u].size(); ++i) &#123; int v = G[u][i]; if (!dfn[v]) &#123; // 更新新的点. tarjan(v); low[u] = min(low[u], low[v]); &#125; else if (in_stack[v]) &#123; low[u] = min(low[u], low[v]); &#125; // 还剩下一种不在栈中但是已经访问过的情况,是其他连通分量的 &#125; if (dfn[u] == low[u]) &#123; do &#123; cout &lt;&lt; stack[top] &lt;&lt; ' '; in_stack[stack[top]] = false; // 漏写了这一条. &#125; while (stack[--top + 1] != u); cout &lt;&lt; endl; &#125;&#125; 第二个问题: 对每个强连通分量进行缩点, 使得此图变成一张DAG.在Tarjan函数内部他们的主要区别是当dfn[u] == low[u]的这一段 12345678910if (dfn[u] == low[u]) &#123; cnt++; int now; do &#123; now = sta.top(); sta.pop(); in_stack[now] = false; to[now] = cnt; &#125; while (now != u); &#125; 增加了一个全局变量cnt, 表示当前缩点的编号. 增加了一个to数组, 用来表示原来的点在缩点之后是哪个点. 所以我们可以有下面这段代码, set&lt;int&gt; Now代表缩点后的新图. 123456for (int i = 1; i &lt;= n; ++i) &#123; for (int j = 0; j &lt; G[i].size(); ++j) &#123; int u = to[i], v = to[G[i][j]]; if (u != v) Now[u].insert(v); &#125; &#125; 通过to数组关联起原图和缩点后图的点, 从而建立新图. 这样, 通过dfn[u] == low[u]处的修改, 以及结合to数组建立新图的过程, 就实现了Tarjan算法的缩点. 第三个问题: 如何快速获得新图各个结点的入度出度.上面的to数组保留, 看下面这段代码 12345678for (int i = 1; i &lt;= n; ++i) &#123; for (int j = 0; j &lt; G[i].size(); ++j) &#123; if (to[i] != to[G[i][j]]) &#123; out[to[i]]++; in[to[G[i][j]]]++; &#125; &#125; &#125; 一二层循环遍历之前所有的边, 里面一个条件语句, 判断边的两端点是否指向同一个缩点, 如果不是, 那么他们在to数组中所指向的新的结点也将作为一条边. 利用to数组可以快速方便的获取新图中的入度和出度, 这样的话要知道入度和出度就无需建立新图. ##第四个问题: 缩点之后求解DAG最长路 看洛谷上的这道题 传送门 此题是以点为权值而非边, 但做法是基本差不多的. 都是DP算法. DP函数是这样 1234567891011int DP(int u)&#123; if (dp[u]) return dp[u]; set&lt;int&gt;::iterator is = Now[u].begin(); while (is != Now[u].end()) &#123; dp[u] = max(dp[u], DP(*is)); is++; &#125; dp[u] += val_now[u]; return dp[u];&#125; 状态转移方程: dp[i] = max{dp[j] | (i, j) ∈E} + val_now[i]区别于边为权值的方程:dp[i] = max{dp[j]+length[i→j] | (i,j)∈E} AC代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778#include &lt;algorithm&gt;#include &lt;iostream&gt;#include &lt;vector&gt;#include &lt;stack&gt;#include &lt;set&gt;using namespace std;const int maxn = 10005;stack&lt;int&gt; sta;vector&lt;int&gt; G[maxn];set&lt;int&gt; Now[maxn];int n, m, index = 0, cnt = 0, ans = 0;int to[maxn], dfn[maxn] = &#123;&#125;, low[maxn];int dp[maxn] = &#123;&#125;, val[maxn], val_now[maxn] = &#123;&#125;;bool in_stack[maxn] = &#123;&#125;;void tarjan(int u)&#123; dfn[u] = low[u] = ++index; in_stack[u] = true; sta.push(u); for (int i = 0; i &lt; G[u].size(); ++i) &#123; int v = G[u][i]; if (dfn[v] == 0) &#123; tarjan(v); low[u] = min(low[u], low[v]); &#125; else if (in_stack[v]) low[u] = min(low[u], low[v]); &#125; if (dfn[u] == low[u]) &#123; cnt++; int now; do &#123; now = sta.top(); sta.pop(); in_stack[now] = false; to[now] = cnt; &#125; while (now != u); &#125;&#125;int DP(int u)&#123; if (dp[u]) return dp[u]; set&lt;int&gt;::iterator is = Now[u].begin(); while (is != Now[u].end()) &#123; dp[u] = max(dp[u], DP(*is)); is++; &#125; dp[u] += val_now[u]; return dp[u];&#125;int main()&#123; cin &gt;&gt; n &gt;&gt; m; for (int i = 1; i &lt;= n; ++i) cin &gt;&gt; val[i]; for (int i = 0; i &lt; m; ++i) &#123; int u, v; cin &gt;&gt; u &gt;&gt; v; G[u].push_back(v); &#125; for (int i = 1; i &lt;= n; ++i) if (dfn[i] == 0) tarjan(i); for (int i = 1; i &lt;= n; ++i) &#123; for (int j = 0; j &lt; G[i].size(); ++j) &#123; int u = to[i], v = to[G[i][j]]; if (u != v) Now[u].insert(v); &#125; &#125; for (int i = 1; i &lt;= n; ++i) &#123; int t = to[i]; val_now[t] += val[i]; &#125; for (int i = 1; i &lt;= cnt; ++i) ans = max(ans, dp[i] = DP(i)); cout &lt;&lt; ans;&#125; 我认为Tarjan算法缩点的核心就是to数组.","categories":[{"name":"算法","slug":"算法","permalink":"https://fiveplus.top/categories/算法/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://fiveplus.top/tags/算法/"}],"author":"姬小野"},{"title":"斐波那契_矩阵快速幂解法","slug":"斐波那契_矩阵快速幂解法","date":"2018-07-25T16:00:00.000Z","updated":"2019-11-22T16:30:28.242Z","comments":true,"path":"2018/07/26/fei-bo-na-qi-ju-zhen-kuai-su-mi-jie-fa/","link":"","permalink":"https://fiveplus.top/2018/07/26/fei-bo-na-qi-ju-zhen-kuai-su-mi-jie-fa/","excerpt":"","text":"学过矩阵学了矩阵再看斐波那契数列, 秒懂, 结合矩阵快速幂, 加深了一个概念的理解: 矩阵也就是一个基本的计算单位. 矩阵快速幂解法其实就是快速幂+矩阵. 和普通的快速幂有什么不同? 不同的是基数的类型,快速幂的过程还是一样的. 同样的,快速幂结果一般取模, 因为数据实在是太大了. 那么矩阵快速幂是否也应该取模? 那么推导一下似乎可以发现,矩阵的每个数都取模p,因为结果其实就是矩阵的某个元素 以[[1, 1], [1, 0]]的幂为n, n = 0时, 结果0, 如果我们取f0 = 0, f1 = 1, 以此类推,那么n次幂的结果就是右下角的那个数. 同时时间复杂度为O(n log n). 我们来回顾一下快速幂, 是从一次不断进行倍增, 如果数n 的二进制形式在某一位上为1,那么就乘以这一位,否则不乘 先写一下快速幂代码. 123456789101112131415#include &lt;iostream&gt;using namespace std;int main()&#123; int n, p, ans = 1, val = 2; cin &gt;&gt; n &gt;&gt; p; while (n) &#123; if (n &amp; 1) ans = ans * val % p; val *= val; n /= 2; &#125; cout &lt;&lt; ans;&#125;// OK, 就是这么简单. 那么矩阵快速幂也呼之欲出了. 然而写了代码发现计算过程有误.(划掉, 应该是推导有误,睡个午觉再来看看).OK, 找出bug来了, 推导没有错误, 是做矩阵乘法的时候几个下标写错了. 需要特别小心 但是发现答案稍微有点问题,看出其实now矩阵不用设置为二维单位矩阵,直接是[1, 0], 他就是答案. 但是非常悲剧的是洛谷上没有这么简单的模板题, 都不给我辛苦学习AC一下的快感. 12345678910111213141516171819202122232425262728#include &lt;iostream&gt;using namespace std;int main()&#123; int n, p = (1 &lt;&lt; 31); cin &gt;&gt; n; int now[2][1] = &#123;&#123;1&#125;, &#123;0&#125;&#125;, matrix[2][2] = &#123;&#123;1, 1&#125;, &#123;1, 0&#125;&#125;; while (n) &#123; int a, b, c, d; if (n &amp; 1) &#123; // 矩阵相乘. a = matrix[0][0] * now[0][0] + matrix[0][1] * now[1][0]; b = matrix[1][0] * now[0][0] + matrix[1][1] * now[1][0]; now[0][0] = a % p, now[1][0] = b % p; &#125; // 下面是矩阵平方, 有点麻烦. a = matrix[0][0] * matrix[0][0] + matrix[0][1] * matrix[1][0]; b = matrix[0][0] * matrix[0][1] + matrix[0][1] * matrix[1][1]; c = matrix[1][0] * matrix[0][0] + matrix[1][1] * matrix[1][0]; d = matrix[1][0] * matrix[0][1] + matrix[1][1] * matrix[1][1]; //cout &lt;&lt; &quot;c = &quot; &lt;&lt; c &lt;&lt; endl; matrix[0][0] = a % p, matrix[0][1] = b % p, matrix[1][0] = c % p, matrix[1][1] = d % p; n /= 2; //cout &lt;&lt; &quot;----------&quot; &lt;&lt; endl; //cout &lt;&lt; matrix[0][0] &lt;&lt; &apos; &apos; &lt;&lt; matrix[0][1] &lt;&lt; endl &lt;&lt; matrix[1][0] &lt;&lt; &apos; &apos; &lt;&lt; matrix[1][1] &lt;&lt; endl; &#125; cout &lt;&lt; now[1][0];&#125; 再来串矩阵快速幂模板(不只是斐波那契矩阵) 也就是矩阵计算 + 快速幂的组合. O(n3 + log k)** 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657#include &lt;iostream&gt;#include &lt;cstring&gt;using namespace std;typedef long long LL;const LL mode = 1000000007;void calc(LL ans[105][105], LL matrix[105][105], LL n)&#123; LL tmp[105][105]; memset(tmp, 0, sizeof(tmp)); for (int i = 1; i &lt;= n; ++i) &#123; for (int j = 1; j &lt;= n; ++j) &#123; for (int k = 1; k &lt;= n; ++k) &#123; tmp[i][j] += ans[i][k] * matrix[k][j]; tmp[i][j] %= mode; &#125; &#125; &#125; for (int i = 1; i &lt;= n; ++i) &#123; for (int j = 1; j &lt;= n; ++j) &#123; ans[i][j] = tmp[i][j]; &#125; &#125;&#125;int main()&#123; LL n, k, matrix[105][105], ans[105][105]; cin &gt;&gt; n &gt;&gt; k; for (int i = 1; i &lt;= n; ++i) &#123; for (int j = 1; j &lt;= n; ++j) &#123; cin &gt;&gt; matrix[i][j]; &#125; &#125; // 初始化为单位矩阵. memset(ans, 0, sizeof(ans)); for (int i = 1; i &lt;= n; ++i) &#123; ans[i][i] = 1; &#125; while (k) &#123; if (k &amp; 1) &#123; calc(ans, matrix, n); &#125; calc(matrix, matrix, n); k /= 2; &#125; for (int i = 1; i &lt;= n; ++i) &#123; for (int j = 1; j &lt;= n; ++j) &#123; cout &lt;&lt; ans[i][j] &lt;&lt; &apos; &apos;; &#125; cout &lt;&lt; endl; &#125;&#125;/*矩阵计算 + 快速幂*/","categories":[{"name":"算法","slug":"算法","permalink":"https://fiveplus.top/categories/算法/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://fiveplus.top/tags/算法/"}],"author":"姬小野"},{"title":"倍增法求Lca(最近公共祖先)","slug":"倍增法求Lca(最近公共祖先)","date":"2018-07-15T16:00:00.000Z","updated":"2019-11-22T16:33:17.620Z","comments":true,"path":"2018/07/16/bei-zeng-fa-qiu-lca-zui-jin-gong-gong-zu-xian/","link":"","permalink":"https://fiveplus.top/2018/07/16/bei-zeng-fa-qiu-lca-zui-jin-gong-gong-zu-xian/","excerpt":"","text":"一. 明确问题看标题便知道了, 这篇博客力求解决的问题是求出一棵树的两个结点的最近公共祖先(LCA), 方法是倍增法. 那么什么是Lca呢? 它是一棵树上两个结点向上移动, 最后交汇的第一个结点, 也就是说这两个结点祖先里离树根最远也是离他们最近的结点. 什么是倍增法呢? 此问题说的是用倍增法求解lca问题, 那么我们可以推测这种方法还可以解决其他的一些问题(不在当下讨论范围). 在学习的过程中, 我是这么理解的: 它是一种类似于二分的方法, 不过这里不是二分, 而是倍增, 以2倍, 4倍, 等等倍数增长 一下没有理解倍增法没关系, 看后面的做法, 再结合前面, 前后贯通大概可以理解的七七八八. 二. 思路引导下面的思路试图把过程模块化, 如果你不知道一个地方如何实现, 还请不要纠结(比如不要纠结于树的深度怎么求, 假设我们求好了树的深度) 我们找的是任意两个结点的最近公共祖先, 那么我们可以考虑这么两种种情况: 两结点的深度相同. 两结点深度不同. 算法实现来说, 第一种情况是第二种情况的特殊情况, 第二种情况是要转化成第一种情况的 先不考虑其他, 我们思考这么一个问题: 对于两个深度不同的结点, 把深度更深的那个向其父节点迭代, 直到这个迭代结点和另一个结点深度相同, 那么这两个深度相同的结点的Lca也就是原两个结点的Lca. 因此第二种情况转化成第一种情况来求解Lca是可行的. 现在还不知道如何把两个结点迭代到相同深度, 别急, 这里用到的是上面提到的倍增法. 那么剩下的问题事就解决第一种情况了, 两个结点深度相同了. 怎么求他们的Lca呢? 这里也是用了倍增法. 思路和上一步的倍增法是一样的, 不同之处有两点 这次是两个结点一起迭代向前的. 这次迭代停止的条件和上次不一样. OK, 现在无法理解上面的几个过程没关系,只要知道我们用递增法解决了上述的两个问题. 具体细节看下面分析. 三. 整体框架.那么过了一遍上面的思路引导之后, 我们可以大概想一想怎么实现整个的问题了. 其实用求Lca这个问题可以分为两块: 预处理 + 查询, 其中预处理是O(VlogV), 而一次查询是O(logV), V代表结点数量. 所以总时间复杂度为O(VlogV +ＱlogV). Q为查询次数 其步骤是这样的: 存储一棵树(邻接表法) 获取树各结点的上的深度(dfs或bfs) 获取2次幂祖先的结点, 用parents[maxn][20]数组存储, 倍增法关键 用倍增法查询Lca 步骤一用邻接表存储一棵树, 并用from[]数组记录各结点的父节点, 其中没有父节点的就是root. parents[u][]数组存储的是u结点的祖先结点.如parents[u][0], 是u结点的2⁰祖先结点, 即1祖先, 也即父节点. 在输入过程中可以直接得到.parents[u][1], 是u结点的2¹祖先结点,即2祖先, 也即父亲的父亲parents[u][2], 是u结点的2²祖先结点, 即4祖先, 也即(父亲的父亲)的(父亲的父亲), 也就是爷爷的爷爷. 理解这个关系很重要, 这也是通过父亲结点获取整个祖先结点的关键. 现在可以先跳过. 1234567891011121314void getData()&#123; cin &gt;&gt; n; int u, v; for (int i = 1; i &lt; n; ++i) &#123; cin &gt;&gt; u &gt;&gt; v; G[u].push_back(v); parents[v][0] = u; from[v] = 1; &#125; for (int i = 1; i &lt;= n; ++i) &#123; if (from[i] == -1) root = i; &#125;&#125; 步骤二获取各结点的深度, 可以用DFS或这BFS方法 1234567891011121314151617181920212223void getDepth_dfs(int u) // DFS求深度&#123; int len = G[u].size(); for (int i = 0; i &lt; len; ++i) &#123; int v = G[u][i]; depth[v] = depth[u] + 1; getDepth_dfs(v); &#125;&#125;void getDepth_bfs(int u) // BFS求深度&#123; queue&lt;int&gt; Q; Q.push(u); while (!Q.empty()) &#123; int v = Q.front(); Q.pop(); for (int i = 0; i &lt; G[v].size(); ++i) &#123; depth[G[v][i]] = depth[v] + 1; Q.push(G[v][i]); &#125; &#125;&#125; 步骤三求祖先 在步骤一里面我们讨论了parents数组的意义, 它存的是结点u的2次幂祖先, 从父亲结点开始. 为什么要存2次幂? 这就是倍增法的思想了, 我们进行范围缩小不是一步一步的, 那样太暴力了, 所以我们需要某个跨度, 让我们能够先跨越大步, 接近的时候在小步小步跨越, 这样可以大大节省时间. 读者可能会疑惑, 先大步, 后小步, 可是我怎么知道什么时候该大步, 什么时候该小步呢? 难道不会不小心跨过头吗? 其实不会的, 在代码实现上, 这样的跨越有条件约束, 是非常讲究的. 读者不必为此纠结, 不过要讲解也是十分费力不讨好的事情, 所以请读者认证推敲后面Lca函数的代码, 认真琢磨为什么是那样跨越, 其中真味自会品出. 最好是自己写几个例子, 模拟跨越的过程, 在结合现实意义去理解 那么我们回到当前问题. 请看下面这个公式: parents[i][j] = parents[parents[i][j-1]][j-1] 这是构造此数组的公式. 不难理解, 父亲的父亲就是爷爷, 爷爷的爷爷就是4倍祖先. 请读者结合现实意义去理解. 12345678void getParents()&#123; for (int up = 1; (1 &lt;&lt; up) &lt;= n; ++up) &#123; for (int i = 1; i &lt;= n; ++i) &#123; parents[i][up] = parents[parents[i][up - 1]][up - 1]; &#125; &#125;&#125; 步骤四做完了前面O(VlogV)的预处理操作, 剩下的就是查询了, 一次查询O(logV) 因此, 我们可以敏锐的想到: Lca算法适合查询次数比较多的情况, 不然, 光是预处理就花了那么多时间了. 所以说, 查询是我们享受成果的时候了. 12345678910111213141516171819202122232425int Lca(int u, int v)&#123; if (depth[u] &lt; depth[v]) swap(u, v); // 使满足u深度更大, 便于后面操作 int i = -1, j; // i求的是最大二分跨度 while ((1 &lt;&lt; (i + 1)) &lt;= depth[u]) ++i; // 下面这个循环是为了让u和v到同一深度 for (j = i; j &gt;= 0; --j) &#123; if (depth[u] - (1 &lt;&lt; j) &gt;= depth[v]) &#123; // 是&gt;=, 因为如果&lt;,代表跳过头了,跳到了上面. u = parents[u][j]; &#125; &#125; if (u == v) return u; // 刚好是祖宗 // u和v一起二分找祖宗 for (j = i; j &gt;= 0; --j) &#123; if (parents[u][j] != parents[v][j]) &#123; u = parents[u][j]; v = parents[v][j]; &#125; &#125; return parents[u][0]; // 说明上个循环迭代到了Lca的子结点 &#125; 首先把u调整到深度更大(或相同)的结点, 便于后面操作. 然后获取最大跨度i, 所有的跨越都是从i开始的. 再然后把u上升到和v一样的深度. 也就是我们前面讨论过的情况二转情况一. 最后, 两个结点同时迭代, 直到找到Lca 至此, 我们的问题就解决了. 完整代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126#include &lt;iostream&gt;#include &lt;algorithm&gt;#include &lt;cstring&gt;#include &lt;queue&gt;#include &lt;vector&gt;using namespace std;const int maxn = 10005;int parents[maxn][20], depth[maxn];int n, from[maxn], root = -1;vector&lt;int&gt; G[maxn];void init()&#123; memset(parents, -1, sizeof(parents)); memset(from, -1, sizeof(from)); memset(depth, -1, sizeof(depth));&#125;void getData()&#123; cin &gt;&gt; n; int u, v; for (int i = 1; i &lt; n; ++i) &#123; cin &gt;&gt; u &gt;&gt; v; G[u].push_back(v); parents[v][0] = u; from[v] = 1; &#125; for (int i = 1; i &lt;= n; ++i) &#123; if (from[i] == -1) root = i; &#125;&#125;void getDepth_dfs(int u)&#123; int len = G[u].size(); for (int i = 0; i &lt; len; ++i) &#123; int v = G[u][i]; depth[v] = depth[u] + 1; getDepth_dfs(v); &#125;&#125;void getDepth_bfs(int u)&#123; queue&lt;int&gt; Q; Q.push(u); while (!Q.empty()) &#123; int v = Q.front(); Q.pop(); for (int i = 0; i &lt; G[v].size(); ++i) &#123; depth[G[v][i]] = depth[v] + 1; Q.push(G[v][i]); &#125; &#125;&#125;void getParents()&#123; for (int up = 1; (1 &lt;&lt; up) &lt;= n; ++up) &#123; for (int i = 1; i &lt;= n; ++i) &#123; parents[i][up] = parents[parents[i][up - 1]][up - 1]; &#125; &#125;&#125;int Lca(int u, int v)&#123; if (depth[u] &lt; depth[v]) swap(u, v); int i = -1, j; while ((1 &lt;&lt; (i + 1)) &lt;= depth[u]) ++i; for (j = i; j &gt;= 0; --j) &#123; if (depth[u] - (1 &lt;&lt; j) &gt;= depth[v]) &#123; u = parents[u][j]; &#125; &#125; if (u == v) return u; for (j = i; j &gt;= 0; --j) &#123; if (parents[u][j] != parents[v][j]) &#123; u = parents[u][j]; v = parents[v][j]; &#125; &#125; return parents[u][0];&#125;void questions()&#123; int q, u, v; cin &gt;&gt; q; for (int i = 0; i &lt; q; ++i) &#123; cin &gt;&gt; u &gt;&gt; v; int ans = Lca(u, v); cout &lt;&lt; ans &lt;&lt; endl; //cout &lt;&lt; u &lt;&lt; &quot; 和 &quot; &lt;&lt; v &lt;&lt; &quot; 的最近公共祖先(LCA)是: &quot; &lt;&lt; ans &lt;&lt; endl; &#125;&#125;int main()&#123; init(); getData(); depth[root] = 1; getDepth_dfs(root); //getDepth_bfs(root); getParents(); questions();&#125;/*91 21 31 42 52 63 76 87 951 35 68 98 45 8*/","categories":[{"name":"算法","slug":"算法","permalink":"https://fiveplus.top/categories/算法/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://fiveplus.top/tags/算法/"}],"author":"姬小野"},{"title":"DP_最长不下降子序列","slug":"DP_最长不下降子序列(LIS)","date":"2018-07-10T16:00:00.000Z","updated":"2019-08-15T05:49:30.390Z","comments":true,"path":"2018/07/11/dp-zui-chang-bu-xia-jiang-zi-xu-lie-lis/","link":"","permalink":"https://fiveplus.top/2018/07/11/dp-zui-chang-bu-xia-jiang-zi-xu-lie-lis/","excerpt":"","text":"序言同类的问题还有“最长上升子序列”, “最长下降子序列”, … 他们的不同就在于定义的core规则不同, 有的是&gt;=, 有的是&gt;, 有的是&lt; 由此启发, 我们可以在解决其他的问题, 不一定是比较数的大小的问题里面抽象出这种模型. 下面介绍这种动态规划入门都会介绍的问题的思路. 首先我们从头开始分析这个问题. 一. 最容易想到的最暴力的方法对这个序列中的每一个数的”有”和”无”分两种情况讨论. 代码实现上就是递归. 时间复杂度就是O(2^n) 代码实现上较为简单. 不展示 二. 第二种方法是O(n^2)的DP方法动态规划的问题是无后效性的, 每个问题都可以分解为更小的子问题, 从而求解. 这道题也不例外. 这个序列的每一个数为止都有一个解, 作为子问题的解. 后面的问题的解就是从这些子问题的最优解继承过来的. so, 给这个序列的解建立数组dp[n], 0 - n分别是截止到Ai的解. 当下一个数要加入来的时候, 有两种情况 前面的数都比当前数更大, 因此以这个数为止的最长不下降子序列的长度就是1. 遍历到第一个数的情况也包含在内. 前面的数有不比当前数大的, 那么这个数的结果dp[i] = max(dp[i], dp[j] + 1). 这个过程遍历前面所有数的dp[j]进行比较. 最后的答案就是所有dp[i]里面的最大值. 这种方法的时间复杂度是O(n^2), 可以看到相比于前面暴力递归的方法有了极大的进步. 代码通过样例, 但不一定能过题, 请谨慎使用. 1234567891011121314151617181920212223242526#include &lt;iostream&gt;#include &lt;vector&gt;using namespace std;int main()&#123; int n, x; vector&lt;int&gt; v; cin &gt;&gt; n; for (int i = 0; i &lt; n; ++i) &#123; cin &gt;&gt; x; v.push_back(x); &#125; int dp[(int)v.size()] = &#123;1&#125;, ans = 1; for (int i = 1; i &lt; (int)v.size(); ++i) &#123; for (int j = 0; j &lt; i; ++j) &#123; if (v[i] &gt;= v[j]) dp[i] = max(dp[i], dp[j] + 1); // 状态转移方程 &#125; ans = max(ans, dp[i]); &#125; cout &lt;&lt; ans;&#125;/*81 2 3 -9 3 9 0 11*/ 三. O(nlogn)方法, 维护单调数组这个方法也是DP方法 时间复杂度可以从O(n^2)降到O(n log n). 我们从最长上升子序列的角度来探讨 假设对一个序列n[1…9] = {2 1 5 3 6 4 8 9 7}, 维护一个单调数组, 使得这个数组为最长上升子序列. 设这个数组为d[ ]. 对n[1] = 2, 使得d[1] = 2; 对n[2] = 1, 因为1比2小, 所以修改d[1]的值, 使其为1 对n[3] = 5, 5比1大, 所以len++, d[2] = 5 对n[4] = 3, 3比1大比5小, 所以替换掉5, 使d[2] = 3 对n[5] = 6, 6比d[2]大, 所以len++, d[3] = 6 对n[6] = 4, 4比3大比6小, 所以替换掉6, 使d[3] = 4 对n[7] = 8, 8比4大, 所以len++, 使d[4] = 8 对n[8] = 9, 9比8大, 所以len++, 使d[5] = 9 对n[9] = 7, 7比4大比8小, 所以替换掉8, 使d[4] = 7. 至此这个序列遍历完了, 最小的长度也出来了. 最后的序列是1 3 4 7 9, len = 5 仔细琢磨会觉得, 如最后一步操作, 为什么后面的7反而到他前面的8, 9的前面去了. 其实仔细一想并无问题, 因为即使7出现在前面, 它并不影响最终结果, 因为我们已经得出最后结果就是len, 而以7为结尾的最长序列在该题中是len - 1, 如果后面还有序列, 那么这里把7替换掉8会使得当前状态更优, 因为这样的修改是不会改变当前结果的, 但是确实后续最优状态的基础. 而这道题的动态规划思想就是这样, 不断地获取最优状态. 经过前面的分析我们也许会发现, 这个DP的过程无法存储中间结果, 也就是说我们只能知道最长的子序列是多长, 而无法得到是哪个序列. 可谓是有利有弊. 利用我们维护的数组的单调性, 我们可以用二分法查找这个比当前数更大数的位置, 从而方便的实现替换. 所以时间复杂度为O(n log n). 1234567891011121314151617181920212223242526272829303132#include &lt;iostream&gt;#include &lt;algorithm&gt;#include &lt;vector&gt;using namespace std;int main()&#123; int n, x; vector&lt;int&gt; v, vec; cin &gt;&gt; n; for (int i = 0; i &lt; n; ++i) &#123; cin &gt;&gt; x; v.push_back(x); &#125; for (int i = 0; i &lt; (int)v.size(); ++i) &#123; if (i == 0) vec.push_back(v[0]); else &#123; if (v[i] &gt;= vec[vec.size() - 1]) vec.push_back(v[i]); else *upper_bound(vec.begin(), vec.end(), v[i]) = v[i]; &#125; &#125; for (int i = 0; i &lt; (int)vec.size(); ++i) &#123; cout &lt;&lt; vec[i] &lt;&lt; &apos; &apos;; &#125; cout &lt;&lt; endl; cout &lt;&lt; &quot;len == &quot; &lt;&lt; vec.size() &lt;&lt; endl;&#125;/*92 1 5 3 6 4 8 9 7*/","categories":[{"name":"算法","slug":"算法","permalink":"https://fiveplus.top/categories/算法/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://fiveplus.top/tags/算法/"}],"author":"姬小野"},{"title":"DP_最长回文子串","slug":"DP_最长回文子串","date":"2018-07-10T16:00:00.000Z","updated":"2019-08-15T05:49:34.109Z","comments":true,"path":"2018/07/11/dp-zui-chang-hui-wen-zi-chuan/","link":"","permalink":"https://fiveplus.top/2018/07/11/dp-zui-chang-hui-wen-zi-chuan/","excerpt":"","text":"####DP问题, 最长回文子串 最长回文子串问题指的是在一个字符串中, 是回文子串的长度的最大值. 这里的回文子串是连续的. 如字符串”PATZJUJZTACCBCC”, 他的最长回文子串是”ATZJUJZTA”, 长度为9, 当然它还有其他回文子串如”CCBCC”, 但是长度不够长. 这类问题似乎有多种解法, 复杂度从O(n^3)到O(n)不等. 下面介绍一种时间复杂度为O(n^2)的. 思路是典型的DP思路, 我们可以考量这样一个数组, dp[i][j], bool类型, 值为1代表字符串从S[i]到S[j]是回文子串, 值为0代表不是. 那么对于任意的i, j, 如何判断dp[i][j]的值呢? 讨论下面两种情况: 1. s[i] = s[j]时, 如果dp[i+1][j-1] = 0, 即从s[i+1]到s[j-1]是回文子串, 那么从s[i][j]自然是回文子串, 所以dp[i][j] = dp[i+1][j-1]2. s[i] != s[j]时, 如论如何dp[i][j] = 0 那么这样看思路就非常清晰了, 看上去非常简单, 按照这个规则判断一下就好了. 不过其实这道题是非常有技巧的, 我们可以看到要获取dp[i][j]值, 那么就需要知道dp[i+1][j-1]的值, 那么就不能从前往后遍历i了, 怎么办呢? 从后往前遍历吗? 当然也不行. 这就是这种方法的精彩所在, 两套循环,外围遍历长度, 内围遍历字符串起始点i. 因为dp[i][j]的长度是j - i + 1, 而dp[i+1][j-1]的长度是j - i - 1, 长度差了两个, 如果我把长度小的结果都求解出来了, 那么长度更长的用长度更小的, 无论i是否会更大, 都是可以的. 不得不说很是精彩. 代码实现上, 注意前面初始化长度 2时对ans赋恰当的值. 12345678910111213141516171819202122232425262728293031#include &lt;iostream&gt;using namespace std;int main()&#123; string str; cin &gt;&gt; str; int dp[str.size() + 1][str.size() + 1] = &#123;&#125;, ans = 1; for (int i = 0; i &lt; int(str.size()); ++i) &#123; dp[i][i] = 1; if (str[i] == str[i + 1]) &#123; dp[i][i + 1] = 1; ans = 2; &#125; &#125; for (int len = 3; len &lt;= (int)str.size(); ++len) &#123; for (int i = 0; i + len - 1 &lt; (int)str.size(); ++i) &#123; int k = i + len - 1; if (str[i] == str[k]) &#123; dp[i][k] = dp[i + 1][k - 1]; if (dp[i][k]) ans = len; &#125; &#125; &#125; cout &lt;&lt; ans;&#125;/*PATZJUJZTACCBCC ans = 934567536487326483254 ans = 1*/","categories":[{"name":"算法","slug":"算法","permalink":"https://fiveplus.top/categories/算法/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://fiveplus.top/tags/算法/"}],"author":"姬小野"},{"title":"离散数学_C++生成真值表_模拟","slug":"离散数学_C++生成真值表_模拟","date":"2018-04-06T16:00:00.000Z","updated":"2019-08-15T05:48:46.146Z","comments":true,"path":"2018/04/07/chi-san-shu-xue-c-sheng-cheng-zhen-zhi-biao-mo-ni/","link":"","permalink":"https://fiveplus.top/2018/04/07/chi-san-shu-xue-c-sheng-cheng-zhen-zhi-biao-mo-ni/","excerpt":"","text":"生成真值表的代码 输入一个真值表达式, 程序自动生成它的真值表. 纯模拟思路 合取*析取|单条件&gt;双条件-非! 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164#include &lt;iostream&gt;#include &lt;string&gt;#include &lt;cmath&gt;using namespace std;int cnt = 0, chval[26] = &#123;&#125;;void getAlpha(string str, char *chs, int &amp;cnt) //获取真值表中的字符 &#123; int ch[26] = &#123;&#125;; for(int i = 0; i &lt; (int)str.length(); ++i) &#123; if(isalpha(str[i])) ch[str[i] - &apos;a&apos;] ++; &#125; for(int i = 0; i &lt; 26; ++i) &#123; if(ch[i]) &#123; chs[cnt++] = i+97; &#125; &#125;&#125;string shuzhitihuan(string str, int chval[26])&#123; string st = &quot;&quot;; for(int i = 0; i &lt; str.size(); ++i) &#123; if(str[i] &lt;= &apos;z&apos; &amp;&amp; str[i] &gt;= &apos;a&apos;) &#123; st += chval[str[i] - &apos;a&apos;] ? &quot;1&quot;:&quot;0&quot;; &#125; else st += str[i]; &#125; return st;&#125;void qvkuohao(string &amp; str) //需要去除两种括号()(1)(0)&#123; string st = &quot;&quot;; for(int i = 0; i &lt; str.size(); ++i) &#123; if(str[i] == &apos;(&apos; &amp;&amp; i+2 &lt; str.size() &amp;&amp; str[i+2] == &apos;)&apos;) &#123; st += str[i+1]; i += 2; &#125; else st += str[i]; &#125; str = st;&#125;void qvfei(string &amp;str) &#123; string st = &quot;&quot;; for(int i = 0; i &lt; str.size(); ++i) &#123; if(str[i] == &apos;!&apos; &amp;&amp; i+1 &lt; str.size() &amp;&amp; str[i+1] == &apos;0&apos;) &#123; st += &apos;1&apos;; i++; &#125; else if(str[i] == &apos;!&apos; &amp;&amp; i + 1 &lt; str.size() &amp;&amp; str[i+1] == &apos;1&apos;) &#123; st += &apos;0&apos;; i++; &#125; else st += str[i]; &#125; str = st;&#125; void qvheqv(string &amp;str)&#123; string st = &quot;&quot;; for(int i = 0; i &lt; str.size(); ++i) &#123; if(str[i] == &apos;1&apos; &amp;&amp; i+2 &lt; str.size() &amp;&amp; str[i+2] == &apos;1&apos; &amp;&amp; str[i+1] == &apos;*&apos;) &#123; st += &apos;1&apos;; i += 2; &#125; else if(i+2 &lt; str.size() &amp;&amp; str[i+1] == &apos;*&apos; &amp;&amp; ((str[i] == &apos;1&apos; &amp;&amp; str[i+2] == &apos;0&apos;) || (str[i] == &apos;0&apos; &amp;&amp; str[i+2] == &apos;1&apos;) || (str[i] == &apos;0&apos; &amp;&amp; str[i+2] == &apos;0&apos;))) &#123; st += &apos;0&apos;; i += 2; &#125; else st += str[i]; &#125; str = st;&#125;void qvxiqv(string &amp; str)&#123; string st = &quot;&quot;; for(int i = 0; i &lt; str.size(); ++i) &#123; if(str[i] == &apos;0&apos; &amp;&amp; i+2 &lt; str.size() &amp;&amp; str[i+2] == &apos;0&apos; &amp;&amp; str[i+1] == &apos;|&apos;) &#123; st += &apos;0&apos;; i += 2; &#125; else if (i+2 &lt; str.size() &amp;&amp; str[i+1] == &apos;|&apos; &amp;&amp; ((str[i] == &apos;1&apos; &amp;&amp; str[i+2] == &apos;0&apos;) || (str[i] == &apos;0&apos; &amp;&amp; str[i+2] == &apos;1&apos;) || (str[i] == &apos;1&apos; &amp;&amp; str[i+2] == &apos;1&apos;))) &#123; st += &apos;1&apos;; i += 2; &#125; else st += str[i]; &#125; str = st;&#125;void qvdantiaojian(string &amp;str)&#123; string st = &quot;&quot;; for(int i = 0; i &lt; str.size(); ++i) &#123; if(str[i + 1] == &apos;&gt;&apos; &amp;&amp; str[i] == &apos;1&apos; &amp;&amp; str[i+2] == &apos;0&apos;) &#123; st += &apos;0&apos;; i += 2; &#125; else if(str[i+1] == &apos;&gt;&apos; &amp;&amp; ((str[i] == &apos;1&apos; &amp;&amp; str[i+2] == &apos;1&apos;) || str[i] == &apos;0&apos; &amp;&amp;(str[i+2] == &apos;1&apos; || str[i+2] == &apos;0&apos;))) &#123; st += &apos;1&apos;; i += 2; &#125; else st += str[i]; &#125; str = st;&#125;void qvshuangtiaojian(string &amp;str)&#123; string st = &quot;&quot;; for(int i = 0; i &lt; str.size(); ++i) &#123; if(str[i+1] == &apos;-&apos; &amp;&amp; ((str[i] == &apos;1&apos; &amp;&amp; str[i+2] == &apos;1&apos;) || (str[i] == &apos;0&apos; &amp;&amp; str[i+2] == &apos;0&apos;))) &#123; st += &apos;1&apos;; i += 2; &#125; else if(str[i+1] == &apos;-&apos; &amp;&amp; ((str[i] == &apos;1&apos; &amp;&amp; str[i+2] == &apos;0&apos;) || (str[i] == &apos;0&apos; &amp;&amp; str[i+2] == &apos;1&apos;))) &#123; st += &apos;0&apos;; i += 2; &#125; else st += str[i]; &#125; str = st;&#125;int main()&#123; string str, tmp; char chs[12]; cin &gt;&gt; str; getAlpha(str, chs, cnt); //只讨论小写字母 tmp = str; for(int j = 0; j &lt; cnt; ++j) &#123; cout &lt;&lt; chs[j] &lt;&lt; &quot; &quot;; &#125; cout &lt;&lt; tmp; cout &lt;&lt; endl; for(int i = 0; i &lt; pow(2, cnt); ++i) &#123; for(int j = 0; j &lt; cnt; ++j) &#123; //赋值过程 chval[chs[j] - &apos;a&apos;] = (1 &amp; (i&gt;&gt;(cnt-1-j))); &#125; cout &lt;&lt; endl; for(int j = 0; j &lt; cnt; ++j) &#123; cout &lt;&lt; chval[chs[j] - &apos;a&apos;] &lt;&lt; &quot; &quot;; &#125; str = shuzhitihuan(str, chval); while(str.size() != 1) &#123; qvkuohao(str); qvfei(str); qvheqv(str); qvxiqv(str); qvdantiaojian(str); qvshuangtiaojian(str); &#125; for(int i = 0; i &lt; tmp.size() / 2; ++i) cout &lt;&lt; &apos; &apos;; cout &lt;&lt; str &lt;&lt; endl; str = tmp; &#125;&#125;/*((p*q)*r) (p*q)|(!p*!q)(!p|q)*(!q|p) (p&gt;q)*(q&gt;p)!(p*q)&gt;(!p*!q)p-q (!p|r)*(r&gt;q)|p*qp*q|r*b*/","categories":[{"name":"算法","slug":"算法","permalink":"https://fiveplus.top/categories/算法/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://fiveplus.top/tags/算法/"}],"author":"姬小野"},{"title":"一键安装v2ray","slug":"一键安装v2ray","date":"2018-03-10T11:19:19.000Z","updated":"2019-08-15T05:02:29.820Z","comments":true,"path":"2018/03/10/yi-jian-an-zhuang-v2ray/","link":"","permalink":"https://fiveplus.top/2018/03/10/yi-jian-an-zhuang-v2ray/","excerpt":"","text":"0、我的vps版本：Ubuntu 18.10 x64。 地点：东京。 1、v2ray官方给出了一键安装脚本bash &lt;(curl -L -s https://install.direct/go.sh) 2、很快就可以安装好了，可以用这个命令来查看状态service v2ray status 3、有以下这些命令，刚开始需要启动服务service v2ray start|stop|status|reload|restart|force-reload 4、由于是一键安装，于是那些设置都是默认的，可以到/etc/v2ray/config.json来配置自己的服务器，也是到这里找到设置然后给我们的客户端进行设置。 5、延迟在90ms左右6、一键进行BBR加速 wget -N --no-check-certificate &quot;https://raw.githubusercontent.com/chiakge/Linux-NetSpeed/master/tcp.sh&quot; &amp;&amp; chmod +x tcp.sh &amp;&amp; ./tcp.sh 7、我选择的是6 8、测试了一下延迟，最低居然达到了31ms，简直令人发指！！！ 9、多试几次稳定在60ms左右，也是非常低的延迟了！","categories":[{"name":"网络","slug":"网络","permalink":"https://fiveplus.top/categories/网络/"}],"tags":[{"name":"科学上网","slug":"科学上网","permalink":"https://fiveplus.top/tags/科学上网/"},{"name":"v2ray","slug":"v2ray","permalink":"https://fiveplus.top/tags/v2ray/"}]},{"title":"主元素问题_奇妙的思维","slug":"主元素问题_奇妙的思维","date":"2018-02-12T16:00:00.000Z","updated":"2019-08-15T05:49:04.012Z","comments":true,"path":"2018/02/13/zhu-yuan-su-wen-ti-qi-miao-de-si-wei/","link":"","permalink":"https://fiveplus.top/2018/02/13/zhu-yuan-su-wen-ti-qi-miao-de-si-wei/","excerpt":"","text":"主元素问题什么是主元素问题? 已知一个数组的大小，并且其中存在一个数，出现的频率大于50%，则称其为该数组的主元素。用一个算法找出这个数，要求其时间复杂度尽可能低。 这是一个很简单的问题, 解决的方法有很多, 思考这样一道问题的意义不在于只是把它解决, 而是找出多种解决它的方法, 感受算法的神奇. 衡量一个算法优劣的一个非常重要的尺度是时间复杂度, 我们如何让计算机用最短的时间, 解决这个问题呢? 先排序(比较排序)后计数的方法先排序后后比较, 这种方法是比较常规的思维.排序之后将每个相同的元素计数, 再根据数量判断是哪一个元素 比较排序最快的平均时间复杂度是O(nlogn), 所以这个方法最快的时间按复杂度是O(nlogn) 这种排序方式在所有方式中效率较低, 但它适合各种数据类型(如浮点型), 且在某些情况下空间复杂度比计数排序的方法小很多. 还可以判断是否存在这样一个主元素. 代码比较简单且常规, 不写出(实际上用STL的sort()很简单, 但手写快排, 还是算了吧……) 一个简单优化对于一个已经排序好了的序列, 其实不需要给每个元素计数. 因为它是主元素(&gt;50%), 所以只要取中值就可以知道它是哪个(它的值). 计数排序的方法计数排序也叫桶排序, 是一种非比较型排序. 时间复杂度位O(N) (N取决于数据范围) 鉴于计数排序对数据类型的限制很大, 所以比较各种排序方法的优劣时通常不把计数排序和快排这种比较排序相比较(事实上没有意义) 如果数据稀松或者范围很大, 计数排序将会非常浪费空间(空间复杂度非常大) 但在某些特定的条件下, 计数排序确实是一种时间复杂度位O(n)的排序算法如: 数据是1-1e6之间的整数 同样可以判断是否存在这样一个主元素 而使用计数排序的方法觉得这道题, 不需要排序, 事实上它可以看作计数排序的一个子过程 用STL中的nth_element()函数刚认识nth_element()函数没几天, 写这个问题的时候突然觉得可以用这个函数解决主元素问题. 思路是: 对N个数的序列用nth_element()找到第N/2+1个元素的值.这个值就是主元素的值 缺陷是: 无法判断是否存在主元素 这是奇数的情况: 123456789101112#include &lt;iostream&gt;#include &lt;algorithm&gt;#define N 7using namespace std;int main()&#123; int a[] = &#123;1, 4, 3, 1, 1, 2, 1&#125;; //N为奇数, 从0开始 nth_element(a, a + N/2, a + N); cout &lt;&lt; a[N/2];&#125; 这是偶数的情况: 123456789101112#include &lt;iostream&gt;#include &lt;algorithm&gt;#define N 6 using namespace std;int main()&#123; int a[] = &#123;1, 3, 1, 1, 2, 1&#125;; //N为偶数, 从0开始 nth_element(a, a + N/2, a + N); cout &lt;&lt; a[N/3];&#125; 时间复杂度为O(N)nth_element()是STL算法库中一种O(N)的单元素排序算法函数 豆瓣里一种巧妙地方法最后介绍的是一种豆瓣网友分享的巧妙算法 其核心思想在于：对于这样一个数组，去除掉任意两个不相等的数，剩下的数中，主元素的出现频率仍然大于50%。 但又缺陷: 只能在确定存在主元素的序列中找到这个主元素.即无法判断是否存在主元素 引自豆瓣:解法：声明一个变量count = 0，声明一个常量size等于数组大小。假设该数组的第一个元素a(1)为主元素，让其与a(2)进行比较，若相同，则使变量count+1，若不同，则count-1。然后继续比较a(3)。以此类推。 当与a(n)比较后，count = -1时，将count重新归为0，并重新假设a(n+1)为主元素，并继续与a(n+2)作比较。 当count&gt;=(size-m)/2时，此时假设的主元素a(m)即为实际的主元素。 或遍历完整个数组后，当前假设的主元素为实际主元素。 这个算法的时间复杂度最大才O(N)，看书看到这一段时令我顿时拍案叫绝啊。其核心思想在于：对于这样一个数组，去除掉任意两个不相等的数，剩下的数中，主元素的出现频率仍然大于50%。而使用count来进行加减计数，当count=0时，必然是偶数个数与假设的主元素进行了比较，且其中有一半与假设数相同一半与假设数不同（当count=-1时，加上假设数的集合，也满足该条件）。 下面是我写的简单代码(可能又bug) 1234567891011121314151617181920212223#include &lt;iostream&gt;#define N 7using namespace std;int main()&#123;// int a[] = &#123;1, 4, 3, 1, 1, 2, 1&#125;; int a[] = &#123;1, 3, 4, 4, 5, 4, 4&#125;;// int a[] = &#123;1 ,5 ,6 ,8 ,7 ,9 ,4 ,2 ,7 ,5 ,2 ,2 ,2 ,2&#125;; int cnt = 0, tmp = a[0]; for(int i = 1; i &lt; N; ++i) &#123; if(tmp == a[i]) cnt++; else cnt--; if(cnt &lt; 0) &#123; tmp = a[i]; cnt = 0; &#125; &#125; cout &lt;&lt; &quot;cnt == &quot; &lt;&lt; cnt &lt;&lt; endl; if (cnt &gt; 0) cout &lt;&lt; tmp &lt;&lt; endl; else cout &lt;&lt; &quot;There is no such a number !\\n&quot;;&#125; ###总而言之, 主元素问题是一种很简单的思维启发问题, 方法有很多, 可是你想到了最简单的方法吗?","categories":[{"name":"算法","slug":"算法","permalink":"https://fiveplus.top/categories/算法/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://fiveplus.top/tags/算法/"}],"author":"姬小野"},{"title":"最大子段和_三种方法","slug":"最大子段和_三种方法","date":"2018-02-08T16:00:00.000Z","updated":"2019-08-15T05:49:13.775Z","comments":true,"path":"2018/02/09/zui-da-zi-duan-he-san-chong-fang-fa/","link":"","permalink":"https://fiveplus.top/2018/02/09/zui-da-zi-duan-he-san-chong-fang-fa/","excerpt":"","text":"今天参加了一场洛谷网的比赛, 深受打击. 寒假过了这么多天, 一直没有认真学习算法, 以至于现在的水平比两个月前还要低. 本来就没有多少底子, 又退步了许多, 感慨万分. 在洛谷上看到这么一道题最大子段和 如果数据小的话, 用暴力枚举很简单就可以做出来了, 时间按复杂度位O(n^3)可是一道算法题怎么会这么简单呢? 样例的数据是非常大的, 所以用n^3的办法一个样例都过不了 1234567891011121314151617181920212223242526#include &lt;iostream&gt;#include &lt;algorithm&gt; using namespace std;int main()&#123; //std::ios::sync_with_stdio(false); long long int n, num[22000], Max = -1e8, sum; cin &gt;&gt; n; for( int i = 1; i &lt;= n; ++i ) &#123; scanf(&quot;%lld&quot;, &amp;num[i]); &#125; for( int i = 1; i &lt;= n; ++ i ) &#123; for( int j = 1; j &lt;= n - i + 1; ++j ) &#123; sum = 0; for(int k = j; k &lt; j + i; ++k) &#123; sum += num[k]; &#125; //cout &lt;&lt; &quot;sum = &quot; &lt;&lt; sum &lt;&lt; endl; Max = max(Max, sum); //cout &lt;&lt; Max &lt;&lt; endl; &#125; &#125; cout &lt;&lt; Max;&#125; 稍微优化一下, 使用前缀和以及差分, 可以有效地将复杂度降为O(n^2), 可是, 对于这道题来说, 这个时间还是太多了. 只能通过40%的样例 1234567891011121314151617181920212223242526#include &lt;iostream&gt;#include &lt;cstdio&gt;#include &lt;algorithm&gt;long long int n, num[220000], qz[220000] = &#123;&#125;, ans = -1e9;using namespace std;int main()&#123; //std::ios::sync_with_stdio(false); cin &gt;&gt; n; for( int i = 1; i &lt;= n; ++ i ) &#123; //cin &gt;&gt; num[i]; scanf(&quot;%lld&quot;, &amp;num[i]); &#125; for( int i = 1; i &lt;= n; ++i ) &#123; qz[i] = qz[i-1] + num[i]; &#125; for( int i = 1; i &lt;= n; ++i ) &#123; for( int j = 1; j &lt;= n-i+1; ++j ) &#123; ans = max(ans, qz[j+i-1] - qz[j-1]); &#125; &#125; cout &lt;&lt; ans &lt;&lt; endl;&#125; 还有一种分治的方法做这道题, 时间复杂度为O(nlogn), 有点复杂,我还不会. 最简单的呢, 使用DP的方法, 时间复杂度为O(n) 这种方法凭我自己现在的水平是想不出来的, 尤其是现在状态如此之差. 看别人解释后写了代码觉得如此巧妙, 于是又惊叹算法之神奇 可怜的是, 即便别人告诉我这道题用DP解最简单, 我也解不出来, 谁叫我DP还没入门呢? 思路描述是这样的: a数组是储存输入的数值；c[i]表示的是a数组从头加到i的和；b[i]表示的是从头到i包括i的的最大子段和~（必须包括i！！！）；minn储存最小的前缀和（因为要减去所以要尽量小，详情见下一行） 动态转移方程式：b[i]=c[i]-minn（总和减去前缀和） 最后输出b数组最大的值（题目求最大的子段和） 第一阶段的代码是这样的 1234567891011121314151617181920#include &lt;iostream&gt;#include &lt;cstdio&gt;#include &lt;algorithm&gt;using namespace std;long long int qz[220000] = &#123;&#125;, num[220000], mm[220000] = &#123;&#125;, an[220000], ans = -1e9;int main()&#123; int n; cin &gt;&gt; n; for(int i = 1; i &lt;= n; ++i) &#123; scanf(&quot;%lld&quot;, &amp;num[i]); qz[i] = num[i] + qz[i - 1]; mm[i] = min(mm[i - 1], qz[i - 1]); ans = max(ans, qz[i] - mm[i]); &#125; cout &lt;&lt; ans;&#125; 时间复杂度确实是小, 但是有一个问题就是空间复杂度太大了, 没必要这样开数组. 看了别人的题解, dalao们用的是滚动数组, 一个上面220000的数组只用两个元素循环滚动即可. 叹服! 妙哉! 12345678910111213141516171819#include &lt;iostream&gt;#include &lt;cstdio&gt;#include &lt;algorithm&gt;using namespace std;long long int qz[2] = &#123;&#125;, mm[2] = &#123;&#125;, ans = -1e9, m, n;int main()&#123; cin &gt;&gt; n; for( int i = 1; i &lt;= n; ++i ) &#123; scanf(&quot;%lld&quot;, &amp;m); qz[i % 2] = qz[(i + 1) % 2] + m; mm[i % 2] = min(mm[(i + 1) % 2], qz[(i + 1) % 2]); ans = max(ans, qz[i % 2] - mm[i % 2]); &#125; cout &lt;&lt; ans;&#125; 写这道题还发现了或者说学到了或者说巩固了几个小知识 1) 取消cin的同步用这样的代码 1std::ios::sync_with_stdio(false); 此为巩固 2) 使用scanf输入C++ 中long long 型的数是这样的 12long long int n;scanf(&quot;%lld&quot;, &amp;n); 如果n的类型写为long long Dev会发出警告, 还不知道为什么 百度一下, 又网友说long long 就是long long int , 只是int省略掉了 3) 使用scanf要包含头文件cstdio 以前我是不包含的, 不过这次在洛谷上提交出现了编译错误, 这也算是发现了自己的一个小bug吧 ____2018-7-9补充更新____ 今天程序设计训练测试出了这道题, 时隔多月再次写这道入门DP, 发现实现方法略有不同. 1234567891011121314151617181920212223#include &lt;iostream&gt;#include &lt;algorithm&gt;#include &lt;vector&gt;using namespace std;const int INF = 0x3f3f3f3f;int main()&#123; int x; vector&lt;int&gt; v; while (cin &gt;&gt; x) &#123; v.push_back(x); &#125; int qz = 0, MAX = -INF; for (int i = 0; i &lt; v.size(); ++i) &#123; if (qz + v[i] &lt;= 0) qz = 0; else &#123; qz += v[i]; MAX = max(MAX, qz); &#125; &#125; cout &lt;&lt; MAX;&#125;","categories":[{"name":"算法","slug":"算法","permalink":"https://fiveplus.top/categories/算法/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://fiveplus.top/tags/算法/"}],"author":"姬小野"},{"title":"初步数论-扩展欧几里得&线性同余方程","slug":"初步数论-扩展欧几里得&线性同余方程","date":"2018-01-03T16:00:00.000Z","updated":"2019-08-15T05:48:19.699Z","comments":true,"path":"2018/01/04/chu-bu-shu-lun-kuo-zhan-ou-ji-li-de-xian-xing-tong-yu-fang-cheng/","link":"","permalink":"https://fiveplus.top/2018/01/04/chu-bu-shu-lun-kuo-zhan-ou-ji-li-de-xian-xing-tong-yu-fang-cheng/","excerpt":"","text":"这篇博客我将介绍数论中的扩展欧几里得算法(extended Euclidean algorithm ),以及其在解线性同余方程(乘法逆元)中的运用. 首先要了解几个概念: 欧几里得算法 扩展欧几里得算法 线性同余方程 欧几里得算法是一种求解两个正整数a, b的最大公因子(一般记为gcd,gcd(a, b) )的方法,这个方法最早被记载在欧几里得的&lt;&lt;几何原本&gt;&gt;中.扩展欧几里得算法是在欧几里得算法的基础上扩展的一种算法.我们知道了 a 和 b 的最大公约数是 gcd ，那么，我们一定能够找到这样的 x 和 y ，使得: ax + by = gcd 这是一个不定方程（一种丢番图方程）.扩展欧几里得算法就这求这样的x, y 的.线性同余方程是最基本的同余方程，“线性”表示方程的未知数次数是一次.它的表现形式是这样的: 设x是未知整数, 形如 ax ≡ b(mod m) 的同余式称为一元线性同余方程. 加下来我将介绍使用扩展欧几里得算法解b = 1时的同余方程, 未知数为 x ,x又称为a的乘法逆元.乘法逆元是当b = 1时的解 x , 可以这样理解: ax ≡ 1(mod m) 我们称 x 是a关于m的乘法逆元 那么,从欧几里得算法开始.学习算法过程中,欧几里得算法大概是我接触到的第一个算法 12345int gcd(int a, int b)&#123; if( b==0 ) return a; else return gcd(b,a%b);&#125; 函数返回的是a, b的最大公约数,一般用gcd(a,b)来表示,数论中一般用(a,b)来表示a,b的最大公约数由于此算法较为基础,在此不过多赘述. 但,需要了解的是,扩展欧几里算法就是在欧几里得算法的基础上加以扩展形成的. 我们首先要知道这样一个结论:a 和 b 的最大公约数是 gcd ，那么，我们一定能够找到这样的 x 和 y ，使得: ax + by = gcd(a,b)扩展欧几里得算法的作用就是求这样的x, y的.它的解是无限的,我们可以这样表示它的通解: x = x0 + (b/gcd)*t; y = y0 - (a/gcd)*t;为什么不是： x = x0 + b*t; y = y0 - a*t; ?我们要知道,这个通解中未知数的表达式的运算过程是互相抵消的.如: (b/gcd) *t *a - (a/gcd) *t *b = 0;而如果a, b不是互质的, 另一种形式那么会漏掉一些解.读者自己斟酌.(具体证明博主也不知如何是好) 如何求解呢?只需要在欧几里德算法的基础上加点改动就行了。 下面引自一篇博客 我们观察到：欧几里德算法停止的状态是： a= gcd ， b = 0 ，那么，这是否能给我们求解 x y 提供一种思路呢？因为，这时候，只要 a = gcd 的系数是 1 ，那么只要 b 的系数是 0 或者其他值（无所谓是多少，反正任何数乘以 0 都等于 0 但是a 的系数一定要是 1），这时，我们就会有： a1 + b0 = gcd 当然这是最终状态，但是我们是否可以从最终状态反推到最初的状态呢？ 假设当前我们要处理的是求出 a 和 b的最大公约数，并求出 x 和 y 使得 ax + by= gcd ，而我们已经求出了下一个状态：b 和 a%b 的最大公约数，并且求出了一组x1 和y1 使得： bx1 + (a%b)y1 = gcd ， 那么这两个相邻的状态之间是否存在一种关系呢？ 我们知道： a%b = a - (a/b)*b（这里的 “/” 指的是整除，例如 5/2=2 , 1/3=0），那么，我们可以进一步得到： gcd = b*x1 + (a-(a/b)*b)*y1 = b*x1 + a*y1 – (a/b)*b*y1 = a*y1 + b*(x1 – a/b*y1) 对比之前我们的状态：求一组 x 和 y 使得：ax + by = gcd ，是否发现了什么？ 这里： x = y1 y = x1 – a/b*y1 123456789101112int ex_gcd( int a, int b, int &amp;x, int &amp;y )&#123; if( b==0 )&#123; x = 1, y = 0; return a; &#125; int ans = ex_gcd(b,a%b,x,y); int tmp = x; x = y; y = tmp - a/b*y; return ans;&#125; 欧几里得算法只能求a, b的最大公因数,而扩展欧几里得算法不仅可以求gcd(a,b),还可以求出a x + b y = gcd的通解只需在欧几里得算法的基础上稍加改动然而,求通解有什么用呢?我将介绍扩展欧几里得算法的一个应用,那就是前面提到过的解乘法逆元. 对于 ax ≡ 1(mod m)我们称 x 是a关于m的乘法逆元这和扩欧有什么关系呢?可以看到这个式子和a x + b y = gcd = 1是有些类似的可以等价于这样的表达式： a x + m y = 1a x + b y = gcd = 1, 说明a, b互质, 那么推广的式子a x + m y = 1中, a, m也是互质的当gcd(a, m) != 1时,x是无解的. 乘法逆元式子中, 已知a, m, 那么就可以利用扩展欧几里得算法求解x了.算法如下: 123456789101112131415161718192021222324#include &lt;iostream&gt;using namespace std;int ex_gcd( int a, int b, int &amp;x, int &amp;y )&#123; if( b==0 )&#123; x = 1, y = 0;//递归到终止条件, 初始化x, y return a; &#125; int ans = ex_gcd(b,a%b,x,y);//继续递归,此前不对x, y进行操作 int temp = x; x = y; y = tmp - a/b*y;//利用推导出的两个相邻状态的代换式进行迭代 return ans;&#125;int main( )&#123; int a, b, x, y; cin &gt;&gt; a &gt;&gt; b; if( ex_gcd(a,b,x,y)==1 )&#123; cout &lt;&lt; (x+b)%b; &#125;&#125; 注意,在ex_gcd()中求得的x可能为负值,因此采用了 cout &lt;&lt; (x+b)%b; 这样的输出方式，输出ｘ最小的正整数解 到这里就结束了,我们讲了什么呢? 欧几里得算法 扩展欧几里得算法 线性同余方程中一种特殊情况:乘法逆元 这是我在CSDN发表的的第一篇博客,有很多不足.如果没看懂的话,欢迎看这篇文章 扩展欧几里德算法详解 博主讲的很清楚, 对我启发很大.","categories":[{"name":"算法","slug":"算法","permalink":"https://fiveplus.top/categories/算法/"}],"tags":[{"name":"数学","slug":"数学","permalink":"https://fiveplus.top/tags/数学/"}],"author":"姬小野"},{"title":"Hello World","slug":"hello-world","date":"2018-01-03T16:00:00.000Z","updated":"2019-08-15T05:49:43.024Z","comments":true,"path":"2018/01/04/hello-world/","link":"","permalink":"https://fiveplus.top/2018/01/04/hello-world/","excerpt":"","text":"你好，世界！今天是本博客诞生的第一天，向世界问好！ hello, world! cpp123456#include &lt;iostream&gt;using namespace std;int main() &#123; cout &lt;&lt; \"hello, world!\" &lt;&lt; endl;&#125; c123456#include &lt;stdio.h&gt;int main() &#123; printf(\"hello, world!\\n); return 0;&#125; python1print('hello, world!\\n')","categories":[{"name":"blog","slug":"blog","permalink":"https://fiveplus.top/categories/blog/"}],"tags":[{"name":"blog","slug":"blog","permalink":"https://fiveplus.top/tags/blog/"}]}]}